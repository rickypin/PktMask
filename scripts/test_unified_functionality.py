#!/usr/bin/env python3
"""
PktMask ç»Ÿä¸€åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯ GUI ä¸ CLI åŠŸèƒ½çš„ä¸€è‡´æ€§
"""
import json
import os
import shutil
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Any, Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from pktmask.services.config_service import (
    build_config_from_cli_args,
    build_config_from_gui,
    get_config_service,
)
from pktmask.services.pipeline_service import create_pipeline_executor


class UnifiedFunctionalityTester:
    """ç»Ÿä¸€åŠŸèƒ½æµ‹è¯•å™¨"""

    def __init__(self):
        self.temp_dir = None
        self.test_results = []
        self.config_service = get_config_service()

    def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.temp_dir = Path(tempfile.mkdtemp(prefix="pktmask_test_"))
        print(f"ğŸ“ Test directory: {self.temp_dir}")

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        self.create_test_files()

    def teardown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.temp_dir and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            print("ğŸ§¹ Cleaned up test directory")

    def create_test_files(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ PCAP æ–‡ä»¶"""
        test_data_dir = self.temp_dir / "test_data"
        test_data_dir.mkdir()

        # åˆ›å»ºæ¨¡æ‹Ÿçš„ PCAP æ–‡ä»¶
        for i in range(3):
            test_file = test_data_dir / f"test_{i}.pcap"
            test_file.write_bytes(b"fake pcap content for testing")

        print(f"ğŸ“„ Created {len(list(test_data_dir.glob('*.pcap')))} test files")

    def test_config_consistency(self) -> bool:
        """æµ‹è¯•é…ç½®ä¸€è‡´æ€§"""
        print("\nğŸ”§ Testing configuration consistency...")

        try:
            # GUI é…ç½®
            gui_options = self.config_service.create_options_from_gui(
                remove_dupes_checked=True,
                anonymize_ips_checked=True,
                mask_payloads_checked=True,
            )
            gui_config = self.config_service.build_pipeline_config(gui_options)

            # CLI é…ç½®
            cli_options = self.config_service.create_options_from_cli_args(
                remove_dupes=True,
                anonymize_ips=True,
                mask_payloads=True,
            )
            cli_config = self.config_service.build_pipeline_config(cli_options)

            # éªŒè¯ä¸€è‡´æ€§
            consistency_checks = [
                gui_config["remove_dupes"]["enabled"] == cli_config["remove_dupes"]["enabled"],
                gui_config["anonymize_ips"]["enabled"] == cli_config["anonymize_ips"]["enabled"],
                gui_config["mask_payloads"]["enabled"] == cli_config["mask_payloads"]["enabled"],
                gui_config["mask_payloads"]["mode"] == cli_config["mask_payloads"]["mode"],
                gui_config["mask_payloads"]["protocol"] == cli_config["mask_payloads"]["protocol"],
            ]

            all_consistent = all(consistency_checks)

            if all_consistent:
                print("âœ… Configuration consistency: PASSED")
                self.test_results.append(("Config Consistency", True, "All configurations match"))
            else:
                print("âŒ Configuration consistency: FAILED")
                self.test_results.append(("Config Consistency", False, "Configuration mismatch"))

            return all_consistent

        except Exception as e:
            print(f"âŒ Configuration consistency: ERROR - {e}")
            self.test_results.append(("Config Consistency", False, str(e)))
            return False

    def test_cli_commands(self) -> bool:
        """æµ‹è¯• CLI å‘½ä»¤"""
        print("\nğŸ’» Testing CLI commands...")

        test_file = self.temp_dir / "test_data" / "test_0.pcap"
        output_file = self.temp_dir / "output.pcap"

        commands_to_test = [
            ["python", "-m", "pktmask", "info", str(test_file)],
            [
                "python",
                "-m",
                "pktmask",
                "info",
                str(self.temp_dir / "test_data"),
                "--format",
                "json",
            ],
        ]

        all_passed = True

        for cmd in commands_to_test:
            try:
                result = subprocess.run(cmd, cwd=project_root, capture_output=True, text=True, timeout=30)

                if result.returncode == 0:
                    print(f"âœ… Command '{' '.join(cmd[-2:])}': PASSED")
                    self.test_results.append((f"CLI {cmd[-2]}", True, "Command executed successfully"))
                else:
                    print(f"âŒ Command '{' '.join(cmd[-2:])}': FAILED")
                    print(f"   Error: {result.stderr}")
                    self.test_results.append((f"CLI {cmd[-2]}", False, result.stderr))
                    all_passed = False

            except subprocess.TimeoutExpired:
                print(f"â° Command '{' '.join(cmd[-2:])}': TIMEOUT")
                self.test_results.append((f"CLI {cmd[-2]}", False, "Command timeout"))
                all_passed = False
            except Exception as e:
                print(f"âŒ Command '{' '.join(cmd[-2:])}': ERROR - {e}")
                self.test_results.append((f"CLI {cmd[-2]}", False, str(e)))
                all_passed = False

        return all_passed

    def test_service_layer(self) -> bool:
        """æµ‹è¯•æœåŠ¡å±‚"""
        print("\nğŸ”§ Testing service layer...")

        try:
            # æµ‹è¯•é…ç½®æœåŠ¡
            config = build_config_from_cli_args(remove_dupes=True, anonymize_ips=True)
            is_valid, error = self.config_service.validate_config(config)

            if not is_valid:
                print(f"âŒ Config validation failed: {error}")
                self.test_results.append(("Service Layer", False, f"Config validation: {error}"))
                return False

            # æµ‹è¯•æ‰§è¡Œå™¨åˆ›å»º
            executor = create_pipeline_executor(config)
            if executor is None:
                print("âŒ Executor creation failed")
                self.test_results.append(("Service Layer", False, "Executor creation failed"))
                return False

            print("âœ… Service layer: PASSED")
            self.test_results.append(("Service Layer", True, "All service components working"))
            return True

        except Exception as e:
            print(f"âŒ Service layer: ERROR - {e}")
            self.test_results.append(("Service Layer", False, str(e)))
            return False

    def test_output_formats(self) -> bool:
        """æµ‹è¯•è¾“å‡ºæ ¼å¼"""
        print("\nğŸ“„ Testing output formats...")

        try:
            import io

            from pktmask.services.output_service import create_output_service
            from pktmask.services.report_service import get_report_service

            # æµ‹è¯•æ–‡æœ¬è¾“å‡º
            text_output = io.StringIO()
            text_service = create_output_service("text", "normal", text_output)

            test_result = {
                "success": True,
                "duration_ms": 1000.0,
                "total_files": 1,
                "processed_files": 1,
            }

            text_service.print_processing_summary(test_result)
            text_content = text_output.getvalue()

            if not text_content:
                print("âŒ Text output: FAILED - No output generated")
                self.test_results.append(("Text Output", False, "No output generated"))
                return False

            # æµ‹è¯• JSON è¾“å‡º
            json_output = io.StringIO()
            json_service = create_output_service("json", "normal", json_output)
            json_service.print_processing_summary(test_result)
            json_content = json_output.getvalue()

            try:
                json.loads(json_content)
            except json.JSONDecodeError:
                print("âŒ JSON output: FAILED - Invalid JSON")
                self.test_results.append(("JSON Output", False, "Invalid JSON format"))
                return False

            # æµ‹è¯•æŠ¥å‘ŠæœåŠ¡
            report_service = get_report_service()
            report_service.start_report("/test/input", "/test/output")
            report = report_service.finalize_report(True, 1, 1)

            text_report = report_service.generate_text_report(report)
            json_report = report_service.generate_json_report(report)

            if not text_report or not json_report:
                print("âŒ Report generation: FAILED")
                self.test_results.append(("Report Generation", False, "Report generation failed"))
                return False

            print("âœ… Output formats: PASSED")
            self.test_results.append(("Output Formats", True, "All formats working"))
            return True

        except Exception as e:
            print(f"âŒ Output formats: ERROR - {e}")
            self.test_results.append(("Output Formats", False, str(e)))
            return False

    def test_error_handling(self) -> bool:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\nğŸš¨ Testing error handling...")

        try:
            # æµ‹è¯•æ— æ•ˆé…ç½®
            invalid_config = {}
            is_valid, error = self.config_service.validate_config(invalid_config)

            if is_valid:
                print("âŒ Error handling: FAILED - Invalid config accepted")
                self.test_results.append(("Error Handling", False, "Invalid config accepted"))
                return False

            # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
            cmd = ["python", "-m", "pktmask", "info", "/nonexistent/file.pcap"]
            result = subprocess.run(cmd, cwd=project_root, capture_output=True, text=True, timeout=10)

            if result.returncode == 0:
                print("âŒ Error handling: FAILED - Nonexistent file not handled")
                self.test_results.append(("Error Handling", False, "Nonexistent file not handled"))
                return False

            print("âœ… Error handling: PASSED")
            self.test_results.append(("Error Handling", True, "Errors properly handled"))
            return True

        except Exception as e:
            print(f"âŒ Error handling: ERROR - {e}")
            self.test_results.append(("Error Handling", False, str(e)))
            return False

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š TEST REPORT")
        print("=" * 60)

        total_tests = len(self.test_results)
        passed_tests = sum(1 for _, passed, _ in self.test_results if passed)
        failed_tests = total_tests - passed_tests

        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests}")
        print(f"Failed: {failed_tests}")
        print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")

        print("\nDetailed Results:")
        print("-" * 40)

        for test_name, passed, message in self.test_results:
            status = "âœ… PASS" if passed else "âŒ FAIL"
            print(f"{status} {test_name}: {message}")

        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = self.temp_dir / "test_report.json"
        report_data = {
            "timestamp": str(Path(__file__).stat().st_mtime),
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "success_rate": (passed_tests / total_tests) * 100,
            "results": [
                {"test_name": name, "passed": passed, "message": message} for name, passed, message in self.test_results
            ],
        }

        with open(report_file, "w") as f:
            json.dump(report_data, f, indent=2)

        print(f"\nğŸ“„ Detailed report saved to: {report_file}")

        return failed_tests == 0

    def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ Starting PktMask Unified Functionality Tests")
        print("=" * 60)

        self.setup()

        try:
            tests = [
                self.test_config_consistency,
                self.test_service_layer,
                self.test_output_formats,
                self.test_cli_commands,
                self.test_error_handling,
            ]

            all_passed = True
            for test in tests:
                if not test():
                    all_passed = False

            success = self.generate_report()
            return success

        finally:
            self.teardown()


def main():
    """ä¸»å‡½æ•°"""
    tester = UnifiedFunctionalityTester()
    success = tester.run_all_tests()

    if success:
        print("\nğŸ‰ All tests passed! PktMask unified functionality is working correctly.")
        sys.exit(0)
    else:
        print("\nğŸ’¥ Some tests failed. Please check the detailed report above.")
        sys.exit(1)


if __name__ == "__main__":
    main()
