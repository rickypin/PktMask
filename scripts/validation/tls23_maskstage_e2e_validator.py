#!/usr/bin/env python3
"""
Enhanced TLS MaskStage ç«¯åˆ°ç«¯éªŒè¯å™¨ (Phase 3 å¢å¼ºç‰ˆ)

ä¸“é—¨ç”¨äºéªŒè¯Enhanced MaskStageçš„å®Œæ•´TLSåè®®ç±»å‹(20-24)æ©ç åŠŸèƒ½ï¼š
- TLS-20 (ChangeCipherSpec): å®Œå…¨ä¿ç•™éªŒè¯
- TLS-21 (Alert): å®Œå…¨ä¿ç•™éªŒè¯  
- TLS-22 (Handshake): å®Œå…¨ä¿ç•™éªŒè¯
- TLS-23 (ApplicationData): æ™ºèƒ½æ©ç éªŒè¯(5å­—èŠ‚å¤´éƒ¨ä¿ç•™)
- TLS-24 (Heartbeat): å®Œå…¨ä¿ç•™éªŒè¯

æ–°å¢éªŒè¯åŠŸèƒ½ï¼š
- å¤šåè®®ç±»å‹éªŒè¯ (validate_protocol_type_detection)
- è·¨TCPæ®µå¤„ç†éªŒè¯ (validate_cross_segment_handling)
- è¾¹ç•Œå®‰å…¨å¤„ç†éªŒè¯ (validate_boundary_safety)
- å®Œå…¨ä¿ç•™ç­–ç•¥éªŒè¯ (validate_complete_preservation)
- æ™ºèƒ½æ©ç ç­–ç•¥éªŒè¯ (validate_smart_masking)

Author: PktMask Core Team
Version: v2.0 (Phase 3 Day 15 å¢å¼ºç‰ˆ)
"""

import argparse
import json
import logging
import shutil
import subprocess
import sys
from glob import glob
from pathlib import Path
from typing import List, Dict, Any, Tuple

# -------------------------- æ—¥å¿—é…ç½® --------------------------
LOG_FORMAT = "[%(levelname)s] %(message)s"
logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)
logger = logging.getLogger("tls23_maskstage_e2e_validator")

# ---------------------- å¸¸é‡ä¸å·¥å…·å‡½æ•° ------------------------
DEFAULT_GLOB = "**/*.pcap,**/*.pcapng"
DEFAULT_OUTPUT_DIR = Path("output/tls23_maskstage_e2e")
PYTHON_EXEC = sys.executable


def run_cmd(cmd: List[str], verbose: bool = False) -> None:
    """æ‰§è¡Œå¤–éƒ¨å‘½ä»¤å¹¶å®æ—¶è¾“å‡ºã€‚å‡ºç°éé›¶é€€å‡ºç æ—¶æŠ›å‡º RuntimeError"""
    if verbose:
        logger.info("è¿è¡Œå‘½ä»¤: %s", " ".join(cmd))
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    if verbose and result.stdout:
        print(result.stdout)
    if result.returncode != 0:
        raise RuntimeError(f"Command failed ({result.returncode}): {' '.join(cmd)}\n{result.stdout}")


def run_enhanced_tls_marker(pcap_path: Path, output_dir: Path, types: str = "20,21,22,23,24", verbose: bool = False) -> Path:
    """è¿è¡Œå¢å¼ºç‰ˆTLSåè®®ç±»å‹æ£€æµ‹å·¥å…·ï¼Œè¿”å›JSONè¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    if verbose:
        logger.info("è¿è¡Œå¢å¼ºç‰ˆTLSåè®®ç±»å‹æ£€æµ‹: %s (ç±»å‹: %s)", pcap_path, types)
    
    try:
        run_cmd([
            PYTHON_EXEC,
            "-m",
            "pktmask.tools.enhanced_tls_marker",
            "--pcap",
            str(pcap_path),
            "--types",
            types,
            "--formats",
            "json",
            "--output-dir",
            str(output_dir),
        ], verbose)
        
        # è¿”å›ç”Ÿæˆçš„JSONæ–‡ä»¶è·¯å¾„
        pcap_stem = pcap_path.stem
        json_path = output_dir / f"{pcap_stem}_enhanced_tls_frames.json"
        
        if not json_path.exists():
            raise RuntimeError(f"å¢å¼ºç‰ˆTLSæ£€æµ‹æœªç”Ÿæˆé¢„æœŸçš„JSONæ–‡ä»¶: {json_path}")
            
        return json_path
        
    except Exception as e:
        raise RuntimeError(f"å¢å¼ºç‰ˆTLSåè®®ç±»å‹æ£€æµ‹å¤±è´¥: {e}")


def discover_files(input_dir: Path, pattern: str) -> List[Path]:
    """é€’å½’æ‰«æè¾“å…¥ç›®å½•ç¬¦åˆ glob æ¨¡å¼çš„æ–‡ä»¶ã€‚

    æ”¯æŒä»¥é€—å·æˆ–ç©ºæ ¼åˆ†éš”çš„å¤šä¸ª glob è¡¨è¾¾å¼ï¼Œä¾‹å¦‚
    "**/*.pcap,**/*.pcapng"ã€‚"""
    patterns = [p.strip() for p in pattern.replace(" ", ",").split(",") if p.strip()]
    matched: List[Path] = []
    for pat in patterns:
        matched.extend(Path(p) for p in glob(str(input_dir / pat), recursive=True))
    # å»é‡å¹¶ä»…ä¿ç•™æ–‡ä»¶
    unique_files = {p.resolve() for p in matched if p.is_file()}
    return [Path(p) for p in unique_files]


def read_json(path: Path) -> Any:
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def write_json(path: Path, data: Any) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def extract_frames(data: Any) -> List[Dict[str, Any]]:
    """æ ¹æ® tls23_marker è¾“å‡ºæ ¼å¼æå–å¸§åˆ—è¡¨ã€‚å°½é‡å…¼å®¹å¤šç§ç»“æ„"""
    if isinstance(data, list):
        return data
    if isinstance(data, dict):
        # æ–°ç‰ˆ schema ä½¿ç”¨ "matches"
        for key in ("frames", "records", "packets", "matches"):
            if key in data and isinstance(data[key], list):
                return data[key]
    return []


def is_zero_payload(frame: Dict[str, Any]) -> bool:
    """åˆ¤æ–­ frame æ˜¯å¦å·²å…¨éƒ¨ç½®é›¶ã€‚å…¼å®¹å¤šç§å­—æ®µæ ¼å¼ï¼š
    1) æ—§ç‰ˆ schema ä½¿ç”¨ payload_preview / data ç­‰åå…­è¿›åˆ¶å­—ç¬¦ä¸²
    2) æ–°ç‰ˆ schema ä½¿ç”¨ zero_bytes + lengths æ•°å­—ç»Ÿè®¡"""
    # --- æ–°ç‰ˆ numeric åˆ¤æ–­ ---
    if "zero_bytes" in frame:
        zb = frame.get("zero_bytes", 0)
        if "lengths" in frame and isinstance(frame["lengths"], list) and frame["lengths"]:
            total_len = sum(frame["lengths"])
            return zb >= total_len  # è‹¥ç½®é›¶å­—èŠ‚æ•°>=æ€»é•¿åº¦ï¼Œåˆ™è®¤ä¸ºå·²å…¨éƒ¨ç½®é›¶
        # æ²¡æœ‰ lengths å­—æ®µæ—¶ï¼Œè‹¥ zero_bytes>0 åˆ™è§†ä¸ºå·²ç½®é›¶ï¼ˆä¿å®ˆå‡è®¾ï¼‰
        return zb > 0

    # --- æ—§ç‰ˆå­—ç¬¦ä¸²åˆ¤æ–­ ---
    hex_fields = []
    for key in ("payload_preview", "data", "payload_hex", "payload"):
        if key in frame and isinstance(frame[key], str):
            hex_fields.append(frame[key])
    if not hex_fields:
        # æ— è½½è·å­—æ®µï¼Œè§†ä¸ºå·²ç½®é›¶ï¼ˆå¯èƒ½é•¿åº¦==0ï¼‰
        return True
    for hf in hex_fields:
        cleaned = hf.replace(" ", "").replace(":", "")
        if cleaned and set(cleaned) != {"0"}:
            return False
    return True


# ---------------------- ä¸»éªŒè¯é€»è¾‘ ----------------------------

def validate_file(original_json: Path, masked_json: Path) -> Dict[str, Any]:
    """æ¯”è¾ƒåŸå§‹ä¸æ©ç åçš„ tls23_marker JSON ç»“æœã€‚

    è¿”å›å­—æ®µè¯´æ˜ï¼š
    - status: pass / fail
    - total_records: TLS 23 æ¶ˆæ¯æ€»æ•°
    - masked_records: å®Œå…¨æˆåŠŸæ©ç çš„æ¶ˆæ¯æ•°
    - unmasked_records: æœªå®Œå…¨æ©ç çš„æ¶ˆæ¯æ•°
    - records_before / records_after: åŸå§‹ã€æ©ç æ–‡ä»¶æ£€æµ‹åˆ°çš„æ¶ˆæ¯æ•°
    - masked_ok_frames: å®Œå…¨æ©ç çš„å¸§å·åˆ—è¡¨
    - failed_frames: æœªå®Œå…¨æ©ç (ä»å«æ˜æ–‡å­—èŠ‚)çš„å¸§å·åˆ—è¡¨
    - failed_frame_details: æ©ç å¤±è´¥å¸§çš„ä¸»è¦ä¿¡æ¯
    """
    original_frames = extract_frames(read_json(original_json))
    masked_frames = extract_frames(read_json(masked_json))

    # ä½¿ç”¨ packet_number æˆ– frame å­—æ®µæ ‡è¯†å¸§
    def _get_frame_no(f: Dict[str, Any]) -> int:
        for k in ("packet_number", "frame", "frame_no", "no"):
            if k in f and isinstance(f[k], int):
                return f[k]
        return -1

    # æ„å»ºå¸§å·åˆ° frame å¯¹è±¡çš„æ˜ å°„ï¼Œä¾¿äºåç»­æ¯”è¾ƒ
    masked_by_no = { _get_frame_no(f): f for f in masked_frames }

    failed_frames: List[int] = []
    masked_ok_frames: List[int] = []
    failed_frame_details: List[Dict[str, Any]] = []

    for no, m_frame in masked_by_no.items():
        if no == -1:  # æ— æ³•è¯†åˆ«å¸§å·ï¼Œè·³è¿‡
            continue
        if is_zero_payload(m_frame):
            masked_ok_frames.append(no)
        else:
            failed_frames.append(no)
            # æ”¶é›†å…³é”®ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
            failed_frame_details.append({
                "frame": no,
                "path": m_frame.get("path"),
                "lengths": m_frame.get("lengths"),
                "zero_bytes": m_frame.get("zero_bytes"),
                "num_records": m_frame.get("num_records"),
                # å°è¯•æä¾›åå…­è¿›åˆ¶é¢„è§ˆï¼ˆè‹¥æœ‰ï¼‰
                "payload_preview": m_frame.get("payload_preview") or m_frame.get("data") or m_frame.get("payload_hex"),
            })

    total_records = len(masked_frames)
    masked_records = len(masked_ok_frames)
    unmasked_records = len(failed_frames)

    status = "pass" if unmasked_records == 0 else "fail"

    return {
        "status": status,
        "records_before": len(original_frames),
        "records_after": len(masked_frames),
        "total_records": total_records,
        "masked_records": masked_records,
        "unmasked_records": unmasked_records,
        "masked_ok_frames": sorted(masked_ok_frames),
        "failed_frames": sorted(failed_frames),
        "failed_frame_details": failed_frame_details,
    }


# ---------------------- å¢å¼ºéªŒè¯å‡½æ•° (Phase 3 Day 15) ------------------------

def validate_complete_preservation(original_json: Path, masked_json: Path, target_types: List[int] = [20, 21, 22, 24]) -> Dict[str, Any]:
    """éªŒè¯TLS-20/21/22/24å®Œå…¨ä¿ç•™ - åŸå§‹å’Œæ©ç åçš„æ•°æ®åº”è¯¥å®Œå…¨ä¸€è‡´"""
    logger.info("éªŒè¯å®Œå…¨ä¿ç•™ç­–ç•¥ (TLSç±»å‹: %s)", target_types)
    
    original_data = read_json(original_json)
    masked_data = read_json(masked_json)
    
    # æå–ç›®æ ‡ç±»å‹çš„è®°å½•
    original_matches = extract_frames(original_data)
    masked_matches = extract_frames(masked_data)
    
    # æŒ‰å¸§å·å»ºç«‹æ˜ å°„
    def _get_frame_no(f: Dict[str, Any]) -> int:
        for k in ("frame", "packet_number", "frame_no", "no"):
            if k in f and isinstance(f[k], int):
                return f[k]
        return -1
    
    original_by_frame = {_get_frame_no(f): f for f in original_matches}
    masked_by_frame = {_get_frame_no(f): f for f in masked_matches}
    
    preservation_results = []
    total_target_records = 0
    preserved_records = 0
    
    for frame_no, orig_frame in original_by_frame.items():
        if frame_no == -1:
            continue
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡ç±»å‹
        orig_types = orig_frame.get("protocol_types", [])
        if not isinstance(orig_types, list):
            orig_types = [orig_types] if orig_types is not None else []
        
        target_found = any(t in target_types for t in orig_types)
        if not target_found:
            continue
            
        total_target_records += 1
        
        # æ£€æŸ¥æ©ç åæ˜¯å¦å­˜åœ¨
        masked_frame = masked_by_frame.get(frame_no)
        if not masked_frame:
            preservation_results.append({
                "frame": frame_no,
                "status": "missing",
                "reason": "æ©ç åå¸§ä¸¢å¤±"
            })
            continue
        
        # æ¯”è¾ƒå…³é”®å±æ€§
        preserved = True
        differences = []
        
        # æ¯”è¾ƒåè®®ç±»å‹
        masked_types = masked_frame.get("protocol_types", [])
        if not isinstance(masked_types, list):
            masked_types = [masked_types] if masked_types is not None else []
            
        if orig_types != masked_types:
            preserved = False
            differences.append(f"åè®®ç±»å‹ä¸ä¸€è‡´: {orig_types} -> {masked_types}")
        
        # æ¯”è¾ƒè®°å½•é•¿åº¦
        orig_lengths = orig_frame.get("lengths", [])
        masked_lengths = masked_frame.get("lengths", [])
        if orig_lengths != masked_lengths:
            preserved = False
            differences.append(f"è®°å½•é•¿åº¦ä¸ä¸€è‡´: {orig_lengths} -> {masked_lengths}")
        
        # æ¯”è¾ƒè½½è·æ•°æ®ï¼ˆå¯¹äºå®Œå…¨ä¿ç•™ç±»å‹ï¼Œåº”è¯¥å®Œå…¨ç›¸åŒï¼‰
        for field in ["payload_preview", "data", "payload_hex"]:
            orig_payload = orig_frame.get(field)
            masked_payload = masked_frame.get(field)
            if orig_payload and masked_payload and orig_payload != masked_payload:
                preserved = False
                differences.append(f"{field}ä¸ä¸€è‡´")
                break
        
        if preserved:
            preserved_records += 1
            preservation_results.append({
                "frame": frame_no,
                "status": "preserved",
                "protocol_types": orig_types
            })
        else:
            preservation_results.append({
                "frame": frame_no, 
                "status": "modified",
                "protocol_types": orig_types,
                "differences": differences
            })
    
    preservation_rate = (preserved_records / total_target_records * 100) if total_target_records > 0 else 0
    
    return {
        "total_target_records": total_target_records,
        "preserved_records": preserved_records, 
        "preservation_rate": round(preservation_rate, 2),
        "status": "pass" if preservation_rate >= 95.0 else "fail",
        "details": preservation_results
    }


def validate_smart_masking(original_json: Path, masked_json: Path, target_type: int = 23, header_bytes: int = 5) -> Dict[str, Any]:
    """éªŒè¯TLS-23æ™ºèƒ½æ©ç ï¼ˆä¿ç•™æŒ‡å®šå­—èŠ‚å¤´éƒ¨ï¼Œæ©ç å…¶ä½™è½½è·ï¼‰"""
    logger.info("éªŒè¯æ™ºèƒ½æ©ç ç­–ç•¥ (TLS-%d, å¤´éƒ¨ä¿ç•™: %då­—èŠ‚)", target_type, header_bytes)
    
    original_data = read_json(original_json)
    masked_data = read_json(masked_json)
    
    original_matches = extract_frames(original_data)
    masked_matches = extract_frames(masked_data)
    
    def _get_frame_no(f: Dict[str, Any]) -> int:
        for k in ("frame", "packet_number", "frame_no", "no"):
            if k in f and isinstance(f[k], int):
                return f[k]
        return -1
    
    def _is_smart_masked(frame: Dict[str, Any], header_bytes: int) -> bool:
        """åˆ¤æ–­å¸§æ˜¯å¦æ­£ç¡®åº”ç”¨äº†æ™ºèƒ½æ©ç ï¼ˆå¤´éƒ¨ä¿ç•™ï¼Œè½½è·æ©ç ï¼‰"""
        # æ£€æŸ¥ zero_bytes å’Œ lengths å­—æ®µ
        if "zero_bytes" in frame and "lengths" in frame:
            zero_bytes = frame.get("zero_bytes", 0)
            lengths = frame.get("lengths", [])
            if isinstance(lengths, list) and lengths:
                total_length = sum(lengths)
                expected_masked_bytes = total_length - header_bytes
                # å¦‚æœç½®é›¶å­—èŠ‚æ•°æ¥è¿‘æœŸæœ›çš„æ©ç å­—èŠ‚æ•°ï¼ˆå…è®¸ä¸€å®šè¯¯å·®ï¼‰
                return abs(zero_bytes - expected_masked_bytes) <= 5
        
        # å›é€€åˆ°å­—ç¬¦ä¸²æ£€æŸ¥
        hex_fields = []
        for key in ("payload_preview", "data", "payload_hex", "payload"):
            if key in frame and isinstance(frame[key], str):
                hex_fields.append(frame[key])
        
        if hex_fields:
            for hf in hex_fields:
                cleaned = hf.replace(" ", "").replace(":", "")
                if len(cleaned) >= header_bytes * 2:  # æ¯å­—èŠ‚2ä¸ªåå…­è¿›åˆ¶å­—ç¬¦
                    header_part = cleaned[:header_bytes * 2]
                    payload_part = cleaned[header_bytes * 2:]
                    # å¤´éƒ¨ä¸åº”å…¨ä¸ºé›¶ï¼Œè½½è·éƒ¨åˆ†åº”å¤§éƒ¨åˆ†ä¸ºé›¶
                    header_not_all_zero = set(header_part) != {"0"}
                    payload_mostly_zero = payload_part.count("0") / len(payload_part) > 0.8 if payload_part else True
                    return header_not_all_zero and payload_mostly_zero
        
        return False
    
    original_by_frame = {_get_frame_no(f): f for f in original_matches}
    masked_by_frame = {_get_frame_no(f): f for f in masked_matches}
    
    masking_results = []
    total_target_records = 0
    correctly_masked_records = 0
    
    for frame_no, orig_frame in original_by_frame.items():
        if frame_no == -1:
            continue
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡ç±»å‹
        orig_types = orig_frame.get("protocol_types", [])
        if not isinstance(orig_types, list):
            orig_types = [orig_types] if orig_types is not None else []
        
        if target_type not in orig_types:
            continue
            
        total_target_records += 1
        
        # æ£€æŸ¥æ©ç åæ˜¯å¦å­˜åœ¨
        masked_frame = masked_by_frame.get(frame_no)
        if not masked_frame:
            masking_results.append({
                "frame": frame_no,
                "status": "missing",
                "reason": "æ©ç åå¸§ä¸¢å¤±"
            })
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®åº”ç”¨äº†æ™ºèƒ½æ©ç ï¼ˆå¤´éƒ¨ä¿ç•™ï¼Œè½½è·å¤§éƒ¨åˆ†ç½®é›¶ï¼‰
        is_correctly_masked = _is_smart_masked(masked_frame, header_bytes)
        
        if is_correctly_masked:
            correctly_masked_records += 1
            masking_results.append({
                "frame": frame_no,
                "status": "correctly_masked",
                "protocol_types": orig_types
            })
        else:
            masking_results.append({
                "frame": frame_no,
                "status": "incorrectly_masked", 
                "protocol_types": orig_types,
                "reason": "è½½è·æœªæ­£ç¡®æ©ç "
            })
    
    masking_rate = (correctly_masked_records / total_target_records * 100) if total_target_records > 0 else 0
    
    return {
        "total_target_records": total_target_records,
        "correctly_masked_records": correctly_masked_records,
        "masking_rate": round(masking_rate, 2),
        "status": "pass" if masking_rate >= 95.0 else "fail",
        "details": masking_results
    }


def validate_cross_segment_handling(original_json: Path, masked_json: Path) -> Dict[str, Any]:
    """éªŒè¯è·¨TCPæ®µå¤„ç†æ­£ç¡®æ€§ - æ£€æŸ¥æµçº§åˆ«çš„å¤„ç†ä¸€è‡´æ€§"""
    logger.info("éªŒè¯è·¨TCPæ®µå¤„ç†æ­£ç¡®æ€§")
    
    original_data = read_json(original_json)
    masked_data = read_json(masked_json)
    
    original_matches = extract_frames(original_data)
    masked_matches = extract_frames(masked_data)
    
    # æŒ‰TCPæµåˆ†ç»„
    def _get_stream_info(f: Dict[str, Any]) -> Tuple[str, int]:
        path = f.get("path", "")
        frame_no = f.get("frame", f.get("packet_number", -1))
        
        # ä»pathä¸­æå–TCPæµä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if "tcp" in path.lower():
            return ("tcp_stream", frame_no)
        return ("unknown_stream", frame_no)
    
    # åˆ†ææµçº§åˆ«çš„ä¸€è‡´æ€§
    stream_analysis = {}
    
    for orig_frame in original_matches:
        stream_id, frame_no = _get_stream_info(orig_frame)
        if stream_id not in stream_analysis:
            stream_analysis[stream_id] = {"original": [], "masked": []}
        stream_analysis[stream_id]["original"].append((frame_no, orig_frame))
    
    for masked_frame in masked_matches:
        stream_id, frame_no = _get_stream_info(masked_frame)
        if stream_id in stream_analysis:
            stream_analysis[stream_id]["masked"].append((frame_no, masked_frame))
    
    cross_segment_results = []
    total_streams = len(stream_analysis)
    consistent_streams = 0
    
    for stream_id, stream_data in stream_analysis.items():
        original_frames = sorted(stream_data["original"], key=lambda x: x[0])
        masked_frames = sorted(stream_data["masked"], key=lambda x: x[0])
        
        # æ£€æŸ¥å¸§æ•°é‡ä¸€è‡´æ€§
        if len(original_frames) != len(masked_frames):
            cross_segment_results.append({
                "stream": stream_id,
                "status": "inconsistent",
                "reason": f"å¸§æ•°é‡ä¸ä¸€è‡´: {len(original_frames)} -> {len(masked_frames)}"
            })
            continue
        
        # æ£€æŸ¥å¸§åºåˆ—ä¸€è‡´æ€§
        frame_consistency = True
        for (orig_no, orig_frame), (masked_no, masked_frame) in zip(original_frames, masked_frames):
            if orig_no != masked_no:
                frame_consistency = False
                break
        
        if frame_consistency:
            consistent_streams += 1
            cross_segment_results.append({
                "stream": stream_id,
                "status": "consistent",
                "frame_count": len(original_frames)
            })
        else:
            cross_segment_results.append({
                "stream": stream_id,
                "status": "inconsistent",
                "reason": "å¸§åºåˆ—ä¸ä¸€è‡´"
            })
    
    consistency_rate = (consistent_streams / total_streams * 100) if total_streams > 0 else 0
    
    return {
        "total_streams": total_streams,
        "consistent_streams": consistent_streams,
        "consistency_rate": round(consistency_rate, 2),
        "status": "pass" if consistency_rate >= 90.0 else "fail",
        "details": cross_segment_results
    }


def validate_protocol_type_detection(original_json: Path, target_types: List[int] = [20, 21, 22, 23, 24]) -> Dict[str, Any]:
    """éªŒè¯åè®®ç±»å‹è¯†åˆ«å‡†ç¡®æ€§ - æ£€æŸ¥æ˜¯å¦æ­£ç¡®è¯†åˆ«æ‰€æœ‰ç›®æ ‡TLSåè®®ç±»å‹"""
    logger.info("éªŒè¯åè®®ç±»å‹è¯†åˆ«å‡†ç¡®æ€§ (ç›®æ ‡ç±»å‹: %s)", target_types)
    
    original_data = read_json(original_json)
    original_matches = extract_frames(original_data)
    
    detected_types = set()
    type_counts = {}
    frame_type_details = []
    
    for frame in original_matches:
        frame_no = frame.get("frame", frame.get("packet_number", -1))
        protocol_types = frame.get("protocol_types", [])
        
        if not isinstance(protocol_types, list):
            protocol_types = [protocol_types] if protocol_types is not None else []
        
        for ptype in protocol_types:
            if isinstance(ptype, int) and ptype in target_types:
                detected_types.add(ptype)
                type_counts[ptype] = type_counts.get(ptype, 0) + 1
                
        if protocol_types:
            frame_type_details.append({
                "frame": frame_no,
                "detected_types": protocol_types
            })
    
    # è®¡ç®—æ£€æµ‹å®Œæ•´æ€§
    missing_types = set(target_types) - detected_types
    detection_completeness = (len(detected_types) / len(target_types) * 100) if target_types else 0
    
    return {
        "target_types": target_types,
        "detected_types": sorted(list(detected_types)),
        "missing_types": sorted(list(missing_types)),
        "type_counts": type_counts,
        "detection_completeness": round(detection_completeness, 2),
        "status": "pass" if detection_completeness >= 80.0 else "fail",
        "frame_details": frame_type_details[:10]  # é™åˆ¶è¾“å‡ºæ•°é‡
    }


def validate_boundary_safety(original_json: Path, masked_json: Path) -> Dict[str, Any]:
    """éªŒè¯è¾¹ç•Œå®‰å…¨å¤„ç† - æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¾¹ç•Œè¿è§„æˆ–æ•°æ®æŸå"""
    logger.info("éªŒè¯è¾¹ç•Œå®‰å…¨å¤„ç†")
    
    original_data = read_json(original_json) 
    masked_data = read_json(masked_json)
    
    original_matches = extract_frames(original_data)
    masked_matches = extract_frames(masked_data)
    
    def _get_frame_no(f: Dict[str, Any]) -> int:
        for k in ("frame", "packet_number", "frame_no", "no"):
            if k in f and isinstance(f[k], int):
                return f[k]
        return -1
    
    original_by_frame = {_get_frame_no(f): f for f in original_matches}
    masked_by_frame = {_get_frame_no(f): f for f in masked_matches}
    
    boundary_issues = []
    safe_frames = 0
    total_frames = len(original_by_frame)
    
    for frame_no, orig_frame in original_by_frame.items():
        if frame_no == -1:
            continue
            
        masked_frame = masked_by_frame.get(frame_no)
        if not masked_frame:
            boundary_issues.append({
                "frame": frame_no,
                "issue": "frame_missing",
                "description": "æ©ç å¤„ç†åå¸§ä¸¢å¤±"
            })
            continue
        
        # æ£€æŸ¥è®°å½•é•¿åº¦ä¸€è‡´æ€§
        orig_lengths = orig_frame.get("lengths", [])
        masked_lengths = masked_frame.get("lengths", [])
        
        if len(orig_lengths) != len(masked_lengths):
            boundary_issues.append({
                "frame": frame_no,
                "issue": "length_mismatch",
                "description": f"è®°å½•æ•°é‡å˜åŒ–: {len(orig_lengths)} -> {len(masked_lengths)}"
            })
            continue
        
        # æ£€æŸ¥é•¿åº¦å€¼å¼‚å¸¸å˜åŒ–
        length_issues = []
        for i, (orig_len, masked_len) in enumerate(zip(orig_lengths, masked_lengths)):
            if orig_len != masked_len:
                length_issues.append(f"è®°å½•{i}: {orig_len} -> {masked_len}")
        
        if length_issues:
            boundary_issues.append({
                "frame": frame_no,
                "issue": "length_change", 
                "description": f"è®°å½•é•¿åº¦å˜åŒ–: {'; '.join(length_issues)}"
            })
            continue
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¼‚å¸¸çš„é›¶å­—èŠ‚è®¡æ•°
        orig_zero_bytes = orig_frame.get("zero_bytes", 0)
        masked_zero_bytes = masked_frame.get("zero_bytes", 0)
        
        # æ©ç åé›¶å­—èŠ‚æ•°åº”è¯¥å¢åŠ ï¼ˆç”¨äºTLS-23ï¼‰æˆ–ä¿æŒä¸å˜ï¼ˆç”¨äºå…¶ä»–ç±»å‹ï¼‰
        if masked_zero_bytes < orig_zero_bytes:
            boundary_issues.append({
                "frame": frame_no,
                "issue": "zero_bytes_decrease",
                "description": f"é›¶å­—èŠ‚æ•°å¼‚å¸¸å‡å°‘: {orig_zero_bytes} -> {masked_zero_bytes}"
            })
            continue
        
        safe_frames += 1
    
    safety_rate = (safe_frames / total_frames * 100) if total_frames > 0 else 0
    
    return {
        "total_frames": total_frames,
        "safe_frames": safe_frames,
        "boundary_issues": len(boundary_issues),
        "safety_rate": round(safety_rate, 2),
        "status": "pass" if safety_rate >= 95.0 else "fail",
        "issue_details": boundary_issues[:10]  # é™åˆ¶è¾“å‡ºæ•°é‡
    }


def validate_enhanced_tls_processing(original_json: Path, masked_json: Path) -> Dict[str, Any]:
    """ç»¼åˆéªŒè¯å¢å¼ºTLSå¤„ç†ç»“æœ - é›†æˆæ‰€æœ‰éªŒè¯åŠŸèƒ½"""
    logger.info("å¼€å§‹ç»¼åˆéªŒè¯å¢å¼ºTLSå¤„ç†ç»“æœ")
    
    results = {}
    
    # 1. éªŒè¯TLS-20/21/22/24å®Œå…¨ä¿ç•™
    results["complete_preservation"] = validate_complete_preservation(original_json, masked_json, [20, 21, 22, 24])
    
    # 2. éªŒè¯TLS-23æ™ºèƒ½æ©ç ï¼ˆ5å­—èŠ‚å¤´éƒ¨ä¿ç•™ï¼‰
    results["smart_masking"] = validate_smart_masking(original_json, masked_json, 23, 5)
    
    # 3. éªŒè¯è·¨TCPæ®µå¤„ç†æ­£ç¡®æ€§
    results["cross_segment_handling"] = validate_cross_segment_handling(original_json, masked_json)
    
    # 4. éªŒè¯åè®®ç±»å‹è¯†åˆ«å‡†ç¡®æ€§
    results["protocol_type_detection"] = validate_protocol_type_detection(original_json, [20, 21, 22, 23, 24])
    
    # 5. éªŒè¯è¾¹ç•Œå®‰å…¨å¤„ç†
    results["boundary_safety"] = validate_boundary_safety(original_json, masked_json)
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    test_scores = []
    for test_name, test_result in results.items():
        if test_result.get("status") == "pass":
            test_scores.append(100)
        else:
            # æ ¹æ®å…·ä½“æŒ‡æ ‡è®¡ç®—åˆ†æ•°
            if "rate" in test_result:
                rate_key = [k for k in test_result.keys() if k.endswith("_rate")][0]
                test_scores.append(test_result[rate_key])
            else:
                test_scores.append(0)
    
    overall_score = sum(test_scores) / len(test_scores) if test_scores else 0
    overall_status = "pass" if overall_score >= 80.0 else "fail"
    
    results["overall"] = {
        "score": round(overall_score, 2),
        "status": overall_status,
        "passed_tests": sum(1 for r in results.values() if r.get("status") == "pass"),
        "total_tests": 5  # 5ä¸ªéªŒè¯å‡½æ•°ï¼šå®Œå…¨ä¿ç•™ã€æ™ºèƒ½æ©ç ã€è·¨æ®µå¤„ç†ã€åè®®ç±»å‹æ£€æµ‹ã€è¾¹ç•Œå®‰å…¨
    }
    
    return results


# ---------------------- MaskStage å¤„ç†å‡½æ•° --------------------------

def run_maskstage_internal(input_path: Path, output_path: Path, verbose: bool = False) -> None:
    """ä½¿ç”¨Enhanced MaskStageå¤„ç†æ–‡ä»¶ï¼ˆé€šè¿‡PipelineExecutorï¼‰"""
    if verbose:
        logger.info("ä½¿ç”¨ Enhanced MaskStage å¤„ç†: %s -> %s", input_path, output_path)

    try:
        from pktmask.core.pipeline.executor import PipelineExecutor
        from pktmask.core.pipeline.stages.mask_payload.stage import MaskStage
    except ImportError as imp_err:
        raise RuntimeError(f"æ— æ³•å¯¼å…¥ Enhanced MaskStage: {imp_err}")

    # é…ç½®Enhanced MaskStageå¤„ç†ï¼ˆProcessor Adapter æ¨¡å¼ï¼‰
    config = {
        "dedup": {"enabled": False},
        "anon": {"enabled": False}, 
        "mask": {
            "enabled": True,
            "mode": "processor_adapter",  # ä½¿ç”¨å¤„ç†å™¨é€‚é…å™¨æ¨¡å¼
            "preserve_ratio": 0.3,
            "tls_strategy_enabled": True,
            "enable_tshark_preprocessing": True
        }
    }

    try:
        # åˆ›å»ºPipelineExecutorå¹¶æ‰§è¡Œ
        executor = PipelineExecutor(config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ‰§è¡Œå¤„ç†
        stats = executor.run(str(input_path), str(output_path))
        
        if verbose:
            logger.info("Enhanced MaskStage å¤„ç†å®Œæˆ: %s", stats)
            
    except Exception as e:
        raise RuntimeError(f"Enhanced MaskStage å¤„ç†å¤±è´¥: {e}")


def run_maskstage_direct(input_path: Path, output_path: Path, verbose: bool = False) -> None:
    """ç›´æ¥ä½¿ç”¨Enhanced MaskStageå¤„ç†æ–‡ä»¶ï¼ˆä¸é€šè¿‡PipelineExecutorï¼‰"""
    if verbose:
        logger.info("ç›´æ¥ä½¿ç”¨ Enhanced MaskStage å¤„ç†: %s -> %s", input_path, output_path)

    try:
        from pktmask.core.pipeline.stages.mask_payload.stage import MaskStage
    except ImportError as imp_err:
        raise RuntimeError(f"æ— æ³•å¯¼å…¥ Enhanced MaskStage: {imp_err}")

    # é…ç½®Enhanced MaskStageï¼ˆProcessor Adapter æ¨¡å¼ï¼‰
    config = {
        "mode": "processor_adapter",  # ä½¿ç”¨å¤„ç†å™¨é€‚é…å™¨æ¨¡å¼
        "preserve_ratio": 0.3,
        "tls_strategy_enabled": True,
        "enable_tshark_preprocessing": True
    }

    try:
        # åˆ›å»ºå¹¶åˆå§‹åŒ–MaskStage
        mask_stage = MaskStage(config)
        mask_stage.initialize()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ‰§è¡Œå¤„ç†
        stats = mask_stage.process_file(input_path, output_path)
        
        if verbose:
            logger.info("Enhanced MaskStage ç›´æ¥å¤„ç†å®Œæˆ: %s", stats)
            
    except Exception as e:
        raise RuntimeError(f"Enhanced MaskStage ç›´æ¥å¤„ç†å¤±è´¥: {e}")


# -------------------------- CLI -------------------------------

def main() -> None:
    parser = argparse.ArgumentParser(
        description="TLS23 MaskStage ç«¯åˆ°ç«¯æ©ç éªŒè¯è„šæœ¬ (åŸºäº tls23_marker + Enhanced MaskStage)",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("--input-dir", type=Path, required=True, help="é€’å½’æ‰«æ PCAP/PCAPNG çš„ç›®å½•")
    parser.add_argument("--output-dir", type=Path, default=DEFAULT_OUTPUT_DIR, help="ç»“æœè¾“å‡ºç›®å½•")
    parser.add_argument("--maskstage-mode", default="pipeline", choices=["pipeline", "direct"], 
                       help="MaskStageè°ƒç”¨æ¨¡å¼ï¼špipeline(é€šè¿‡PipelineExecutor) æˆ– direct(ç›´æ¥è°ƒç”¨)")
    parser.add_argument("--glob", dest="glob_pattern", default=DEFAULT_GLOB, help="æ–‡ä»¶åŒ¹é… glob è¡¨è¾¾å¼")
    parser.add_argument("--verbose", action="store_true", help="è¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯")

    args = parser.parse_args()

    input_dir: Path = args.input_dir
    output_dir: Path = args.output_dir
    maskstage_mode: str = args.maskstage_mode
    glob_pattern: str = args.glob_pattern
    verbose: bool = args.verbose

    # ä¸“ç”¨ç›®å½•ä¿å­˜æ©ç åçš„ PCAP
    masked_dir: Path = output_dir / "masked_pcaps"
    masked_dir.mkdir(parents=True, exist_ok=True)

    files = discover_files(input_dir, glob_pattern)
    if not files:
        logger.error("è¾“å…¥ç›®å½•æ— åŒ¹é…æ–‡ä»¶: %s", input_dir)
        sys.exit(2)

    results = []
    passed_files = 0

    logger.info("å¼€å§‹TLS23 MaskStageç«¯åˆ°ç«¯éªŒè¯ï¼Œä½¿ç”¨æ¨¡å¼: %s", maskstage_mode)

    for pcap_path in files:
        stem = pcap_path.stem
        suffix = pcap_path.suffix  # .pcap / .pcapng
        orig_json = output_dir / f"{stem}_orig_tls23.json"
        masked_json = output_dir / f"{stem}_masked_tls23.json"

        try:
            # ---------- ç¬¬ä¸€æ¬¡æ‰«æ ----------
            run_cmd(
                [
                    PYTHON_EXEC,
                    "-m",
                    "pktmask.tools.tls23_marker",
                    "--pcap",
                    str(pcap_path),
                    "--no-annotate",
                    "--formats",
                    "json",
                    "--output-dir",
                    str(output_dir),
                ],
                verbose,
            )
            # ç§»åŠ¨æ–‡ä»¶ä¸º _orig_tls23.json
            tmp_json = output_dir / f"{stem}_tls23_frames.json"
            if tmp_json.exists():
                shutil.move(tmp_json, orig_json)

            # ---------- è°ƒç”¨ Enhanced MaskStage è¿›è¡Œæ©ç  ----------
            masked_file = masked_dir / f"{stem}_masked{suffix}"
            
            if maskstage_mode == "pipeline":
                run_maskstage_internal(pcap_path, masked_file, verbose)
            else:  # direct
                run_maskstage_direct(pcap_path, masked_file, verbose)

            # ---------- ç¬¬äºŒæ¬¡æ‰«æ ----------
            run_cmd(
                [
                    PYTHON_EXEC,
                    "-m",
                    "pktmask.tools.tls23_marker",
                    "--pcap",
                    str(masked_file),
                    "--no-annotate",
                    "--formats",
                    "json",
                    "--output-dir",
                    str(output_dir),
                ],
                verbose,
            )
            tmp_json_masked = output_dir / f"{stem}_masked_tls23_frames.json"
            # å¦‚æœ tls23_marker ä»ç„¶ä½¿ç”¨ _tls23_frames.json å‘½åï¼Œåˆ™å…¼å®¹å¤„ç†
            if not tmp_json_masked.exists():
                generic_tmp = output_dir / f"{stem}_tls23_frames.json"
                if generic_tmp.exists():
                    tmp_json_masked = generic_tmp
            if tmp_json_masked.exists():
                shutil.move(tmp_json_masked, masked_json)

            # ---------- éªŒè¯ç»“æœ ----------
            file_result = validate_file(orig_json, masked_json)
            file_result["file"] = pcap_path.name
            file_result["maskstage_mode"] = maskstage_mode
            results.append(file_result)

            if file_result["status"] == "pass":
                passed_files += 1
                logger.info("âœ… %s - é€šè¿‡ (MaskStage %s)", pcap_path.name, maskstage_mode)
            else:
                logger.warning("âŒ %s - å¤±è´¥ (MaskStage %s)", pcap_path.name, maskstage_mode)

        except Exception as e:
            logger.error("å¤„ç†æ–‡ä»¶ %s æ—¶å‡ºé”™: %s", pcap_path, e)
            results.append({
                "file": pcap_path.name,
                "status": "error",
                "error": str(e),
                "maskstage_mode": maskstage_mode,
            })

    overall_pass_rate = (passed_files / len(files)) * 100
    summary = {
        "overall_pass_rate": round(overall_pass_rate, 2),
        "files": results
    }
    write_json(output_dir / "validation_summary.json", summary)

    # ç”Ÿæˆ HTML æŠ¥å‘Š
    write_html_report(summary, output_dir / "validation_summary.html")

    logger.info("ğŸ“Š MaskStage (%s) Overall Pass Rate: %.2f%%", maskstage_mode, overall_pass_rate)

    # é€€å‡ºç 
    if passed_files == len(files):
        sys.exit(0)
    else:
        sys.exit(1)


def write_html_report(summary: Dict[str, Any], output_path: Path) -> None:
    """æ ¹æ® summary ç”Ÿæˆäººç±»å¯è¯»çš„ HTML æŠ¥å‘Š"""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # ç®€å•å†…è”æ ·å¼ï¼Œé¿å…å¤–éƒ¨ä¾èµ–
    style = (
        "body{font-family:Arial,Helvetica,sans-serif;margin:20px;}"
        "h1{font-size:24px;} table{border-collapse:collapse;width:100%;}"  
        "th,td{border:1px solid #ddd;padding:8px;} th{background:#f4f4f4;}"  
        "tr.pass{background:#e8f7e4;} tr.fail{background:#fdecea;}"  
        "code{background:#f4f4f4;padding:2px 4px;border-radius:4px;}"  
    )

    rows_html = []
    for f in summary.get("files", []):
        status = f.get("status")
        cls = "pass" if status == "pass" else "fail"
        rows_html.append(
            f"<tr class='{cls}'>"
            f"<td>{f.get('file')}</td>"
            f"<td>{status}</td>"
            f"<td>{f.get('total_records','-')}</td>"
            f"<td>{f.get('masked_records','-')}</td>"
            f"<td>{f.get('unmasked_records','-')}</td>"
            f"</tr>"
        )
        # è‹¥å¤±è´¥åˆ™æ·»åŠ è¯¦æƒ…è¡Œï¼Œå¯æŠ˜å  <details>
        if status != "pass" and f.get("failed_frame_details"):
            detail_lines = []
            for d in f["failed_frame_details"]:
                frame = d.get("frame")
                path = d.get("path")
                zero = d.get("zero_bytes")
                lens = d.get("lengths")
                preview = (d.get("payload_preview") or "").replace("<", "&lt;")
                detail_lines.append(
                    f"<li>å¸§ <code>{frame}</code> | path=<code>{path}</code> | lengths={lens} | zero_bytes={zero} | payload_preview=<code>{preview}</code></li>"
                )
            details_html = "<details><summary>å¤±è´¥å¸§è¯¦æƒ…</summary><ul>" + "\n".join(detail_lines) + "</ul></details>"
            rows_html.append(f"<tr class='{cls}'><td colspan='5'>" + details_html + "</td></tr>")

    html = (
        "<!DOCTYPE html><html><head><meta charset='utf-8'>"  
        f"<title>TLS23 Validation Report</title><style>{style}</style></head><body>"  
        f"<h1>TLS23 Validation Report</h1>"  
        f"<p>Overall Pass Rate: <strong>{summary.get('overall_pass_rate')}%</strong></p>"  
        "<table><thead><tr><th>File</th><th>Status</th><th>Total Records</th><th>Masked</th><th>Unmasked</th></tr></thead><tbody>"  
        + "\n".join(rows_html) + "</tbody></table>"  
        "</body></html>"
    )

    output_path.write_text(html, encoding="utf-8")


if __name__ == "__main__":
    try:
        main()
    except Exception as exc:
        logger.exception("è¿è¡Œæ—¶å¼‚å¸¸: %s", exc)
        sys.exit(3) 