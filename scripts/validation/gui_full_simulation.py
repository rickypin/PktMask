#!/usr/bin/env python3
"""
GUIå®Œæ•´è°ƒç”¨é“¾æ¨¡æ‹Ÿå™¨

å®Œå…¨æ¨¡æ‹ŸGUIå®é™…è¿è¡Œæ—¶çš„è°ƒç”¨é“¾ï¼ŒåŒ…æ‹¬ServicePipelineThreadå’Œprocess_directory
ä¸¥æ ¼ç¦æ­¢ä¿®æ”¹ä¸»ç¨‹åºä»£ç ï¼Œä»…ç”¨äºéªŒè¯åˆ†æã€‚

Author: PktMask Core Team
Version: v1.0 (GUIå®Œæ•´è°ƒç”¨é“¾æ¨¡æ‹Ÿä¸“ç”¨)
"""

import sys
import logging
import tempfile
from pathlib import Path
from typing import Dict, Any, List

# Add src directory to Python path
script_dir = Path(__file__).parent.absolute()
project_root = script_dir.parent.parent
src_path = project_root / "src"
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format="[%(levelname)s] %(message)s")
logger = logging.getLogger("gui_full_simulation")

class ProgressCollector:
    """è¿›åº¦äº‹ä»¶æ”¶é›†å™¨"""
    
    def __init__(self):
        self.events = []
        self.log_messages = []
        self.step_summaries = []
    
    def collect_event(self, event_type, data):
        """æ”¶é›†è¿›åº¦äº‹ä»¶"""
        if hasattr(event_type, 'value'):
            event_type_str = event_type.value
        else:
            event_type_str = str(event_type)
        
        event_entry = {
            "event_type": event_type_str,
            "data": data
        }
        self.events.append(event_entry)
        
        # ç‰¹åˆ«å¤„ç†LOGå’ŒSTEP_SUMMARYäº‹ä»¶
        if event_type_str == "LOG" and "message" in data:
            self.log_messages.append(data["message"])
            logger.info(f"LOG: {data['message']}")
        elif event_type_str == "STEP_SUMMARY":
            self.step_summaries.append(data)
            logger.info(f"STEP_SUMMARY: {data}")

def simulate_gui_full_pipeline(test_file: Path) -> Dict[str, Any]:
    """å®Œå…¨æ¨¡æ‹ŸGUIçš„å®Œæ•´è°ƒç”¨é“¾"""
    logger.info(f"æ¨¡æ‹ŸGUIå®Œæ•´è°ƒç”¨é“¾: {test_file}")
    
    try:
        from pktmask.services.pipeline_service import build_pipeline_config, create_pipeline_executor, process_directory
        from pktmask.core.events import PipelineEvents
        
        # åˆ›å»ºè¿›åº¦æ”¶é›†å™¨
        progress_collector = ProgressCollector()
        
        # æ„å»ºGUIé…ç½®ï¼ˆå®Œå…¨æ¨¡æ‹ŸGUIçš„é…ç½®ï¼‰
        config = build_pipeline_config(
            enable_anon=True,
            enable_dedup=True,
            enable_mask=True
        )
        logger.info(f"GUIé…ç½®: {config}")
        
        # åˆ›å»ºæ‰§è¡Œå™¨ï¼ˆå®Œå…¨æ¨¡æ‹ŸGUIçš„æ‰§è¡Œå™¨åˆ›å»ºï¼‰
        executor = create_pipeline_executor(config)
        logger.info(f"æ‰§è¡Œå™¨åˆ›å»ºæˆåŠŸï¼ŒåŒ…å«stages: {[stage.name for stage in executor.stages]}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•æ¨¡æ‹ŸGUIçš„è¾“å…¥è¾“å‡ºç›®å½•
        with tempfile.TemporaryDirectory(prefix="gui_full_sim_") as temp_dir:
            temp_path = Path(temp_dir)
            
            # åˆ›å»ºè¾“å…¥ç›®å½•å¹¶å¤åˆ¶æµ‹è¯•æ–‡ä»¶
            input_dir = temp_path / "input"
            input_dir.mkdir()
            input_file = input_dir / test_file.name
            import shutil
            shutil.copy2(test_file, input_file)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = temp_path / "output"
            output_dir.mkdir()
            
            # å®Œå…¨æ¨¡æ‹ŸGUIçš„process_directoryè°ƒç”¨
            logger.info(f"è°ƒç”¨process_directory: {input_dir} -> {output_dir}")
            
            # æ¨¡æ‹Ÿis_running_checkå‡½æ•°
            def is_running_check():
                return True
            
            # è°ƒç”¨process_directoryï¼ˆè¿™æ˜¯GUIå®é™…ä½¿ç”¨çš„å‡½æ•°ï¼‰
            process_directory(
                executor=executor,
                input_dir=str(input_dir),
                output_dir=str(output_dir),
                progress_callback=progress_collector.collect_event,
                is_running_check=is_running_check
            )
            
            # åˆ†æç»“æœ
            analysis = {
                "success": True,
                "total_events": len(progress_collector.events),
                "log_messages": progress_collector.log_messages,
                "step_summaries": progress_collector.step_summaries,
                "all_events": progress_collector.events
            }
            
            return analysis
        
    except Exception as e:
        logger.error(f"GUIå®Œæ•´è°ƒç”¨é“¾æ¨¡æ‹Ÿå¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return {"error": str(e)}

def analyze_log_messages(log_messages: List[str]) -> None:
    """åˆ†ææ—¥å¿—æ¶ˆæ¯"""
    print(f"\nğŸ“ æ—¥å¿—æ¶ˆæ¯åˆ†æ:")
    print(f"   æ€»æ—¥å¿—æ¡æ•°: {len(log_messages)}")
    
    # åˆ†ç±»æ—¥å¿—æ¶ˆæ¯
    masked_messages = []
    other_stage_messages = []
    general_messages = []
    
    for i, message in enumerate(log_messages, 1):
        print(f"     {i}. {message}")
        
        if "masked" in message and "pkts" in message:
            masked_messages.append(message)
        elif any(keyword in message for keyword in ["processed", "removed", "Anonymized"]):
            other_stage_messages.append(message)
        else:
            general_messages.append(message)
    
    print(f"\n   åˆ†ç±»ç»Ÿè®¡:")
    print(f"     æ©ç ç›¸å…³æ¶ˆæ¯: {len(masked_messages)}")
    print(f"     å…¶ä»–Stageæ¶ˆæ¯: {len(other_stage_messages)}")
    print(f"     ä¸€èˆ¬æ¶ˆæ¯: {len(general_messages)}")
    
    if masked_messages:
        print(f"\n   æ©ç æ¶ˆæ¯è¯¦æƒ…:")
        for msg in masked_messages:
            print(f"     - {msg}")
            if "masked 0 pkts" in msg:
                print(f"       âš ï¸  å‘ç°'masked 0 pkts'æ¶ˆæ¯ï¼")
            elif "masked" in msg and "pkts" in msg:
                print(f"       âœ… æ­£å¸¸æ©ç æ¶ˆæ¯")

def analyze_step_summaries(step_summaries: List[Dict]) -> None:
    """åˆ†ææ­¥éª¤æ‘˜è¦"""
    print(f"\nğŸ“Š æ­¥éª¤æ‘˜è¦åˆ†æ:")
    print(f"   æ€»æ‘˜è¦æ¡æ•°: {len(step_summaries)}")
    
    for i, summary in enumerate(step_summaries, 1):
        step_name = summary.get('step_name', 'Unknown')
        packets_processed = summary.get('packets_processed', 0)
        packets_modified = summary.get('packets_modified', 0)
        filename = summary.get('filename', 'Unknown')
        
        print(f"     {i}. {step_name} ({filename}):")
        print(f"        - processed: {packets_processed}")
        print(f"        - modified: {packets_modified}")
        
        if step_name in ['NewMaskPayloadStage', 'Mask Payloads (v2)'] and packets_modified == 0:
            print(f"        âš ï¸  æ©ç Stageä¿®æ”¹åŒ…æ•°ä¸º0ï¼")
        elif step_name in ['NewMaskPayloadStage', 'Mask Payloads (v2)'] and packets_modified > 0:
            print(f"        âœ… æ©ç Stageæ­£å¸¸ä¿®æ”¹äº†{packets_modified}ä¸ªåŒ…")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹GUIå®Œæ•´è°ƒç”¨é“¾æ¨¡æ‹Ÿ")
    
    # æµ‹è¯•æ–‡ä»¶
    test_files = [
        "tls_1_2-2.pcap",
        "tls_1_2_plainip.pcap"
    ]
    
    test_dir = project_root / "tests" / "data" / "tls"
    
    for file_name in test_files:
        test_file = test_dir / file_name
        if not test_file.exists():
            logger.warning(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            continue
        
        print(f"\n{'='*80}")
        print(f"æµ‹è¯•æ–‡ä»¶: {file_name}")
        print(f"{'='*80}")
        
        # è¿è¡Œå®Œæ•´æ¨¡æ‹Ÿ
        result = simulate_gui_full_pipeline(test_file)
        
        if "error" in result:
            print(f"âŒ æ¨¡æ‹Ÿå¤±è´¥: {result['error']}")
            continue
        
        print(f"âœ… æ¨¡æ‹ŸæˆåŠŸ")
        print(f"   æ€»äº‹ä»¶æ•°: {result.get('total_events', 0)}")
        
        # åˆ†ææ—¥å¿—æ¶ˆæ¯
        analyze_log_messages(result.get('log_messages', []))
        
        # åˆ†ææ­¥éª¤æ‘˜è¦
        analyze_step_summaries(result.get('step_summaries', []))
    
    print(f"\n{'='*80}")
    print("GUIå®Œæ•´è°ƒç”¨é“¾æ¨¡æ‹Ÿå®Œæˆ")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
