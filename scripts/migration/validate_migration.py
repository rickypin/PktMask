#!/usr/bin/env python3
"""
PktMaskç›®å½•ç»“æ„è¿ç§»éªŒè¯è„šæœ¬

æ­¤è„šæœ¬ç”¨äºéªŒè¯ç›®å½•ç»“æ„è¿ç§»çš„å®Œæ•´æ€§ï¼Œç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½æ­£ç¡®è¿ç§»ä¸”åŠŸèƒ½æ­£å¸¸ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/migration/validate_migration.py [--verbose] [--fix-issues]
    
å‚æ•°:
    --verbose: æ˜¾ç¤ºè¯¦ç»†çš„éªŒè¯è¿‡ç¨‹
    --fix-issues: è‡ªåŠ¨ä¿®å¤å‘ç°çš„é—®é¢˜
"""

import os
import sys
import json
import argparse
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MigrationValidator:
    """è¿ç§»éªŒè¯å™¨ - éªŒè¯ç›®å½•ç»“æ„è¿ç§»çš„å®Œæ•´æ€§"""
    
    def __init__(self, verbose: bool = False, fix_issues: bool = False):
        self.verbose = verbose
        self.fix_issues = fix_issues
        self.project_root = Path(__file__).parent.parent.parent
        self.issues_found = []
        self.validation_results = {}
        
    def validate_directory_structure(self) -> bool:
        """éªŒè¯ç›®å½•ç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸ"""
        logger.info("=== éªŒè¯ç›®å½•ç»“æ„ ===")
        
        # æœŸæœ›çš„ç›®å½•ç»“æ„
        expected_dirs = [
            "config/default",
            "config/samples", 
            "config/production",
            "config/test",
            "scripts/build",
            "scripts/test",
            "scripts/validation",
            "scripts/migration",
            "scripts/hooks",
            "docs/api",
            "docs/development",
            "docs/reports",
            "docs/user",
            "output/processed",
            "output/reports",
            "output/temp"
        ]
        
        missing_dirs = []
        for dir_path in expected_dirs:
            full_path = self.project_root / dir_path
            if not full_path.exists():
                missing_dirs.append(dir_path)
                if self.fix_issues:
                    full_path.mkdir(parents=True, exist_ok=True)
                    logger.info(f"âœ… åˆ›å»ºç¼ºå¤±ç›®å½•: {dir_path}")
        
        if missing_dirs:
            if not self.fix_issues:
                self.issues_found.extend([f"ç¼ºå¤±ç›®å½•: {d}" for d in missing_dirs])
                logger.error(f"âŒ å‘ç° {len(missing_dirs)} ä¸ªç¼ºå¤±ç›®å½•")
            
        self.validation_results['directory_structure'] = {
            'status': 'pass' if not missing_dirs or self.fix_issues else 'fail',
            'missing_dirs': missing_dirs,
            'expected_count': len(expected_dirs)
        }
        
        return len(missing_dirs) == 0 or self.fix_issues
    
    def validate_file_migrations(self) -> bool:
        """éªŒè¯æ–‡ä»¶è¿ç§»æ˜¯å¦æ­£ç¡®"""
        logger.info("=== éªŒè¯æ–‡ä»¶è¿ç§» ===")
        
        # æœŸæœ›çš„æ–‡ä»¶è¿ç§»æ˜ å°„
        expected_files = {
            # é…ç½®æ–‡ä»¶
            "config/default/mask_config.yaml": "mask_config.yaml",
            "config/samples/simple_mask_recipe.json": "simple_mask_recipe_sample.json",
            "config/samples/comprehensive_mask_recipe.json": "comprehensive_mask_recipe_sample.json",
            "config/samples/demo_recipe.json": "demo_recipe.json",
            "config/samples/custom_recipe.json": "custom_recipe.json",
            "config/samples/tls_mask_recipe.json": "tls_mask_recipe_sample.json",
            
            # è„šæœ¬æ–‡ä»¶
            "scripts/test/manual_tcp_masker_test.py": "manual_tcp_masker_test.py",
            "scripts/test/run_tcp_masker_test.py": "run_tcp_masker_test.py",
            "scripts/build/build_app.sh": "build_app.sh",
            "scripts/migration/sequence_unification_strategy.py": "sequence_unification_strategy.py",
            "scripts/migration/hybrid_architecture_design.py": "hybrid_architecture_design.py",
            
            # æ–‡æ¡£æ–‡ä»¶
            "docs/reports/tcp_payload_masker_phase1_4_validation_report.md": "tcp_payload_masker_phase1_4_validation_report.md"
        }
        
        missing_files = []
        incorrect_locations = []
        
        for new_path, old_filename in expected_files.items():
            new_full_path = self.project_root / new_path
            old_full_path = self.project_root / old_filename
            
            if not new_full_path.exists():
                if old_full_path.exists():
                    incorrect_locations.append((old_filename, new_path))
                else:
                    missing_files.append(new_path)
        
        if missing_files:
            self.issues_found.extend([f"ç¼ºå¤±æ–‡ä»¶: {f}" for f in missing_files])
            logger.error(f"âŒ å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶")
            
        if incorrect_locations:
            self.issues_found.extend([f"æ–‡ä»¶æœªè¿ç§»: {old} -> {new}" for old, new in incorrect_locations])
            logger.error(f"âŒ å‘ç° {len(incorrect_locations)} ä¸ªæœªè¿ç§»æ–‡ä»¶")
        
        self.validation_results['file_migrations'] = {
            'status': 'pass' if not missing_files and not incorrect_locations else 'fail',
            'missing_files': missing_files,
            'incorrect_locations': incorrect_locations,
            'expected_count': len(expected_files)
        }
        
        return len(missing_files) == 0 and len(incorrect_locations) == 0
    
    def validate_path_references(self) -> bool:
        """éªŒè¯è·¯å¾„å¼•ç”¨æ˜¯å¦æ­£ç¡®æ›´æ–°"""
        logger.info("=== éªŒè¯è·¯å¾„å¼•ç”¨ ===")
        
        # æ£€æŸ¥å¯èƒ½åŒ…å«æ—§è·¯å¾„å¼•ç”¨çš„æ–‡ä»¶
        files_to_check = [
            "src/pktmask/config/defaults.py",
            "examples/basic_usage.py",
            "examples/advanced_usage.py",
            "run_tests.py",
            "README.md"
        ]
        
        # æ—§è·¯å¾„æ¨¡å¼ (è¿™äº›åº”è¯¥å·²ç»è¢«æ›´æ–°)
        old_patterns = [
            "mask_config.yaml",
            "simple_mask_recipe_sample.json",
            "manual_tcp_masker_test.py",
            "build_app.sh",
            "tcp_payload_masker_phase1_4_validation_report.md"
        ]
        
        path_issues = []
        
        for file_path in files_to_check:
            full_path = self.project_root / file_path
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    for pattern in old_patterns:
                        if pattern in content:
                            path_issues.append(f"{file_path} åŒ…å«æ—§è·¯å¾„å¼•ç”¨: {pattern}")
                            
                except Exception as e:
                    logger.warning(f"æ— æ³•æ£€æŸ¥æ–‡ä»¶ {file_path}: {e}")
        
        if path_issues:
            self.issues_found.extend(path_issues)
            logger.error(f"âŒ å‘ç° {len(path_issues)} ä¸ªè·¯å¾„å¼•ç”¨é—®é¢˜")
        
        self.validation_results['path_references'] = {
            'status': 'pass' if not path_issues else 'fail',
            'issues': path_issues,
            'checked_files': len(files_to_check)
        }
        
        return len(path_issues) == 0
    
    def validate_functionality(self) -> bool:
        """éªŒè¯åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸"""
        logger.info("=== éªŒè¯åŸºæœ¬åŠŸèƒ½ ===")
        
        functionality_results = {}
        
        # æµ‹è¯•1: æ£€æŸ¥Pythonæ¨¡å—å¯¼å…¥
        try:
            import sys
            sys.path.insert(0, str(self.project_root / "src"))
            import pktmask
            functionality_results['module_import'] = 'pass'
            logger.info("âœ… Pythonæ¨¡å—å¯¼å…¥æ­£å¸¸")
        except Exception as e:
            functionality_results['module_import'] = f'fail: {e}'
            logger.error(f"âŒ Pythonæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            self.issues_found.append(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        
        # æµ‹è¯•2: æ£€æŸ¥é…ç½®æ–‡ä»¶åŠ è½½
        try:
            config_path = self.project_root / "config" / "default" / "mask_config.yaml"
            if config_path.exists():
                functionality_results['config_loading'] = 'pass'
                logger.info("âœ… é…ç½®æ–‡ä»¶å­˜åœ¨")
            else:
                functionality_results['config_loading'] = 'fail: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                logger.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
                self.issues_found.append("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            functionality_results['config_loading'] = f'fail: {e}'
            logger.error(f"âŒ é…ç½®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            self.issues_found.append(f"é…ç½®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
        
        # æµ‹è¯•3: è¿è¡Œå¿«é€Ÿæµ‹è¯• (å¦‚æœå¯ç”¨)
        try:
            test_script = self.project_root / "run_tests.py"
            if test_script.exists():
                result = subprocess.run([
                    sys.executable, str(test_script), "--quick"
                ], capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    functionality_results['quick_tests'] = 'pass'
                    logger.info("âœ… å¿«é€Ÿæµ‹è¯•é€šè¿‡")
                else:
                    functionality_results['quick_tests'] = f'fail: é€€å‡ºç  {result.returncode}'
                    logger.error(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: é€€å‡ºç  {result.returncode}")
                    if self.verbose:
                        logger.error(f"æµ‹è¯•è¾“å‡º: {result.stderr}")
                    self.issues_found.append(f"å¿«é€Ÿæµ‹è¯•å¤±è´¥: é€€å‡ºç  {result.returncode}")
            else:
                functionality_results['quick_tests'] = 'skip: æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨'
                logger.warning("âš ï¸  æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
                
        except subprocess.TimeoutExpired:
            functionality_results['quick_tests'] = 'fail: è¶…æ—¶'
            logger.error("âŒ å¿«é€Ÿæµ‹è¯•è¶…æ—¶")
            self.issues_found.append("å¿«é€Ÿæµ‹è¯•è¶…æ—¶")
        except Exception as e:
            functionality_results['quick_tests'] = f'fail: {e}'
            logger.error(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")
            self.issues_found.append(f"å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")
        
        self.validation_results['functionality'] = functionality_results
        
        # å¦‚æœæ¨¡å—å¯¼å…¥å’Œé…ç½®åŠ è½½éƒ½æ­£å¸¸ï¼Œåˆ™è®¤ä¸ºåŸºæœ¬åŠŸèƒ½æ­£å¸¸
        basic_checks = ['module_import', 'config_loading']
        all_basic_pass = all(functionality_results.get(check, '').startswith('pass') for check in basic_checks)
        
        return all_basic_pass
    
    def validate_cleanup(self) -> bool:
        """éªŒè¯æ¸…ç†å·¥ä½œæ˜¯å¦å®Œæˆ"""
        logger.info("=== éªŒè¯æ¸…ç†å·¥ä½œ ===")
        
        # åº”è¯¥è¢«ç§»åŠ¨æˆ–åˆ é™¤çš„æ–‡ä»¶/ç›®å½•
        items_to_cleanup = [
            "mask_config.yaml",
            "simple_mask_recipe_sample.json",
            "comprehensive_mask_recipe_sample.json",
            "demo_recipe.json",
            "custom_recipe.json",
            "tls_mask_recipe_sample.json",
            "manual_tcp_masker_test.py",
            "run_tcp_masker_test.py",
            "build_app.sh",
            "sequence_unification_strategy.py",
            "hybrid_architecture_design.py",
            "tcp_payload_masker_phase1_4_validation_report.md",
            "conf",
            "test_configs",
            "hooks",
            "examples/examples"  # åµŒå¥—ç›®å½•
        ]
        
        cleanup_issues = []
        
        for item in items_to_cleanup:
            item_path = self.project_root / item
            if item_path.exists():
                cleanup_issues.append(f"æœªæ¸…ç†é¡¹ç›®: {item}")
                if self.fix_issues:
                    try:
                        if item_path.is_dir():
                            import shutil
                            shutil.rmtree(item_path)
                        else:
                            item_path.unlink()
                        logger.info(f"âœ… æ¸…ç†é¡¹ç›®: {item}")
                    except Exception as e:
                        logger.error(f"âŒ æ¸…ç†å¤±è´¥ {item}: {e}")
        
        if cleanup_issues:
            if not self.fix_issues:
                self.issues_found.extend(cleanup_issues)
                logger.error(f"âŒ å‘ç° {len(cleanup_issues)} ä¸ªæœªæ¸…ç†é¡¹ç›®")
        
        self.validation_results['cleanup'] = {
            'status': 'pass' if not cleanup_issues or self.fix_issues else 'fail',
            'issues': cleanup_issues,
            'checked_items': len(items_to_cleanup)
        }
        
        return len(cleanup_issues) == 0 or self.fix_issues
    
    def generate_validation_report(self) -> None:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        logger.info("=== ç”ŸæˆéªŒè¯æŠ¥å‘Š ===")
        
        report_dir = self.project_root / "output" / "reports"
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # JSONæ ¼å¼è¯¦ç»†æŠ¥å‘Š
        json_report = {
            "validation_timestamp": "2025-01-XX",  # å®é™…ä½¿ç”¨æ—¶éœ€è¦åŠ¨æ€ç”Ÿæˆ
            "project_root": str(self.project_root),
            "validation_options": {
                "verbose": self.verbose,
                "fix_issues": self.fix_issues
            },
            "overall_status": "pass" if not self.issues_found else "fail",
            "issues_count": len(self.issues_found),
            "issues_found": self.issues_found,
            "detailed_results": self.validation_results
        }
        
        json_path = report_dir / "migration_validation_report.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        # Markdownæ ¼å¼æ‘˜è¦æŠ¥å‘Š
        md_path = report_dir / "migration_validation_summary.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write("# PktMaskç›®å½•ç»“æ„è¿ç§»éªŒè¯æŠ¥å‘Š\n\n")
            f.write(f"**éªŒè¯çŠ¶æ€**: {'âœ… é€šè¿‡' if not self.issues_found else 'âŒ å‘ç°é—®é¢˜'}\n")
            f.write(f"**é—®é¢˜æ•°é‡**: {len(self.issues_found)}\n")
            f.write(f"**ä¿®å¤æ¨¡å¼**: {'å¯ç”¨' if self.fix_issues else 'ç¦ç”¨'}\n\n")
            
            f.write("## éªŒè¯ç»“æœæ¦‚è§ˆ\n\n")
            for category, result in self.validation_results.items():
                status = result.get('status', 'unknown')
                emoji = 'âœ…' if status == 'pass' else 'âŒ'
                f.write(f"- {emoji} **{category}**: {status}\n")
            
            if self.issues_found:
                f.write("\n## å‘ç°çš„é—®é¢˜\n\n")
                for i, issue in enumerate(self.issues_found, 1):
                    f.write(f"{i}. {issue}\n")
            
            f.write("\n## å»ºè®®åç»­æ­¥éª¤\n\n")
            if not self.issues_found:
                f.write("ğŸ‰ è¿ç§»éªŒè¯é€šè¿‡ï¼é¡¹ç›®å·²æˆåŠŸé‡ç»„ã€‚\n\n")
                f.write("å»ºè®®æ‰§è¡Œä»¥ä¸‹æœ€ç»ˆéªŒè¯æ­¥éª¤ï¼š\n")
                f.write("1. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶\n")
                f.write("2. å¯åŠ¨GUIç¡®è®¤åŠŸèƒ½æ­£å¸¸\n")
                f.write("3. è¿è¡Œç¤ºä¾‹è„šæœ¬éªŒè¯\n")
            else:
                f.write("âš ï¸ å‘ç°é—®é¢˜éœ€è¦è§£å†³ã€‚\n\n")
                f.write("å»ºè®®æ‰§è¡Œæ­¥éª¤ï¼š\n")
                f.write("1. ä½¿ç”¨ --fix-issues å‚æ•°è‡ªåŠ¨ä¿®å¤\n")
                f.write("2. æ‰‹åŠ¨æ£€æŸ¥æ— æ³•è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜\n")
                f.write("3. é‡æ–°è¿è¡ŒéªŒè¯\n")
        
        logger.info(f"ğŸ“Š éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ:")
        logger.info(f"   - è¯¦ç»†æŠ¥å‘Š: {json_path}")
        logger.info(f"   - æ‘˜è¦æŠ¥å‘Š: {md_path}")
    
    def run_validation(self) -> bool:
        """è¿è¡Œå®Œæ•´çš„è¿ç§»éªŒè¯"""
        logger.info("ğŸš€ å¼€å§‹PktMaskç›®å½•ç»“æ„è¿ç§»éªŒè¯")
        
        validation_steps = [
            ("ç›®å½•ç»“æ„", self.validate_directory_structure),
            ("æ–‡ä»¶è¿ç§»", self.validate_file_migrations),
            ("è·¯å¾„å¼•ç”¨", self.validate_path_references),
            ("åŸºæœ¬åŠŸèƒ½", self.validate_functionality),
            ("æ¸…ç†å·¥ä½œ", self.validate_cleanup)
        ]
        
        passed_steps = 0
        total_steps = len(validation_steps)
        
        for step_name, step_func in validation_steps:
            logger.info(f"ğŸ“‹ éªŒè¯æ­¥éª¤: {step_name}")
            try:
                if step_func():
                    logger.info(f"âœ… {step_name}éªŒè¯é€šè¿‡")
                    passed_steps += 1
                else:
                    logger.error(f"âŒ {step_name}éªŒè¯å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {step_name}éªŒè¯å¼‚å¸¸: {e}")
                self.issues_found.append(f"{step_name}éªŒè¯å¼‚å¸¸: {e}")
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        self.generate_validation_report()
        
        # è¾“å‡ºæœ€ç»ˆç»“æœ
        success_rate = (passed_steps / total_steps) * 100
        logger.info(f"ğŸ“Š éªŒè¯å®Œæˆ: {passed_steps}/{total_steps} æ­¥éª¤é€šè¿‡ ({success_rate:.1f}%)")
        
        if self.issues_found:
            logger.error(f"âŒ å‘ç° {len(self.issues_found)} ä¸ªé—®é¢˜:")
            for issue in self.issues_found[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                logger.error(f"   â€¢ {issue}")
            if len(self.issues_found) > 5:
                logger.error(f"   ... è¿˜æœ‰ {len(self.issues_found) - 5} ä¸ªé—®é¢˜ (è¯¦è§æŠ¥å‘Š)")
        else:
            logger.info("ğŸ‰ è¿ç§»éªŒè¯å®Œå…¨é€šè¿‡ï¼")
        
        return len(self.issues_found) == 0

def main():
    parser = argparse.ArgumentParser(description="PktMaskç›®å½•ç»“æ„è¿ç§»éªŒè¯è„šæœ¬")
    parser.add_argument("--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†éªŒè¯è¿‡ç¨‹")
    parser.add_argument("--fix-issues", action="store_true", help="è‡ªåŠ¨ä¿®å¤å‘ç°çš„é—®é¢˜")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    validator = MigrationValidator(verbose=args.verbose, fix_issues=args.fix_issues)
    
    try:
        success = validator.run_validation()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"âŒ éªŒè¯è¿‡ç¨‹å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 