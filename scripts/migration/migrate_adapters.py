#!/usr/bin/env python3
"""
é€‚é…å™¨è‡ªåŠ¨è¿ç§»è„šæœ¬

è‡ªåŠ¨åŒ–æ‰§è¡Œé€‚é…å™¨è¿ç§»ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼š
1. ç§»åŠ¨æ–‡ä»¶åˆ°æ–°ä½ç½®
2. æ›´æ–°å¯¼å…¥è·¯å¾„
3. é‡å‘½åç±»ï¼ˆå¦‚éœ€è¦ï¼‰
4. åˆ›å»ºå‘åå…¼å®¹çš„ä»£ç†æ–‡ä»¶
"""

import os
import shutil
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple
import argparse

# é€‚é…å™¨è¿ç§»æ˜ å°„
ADAPTER_MIGRATIONS = [
    # (åŸæ–‡ä»¶è·¯å¾„, æ–°æ–‡ä»¶è·¯å¾„, æ˜¯å¦éœ€è¦é‡å‘½å)
    ("src/pktmask/core/adapters/processor_adapter.py", 
     "src/pktmask/adapters/processor_adapter.py", False),
    
    ("src/pktmask/core/encapsulation/adapter.py", 
     "src/pktmask/adapters/encapsulation_adapter.py", True),
    
    ("src/pktmask/domain/adapters/event_adapter.py", 
     "src/pktmask/adapters/event_adapter.py", False),
    
    ("src/pktmask/domain/adapters/statistics_adapter.py", 
     "src/pktmask/adapters/statistics_adapter.py", False),
    
    ("src/pktmask/stages/adapters/anon_compat.py", 
     "src/pktmask/adapters/compatibility/anon_compat.py", False),
    
    ("src/pktmask/stages/adapters/dedup_compat.py", 
     "src/pktmask/adapters/compatibility/dedup_compat.py", False),
]

# å¯¼å…¥è·¯å¾„æ˜ å°„
IMPORT_MAPPINGS = {
    "pktmask.core.adapters.processor_adapter": "pktmask.adapters.processor_adapter",
    "pktmask.core.encapsulation.adapter": "pktmask.adapters.encapsulation_adapter",
    "pktmask.domain.adapters.event_adapter": "pktmask.adapters.event_adapter",
    "pktmask.domain.adapters.statistics_adapter": "pktmask.adapters.statistics_adapter",
    "pktmask.stages.adapters.anon_compat": "pktmask.adapters.compatibility.anon_compat",
    "pktmask.stages.adapters.dedup_compat": "pktmask.adapters.compatibility.dedup_compat",
}

# ç±»åæ˜ å°„
CLASS_MAPPINGS = {
    "ProcessorAdapter": "ProcessorAdapter",
}


def create_proxy_file(old_path: Path, new_module: str) -> None:
    """åˆ›å»ºå‘åå…¼å®¹çš„ä»£ç†æ–‡ä»¶"""
    module_parts = new_module.split('.')
    class_imports = []
    
    # æ ¹æ®æ–‡ä»¶åæ¨æµ‹å¯èƒ½çš„ç±»å
    file_name = old_path.stem
    if file_name.endswith('_adapter'):
        class_name = ''.join(word.capitalize() for word in file_name.split('_'))
        class_imports.append(class_name)
    elif file_name.endswith('_compat'):
        class_name = ''.join(word.capitalize() for word in file_name.split('_'))
        class_imports.append(class_name)
    
    proxy_content = f'''"""
å‘åå…¼å®¹ä»£ç†æ–‡ä»¶

æ­¤æ–‡ä»¶ç”¨äºä¿æŒå‘åå…¼å®¹æ€§ã€‚
è¯·ä½¿ç”¨æ–°çš„å¯¼å…¥è·¯å¾„ï¼š{new_module}
"""

import warnings
from {new_module} import *

warnings.warn(
    f"å¯¼å…¥è·¯å¾„ '{{__name__}}' å·²åºŸå¼ƒï¼Œ"
    f"è¯·ä½¿ç”¨ '{new_module}' æ›¿ä»£ã€‚"
    f"æ­¤å…¼å®¹æ€§æ”¯æŒå°†åœ¨ v2.0 ä¸­ç§»é™¤ã€‚",
    DeprecationWarning,
    stacklevel=2
)
'''
    
    old_path.write_text(proxy_content, encoding='utf-8')
    print(f"  åˆ›å»ºä»£ç†æ–‡ä»¶: {old_path}")


def move_adapter_file(root_dir: Path, old_path: str, new_path: str, needs_rename: bool) -> bool:
    """ç§»åŠ¨é€‚é…å™¨æ–‡ä»¶åˆ°æ–°ä½ç½®"""
    src = root_dir / old_path
    dst = root_dir / new_path
    
    if not src.exists():
        print(f"  âš ï¸  æºæ–‡ä»¶ä¸å­˜åœ¨: {src}")
        return False
    
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    dst.parent.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶åˆ°æ–°ä½ç½®
    shutil.copy2(src, dst)
    print(f"  âœ… å¤åˆ¶æ–‡ä»¶: {old_path} -> {new_path}")
    
    # åˆ›å»ºä»£ç†æ–‡ä»¶
    old_module = old_path.replace('src/', '').replace('.py', '').replace('/', '.')
    new_module = new_path.replace('src/', '').replace('.py', '').replace('/', '.')
    create_proxy_file(src, new_module)
    
    return True


def update_imports_in_file(file_path: Path, dry_run: bool = False) -> int:
    """æ›´æ–°æ–‡ä»¶ä¸­çš„å¯¼å…¥è·¯å¾„"""
    try:
        content = file_path.read_text(encoding='utf-8')
        original_content = content
        changes = 0
        
        # æ›´æ–°å¯¼å…¥è·¯å¾„
        for old_import, new_import in IMPORT_MAPPINGS.items():
            # åŒ¹é… from ... import è¯­å¥
            pattern1 = re.compile(rf'from\s+{re.escape(old_import)}\s+import')
            if pattern1.search(content):
                content = pattern1.sub(f'from {new_import} import', content)
                changes += 1
            
            # åŒ¹é… import ... è¯­å¥
            pattern2 = re.compile(rf'import\s+{re.escape(old_import)}')
            if pattern2.search(content):
                content = pattern2.sub(f'import {new_import}', content)
                changes += 1
        
        # æ›´æ–°ç±»åï¼ˆå¦‚æœéœ€è¦ï¼‰
        for old_class, new_class in CLASS_MAPPINGS.items():
            if old_class in content:
                content = content.replace(old_class, new_class)
                changes += 1
        
        # å†™å›æ–‡ä»¶
        if changes > 0 and not dry_run:
            file_path.write_text(content, encoding='utf-8')
            print(f"  âœ… æ›´æ–° {file_path}: {changes} å¤„å˜æ›´")
        elif changes > 0:
            print(f"  ğŸ” å‘ç° {file_path}: {changes} å¤„éœ€è¦å˜æ›´")
        
        return changes
        
    except Exception as e:
        print(f"  âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return 0


def find_affected_files(root_dir: Path) -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æ›´æ–°å¯¼å…¥çš„æ–‡ä»¶"""
    affected_files = []
    
    for root, dirs, files in os.walk(root_dir):
        # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in {'.venv', '__pycache__', '.git', 'output'}]
        
        for file in files:
            if file.endswith('.py'):
                file_path = Path(root) / file
                # å¿«é€Ÿæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«éœ€è¦æ›´æ–°çš„å¯¼å…¥
                try:
                    content = file_path.read_text(encoding='utf-8')
                    for old_import in IMPORT_MAPPINGS:
                        if old_import in content:
                            affected_files.append(file_path)
                            break
                except:
                    pass
    
    return affected_files


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é€‚é…å™¨è¿ç§»è„šæœ¬')
    parser.add_argument('--dry-run', action='store_true', help='ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…æ‰§è¡Œ')
    parser.add_argument('--step', choices=['move', 'update', 'all'], default='all', 
                        help='æ‰§è¡Œçš„æ­¥éª¤ï¼šmove-ç§»åŠ¨æ–‡ä»¶ï¼Œupdate-æ›´æ–°å¯¼å…¥ï¼Œall-å…¨éƒ¨')
    args = parser.parse_args()
    
    root_dir = Path(__file__).parent.parent.parent
    
    print(f"{'ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼' if args.dry_run else 'ğŸš€ æ‰§è¡Œè¿ç§»'}")
    print("=" * 60)
    
    # æ­¥éª¤1ï¼šç§»åŠ¨é€‚é…å™¨æ–‡ä»¶
    if args.step in ['move', 'all']:
        print("\nğŸ“ æ­¥éª¤1ï¼šç§»åŠ¨é€‚é…å™¨æ–‡ä»¶")
        print("-" * 40)
        for old_path, new_path, needs_rename in ADAPTER_MIGRATIONS:
            if not args.dry_run:
                move_adapter_file(root_dir, old_path, new_path, needs_rename)
            else:
                print(f"  å°†ç§»åŠ¨: {old_path} -> {new_path}")
    
    # æ­¥éª¤2ï¼šæ›´æ–°å¯¼å…¥è·¯å¾„
    if args.step in ['update', 'all']:
        print("\nğŸ“ æ­¥éª¤2ï¼šæ›´æ–°å¯¼å…¥è·¯å¾„")
        print("-" * 40)
        
        # æŸ¥æ‰¾å—å½±å“çš„æ–‡ä»¶
        print("æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„æ–‡ä»¶...")
        affected_files = find_affected_files(root_dir)
        print(f"æ‰¾åˆ° {len(affected_files)} ä¸ªæ–‡ä»¶éœ€è¦æ›´æ–°")
        
        total_changes = 0
        for file_path in affected_files:
            changes = update_imports_in_file(file_path, dry_run=args.dry_run)
            total_changes += changes
        
        print(f"\næ€»è®¡éœ€è¦æ›´æ–° {total_changes} å¤„å¯¼å…¥")
    
    print("\nâœ… è¿ç§»å‡†å¤‡å®Œæˆï¼")
    
    if args.dry_run:
        print("\nğŸ’¡ è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œå®é™…æ–‡ä»¶æœªè¢«ä¿®æ”¹ã€‚")
        print("   è¦æ‰§è¡Œå®é™…è¿ç§»ï¼Œè¯·è¿è¡Œä¸å¸¦ --dry-run å‚æ•°çš„å‘½ä»¤ã€‚")


if __name__ == "__main__":
    main()
