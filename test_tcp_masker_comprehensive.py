#!/usr/bin/env python3
"""
TCPè½½è·æ©ç å™¨ç»¼åˆæµ‹è¯•è„šæœ¬ - ç¬¬äº”é˜¶æ®µå®ç°
è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶ï¼ŒåŒ…å«æ•°æ®åŒ…çº§ã€ç»Ÿè®¡çº§ã€å®Œæ•´æ€§éªŒè¯å’Œå¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import json
import yaml
import logging
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import datetime
import shutil
from dataclasses import dataclass
import base64

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root / 'src'))

try:
    from scapy.all import rdpcap, wrpcap, Packet
    from scapy.layers.inet import IP, TCP
    from scapy.layers.l2 import Ether
except ImportError:
    print("é”™è¯¯ï¼šéœ€è¦å®‰è£…Scapyåº“")
    sys.exit(1)


@dataclass
class PacketComparison:
    """æ•°æ®åŒ…å¯¹æ¯”ç»“æœ"""
    packet_number: int
    original_size: int
    modified_size: int
    payload_modified: bool
    header_modified: bool
    modifications: List[Dict[str, Any]]
    masked_bytes: int
    kept_bytes: int


@dataclass
class TestScenarioResult:
    """æµ‹è¯•åœºæ™¯ç»“æœ"""
    scenario_name: str
    success: bool
    execution_time: float
    expected_packets: int
    actual_packets: int
    expected_bytes: int
    actual_bytes: int
    packet_comparisons: List[PacketComparison]
    statistics: Dict[str, Any]
    errors: List[str]


class VisualizationGenerator:
    """å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def generate_hex_comparison(self, original_bytes: bytes, modified_bytes: bytes, 
                               keep_ranges: List[Tuple[int, int]], packet_number: int) -> str:
        """ç”Ÿæˆåå…­è¿›åˆ¶å¯¹æ¯”å›¾"""
        if len(original_bytes) != len(modified_bytes):
            return f"<p>æ•°æ®åŒ… #{packet_number}: é•¿åº¦ä¸åŒ¹é… ({len(original_bytes)} vs {len(modified_bytes)})</p>"
        
        html = [f'<div class="hex-comparison" id="packet-{packet_number}">']
        html.append(f'<h4>æ•°æ®åŒ… #{packet_number} åå…­è¿›åˆ¶å¯¹æ¯”</h4>')
        html.append('<table class="hex-table">')
        html.append('<tr><th>åç§»</th><th>åŸå§‹æ•°æ®</th><th>ä¿®æ”¹åæ•°æ®</th><th>çŠ¶æ€</th></tr>')
        
        # ç¡®å®šå“ªäº›å­—èŠ‚åº”è¯¥è¢«ä¿ç•™
        keep_set = set()
        for start, end in keep_ranges:
            keep_set.update(range(start, end + 1))
        
        # æŒ‰16å­—èŠ‚ä¸€è¡Œæ˜¾ç¤º
        for i in range(0, len(original_bytes), 16):
            chunk_orig = original_bytes[i:i+16]
            chunk_mod = modified_bytes[i:i+16]
            
            # æ ¼å¼åŒ–åå…­è¿›åˆ¶
            hex_orig = ' '.join(f'{b:02x}' for b in chunk_orig)
            hex_mod = ' '.join(f'{b:02x}' for b in chunk_mod)
            
            # åˆ†æçŠ¶æ€
            statuses = []
            for j, (orig_b, mod_b) in enumerate(zip(chunk_orig, chunk_mod)):
                byte_idx = i + j
                if byte_idx in keep_set:
                    if orig_b == mod_b:
                        statuses.append('kept')
                    else:
                        statuses.append('error')  # åº”è¯¥ä¿ç•™ä½†è¢«ä¿®æ”¹äº†
                else:
                    if orig_b != mod_b:
                        statuses.append('masked')
                    else:
                        statuses.append('unchanged')
            
            # æ ¹æ®çŠ¶æ€æ·»åŠ é¢œè‰²ç±»
            colored_orig = self._color_hex_bytes(hex_orig.split(), statuses)
            colored_mod = self._color_hex_bytes(hex_mod.split(), statuses)
            
            status_summary = self._get_status_summary(statuses)
            
            html.append(f'<tr>')
            html.append(f'<td>{i:04x}</td>')
            html.append(f'<td class="hex-data">{colored_orig}</td>')
            html.append(f'<td class="hex-data">{colored_mod}</td>')
            html.append(f'<td>{status_summary}</td>')
            html.append(f'</tr>')
        
        html.append('</table>')
        html.append('<div class="legend">')
        html.append('<span class="kept">ä¿ç•™</span> ')
        html.append('<span class="masked">æ©ç </span> ')
        html.append('<span class="unchanged">æœªå˜</span> ')
        html.append('<span class="error">é”™è¯¯</span>')
        html.append('</div>')
        html.append('</div>')
        
        return '\n'.join(html)
    
    def _color_hex_bytes(self, hex_bytes: List[str], statuses: List[str]) -> str:
        """ä¸ºåå…­è¿›åˆ¶å­—èŠ‚æ·»åŠ é¢œè‰²æ ‡è®°"""
        colored = []
        for hex_byte, status in zip(hex_bytes, statuses):
            colored.append(f'<span class="{status}">{hex_byte}</span>')
        return ' '.join(colored)
    
    def _get_status_summary(self, statuses: List[str]) -> str:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        counts = {}
        for status in statuses:
            counts[status] = counts.get(status, 0) + 1
        
        summary = []
        if counts.get('kept', 0) > 0:
            summary.append(f"ä¿ç•™{counts['kept']}")
        if counts.get('masked', 0) > 0:
            summary.append(f"æ©ç {counts['masked']}")
        if counts.get('unchanged', 0) > 0:
            summary.append(f"æœªå˜{counts['unchanged']}")
        if counts.get('error', 0) > 0:
            summary.append(f"é”™è¯¯{counts['error']}")
        
        return ', '.join(summary)
    
    def generate_statistics_charts(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»Ÿè®¡å›¾è¡¨"""
        html = ['<div class="charts-container">']
        
        # æµ‹è¯•é€šè¿‡ç‡é¥¼å›¾
        html.append(self._generate_pass_rate_pie_chart(test_results))
        
        # åœºæ™¯è¦†ç›–ç‡æŸ±çŠ¶å›¾
        html.append(self._generate_scenario_coverage_bar_chart(test_results))
        
        # æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿å›¾
        html.append(self._generate_performance_metrics_chart(test_results))
        
        html.append('</div>')
        return '\n'.join(html)
    
    def _generate_pass_rate_pie_chart(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæµ‹è¯•é€šè¿‡ç‡é¥¼å›¾"""
        summary = test_results['summary']
        total = summary['total_scenarios']
        passed = summary['successful_scenarios']
        failed = total - passed
        
        pass_rate = (passed / total * 100) if total > 0 else 0
        fail_rate = 100 - pass_rate
        
        html = ['<div class="chart pass-rate-chart">']
        html.append('<h3>ğŸ“Š æµ‹è¯•é€šè¿‡ç‡</h3>')
        html.append('<div class="pie-chart">')
        
        # ä½¿ç”¨CSSç”»é¥¼å›¾
        if passed > 0:
            html.append(f'<div class="pie-slice pass" style="--percentage:{pass_rate}"></div>')
        if failed > 0:
            html.append(f'<div class="pie-slice fail" style="--percentage:{fail_rate}"></div>')
        
        html.append('</div>')
        html.append('<div class="chart-legend">')
        html.append(f'<div class="legend-item"><span class="color-pass"></span>é€šè¿‡: {passed} ({pass_rate:.1f}%)</div>')
        html.append(f'<div class="legend-item"><span class="color-fail"></span>å¤±è´¥: {failed} ({fail_rate:.1f}%)</div>')
        html.append('</div>')
        html.append('</div>')
        
        return '\n'.join(html)
    
    def _generate_scenario_coverage_bar_chart(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆåœºæ™¯è¦†ç›–ç‡æŸ±çŠ¶å›¾"""
        html = ['<div class="chart coverage-chart">']
        html.append('<h3>ğŸ“ˆ åœºæ™¯å‡†ç¡®ç‡å¯¹æ¯”</h3>')
        html.append('<div class="bar-chart">')
        
        for result in test_results['results']:
            scenario_name = result['scenario']['config']['metadata']['name']
            verification = result['verification']
            accuracy = verification.get('accuracy', 0) * 100
            status = 'âœ…' if result['result'].success else 'âŒ'
            
            bar_class = 'success' if result['result'].success else 'failure'
            
            html.append('<div class="bar-item">')
            html.append(f'<div class="bar-label">{status} {scenario_name}</div>')
            html.append(f'<div class="bar-container">')
            html.append(f'<div class="bar {bar_class}" style="width: {accuracy}%"></div>')
            html.append(f'<div class="bar-value">{accuracy:.1f}%</div>')
            html.append('</div>')
            html.append('</div>')
        
        html.append('</div>')
        html.append('</div>')
        
        return '\n'.join(html)
    
    def _generate_performance_metrics_chart(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡å›¾è¡¨"""
        html = ['<div class="chart performance-chart">']
        html.append('<h3>âš¡ æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡</h3>')
        html.append('<div class="metrics-grid">')
        
        summary = test_results['summary']
        
        # æ‰§è¡Œæ—¶é—´
        avg_time = summary.get('average_execution_time', 0)
        total_time = summary.get('total_execution_time', 0)
        
        html.append('<div class="metric-item">')
        html.append('<div class="metric-title">å¹³å‡æ‰§è¡Œæ—¶é—´</div>')
        html.append(f'<div class="metric-value">{avg_time:.3f}s</div>')
        html.append('</div>')
        
        html.append('<div class="metric-item">')
        html.append('<div class="metric-title">æ€»æ‰§è¡Œæ—¶é—´</div>')
        html.append(f'<div class="metric-value">{total_time:.3f}s</div>')
        html.append('</div>')
        
        # å¹³å‡å‡†ç¡®ç‡
        avg_accuracy = summary.get('average_accuracy', 0) * 100
        html.append('<div class="metric-item">')
        html.append('<div class="metric-title">å¹³å‡å‡†ç¡®ç‡</div>')
        html.append(f'<div class="metric-value">{avg_accuracy:.1f}%</div>')
        html.append('</div>')
        
        # å¤„ç†é€Ÿåº¦ï¼ˆåŸºäºå¹³å‡åŒ…æ•°å’Œæ—¶é—´è®¡ç®—ï¼‰
        if avg_time > 0:
            # å‡è®¾æµ‹è¯•æ–‡ä»¶æœ‰22ä¸ªåŒ…
            pps = 22 / avg_time
            html.append('<div class="metric-item">')
            html.append('<div class="metric-title">å¤„ç†é€Ÿåº¦</div>')
            html.append(f'<div class="metric-value">{pps:.0f} pps</div>')
            html.append('</div>')
        
        html.append('</div>')
        html.append('</div>')
        
        return '\n'.join(html)
    
    def generate_visual_html_report(self, test_results: Dict[str, Any], 
                                   packet_comparisons: List[PacketComparison] = None) -> str:
        """ç”Ÿæˆå®Œæ•´çš„HTMLå¯è§†åŒ–æŠ¥å‘Š"""
        self.logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–HTMLæŠ¥å‘Š...")
        
        summary = test_results['summary']
        
        html = ['<!DOCTYPE html>']
        html.append('<html lang="zh-CN">')
        html.append('<head>')
        html.append('<meta charset="UTF-8">')
        html.append('<meta name="viewport" content="width=device-width, initial-scale=1.0">')
        html.append('<title>TCPè½½è·æ©ç å™¨å¯è§†åŒ–æµ‹è¯•æŠ¥å‘Š</title>')
        html.append('<style>')
        html.append(self._get_css_styles())
        html.append('</style>')
        html.append('</head>')
        html.append('<body>')
        
        # é¡µé¢å¤´éƒ¨
        html.append('<div class="header">')
        html.append('<h1>ğŸ”’ TCPè½½è·æ©ç å™¨å¯è§†åŒ–æµ‹è¯•æŠ¥å‘Š</h1>')
        html.append(f'<p class="timestamp">ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>')
        html.append('</div>')
        
        # æ¦‚è§ˆä¿¡æ¯
        html.append('<div class="overview">')
        html.append('<h2>ğŸ“Š æµ‹è¯•æ¦‚è§ˆ</h2>')
        html.append('<div class="overview-grid">')
        html.append(f'<div class="overview-item"><strong>æ€»åœºæ™¯æ•°:</strong> {summary["total_scenarios"]}</div>')
        html.append(f'<div class="overview-item"><strong>æˆåŠŸåœºæ™¯:</strong> {summary["successful_scenarios"]}</div>')
        html.append(f'<div class="overview-item"><strong>æˆåŠŸç‡:</strong> {summary["success_rate"]:.1f}%</div>')
        html.append(f'<div class="overview-item"><strong>å¹³å‡å‡†ç¡®ç‡:</strong> {summary["average_accuracy"]*100:.1f}%</div>')
        html.append('</div>')
        html.append('</div>')
        
        # ç»Ÿè®¡å›¾è¡¨
        html.append(self.generate_statistics_charts(test_results))
        
        # è¯¦ç»†åœºæ™¯ç»“æœ
        html.append('<div class="scenarios">')
        html.append('<h2>ğŸ¯ è¯¦ç»†åœºæ™¯ç»“æœ</h2>')
        
        for result in test_results['results']:
            scenario = result['scenario']
            test_result = result['result']
            verification = result['verification']
            
            status_class = 'success' if test_result.success else 'failure'
            status_icon = 'âœ…' if test_result.success else 'âŒ'
            
            html.append(f'<div class="scenario-item {status_class}">')
            html.append(f'<h3>{status_icon} {scenario["config"]["metadata"]["name"]}</h3>')
            html.append(f'<p><strong>æè¿°:</strong> {scenario["config"]["metadata"]["description"]}</p>')
            html.append('<div class="scenario-metrics">')
            html.append(f'<span>æ‰§è¡Œæ—¶é—´: {test_result.execution_time:.3f}s</span>')
            html.append(f'<span>é¢„æœŸä¿®æ”¹: {test_result.expected_packets}åŒ…</span>')
            html.append(f'<span>å®é™…ä¿®æ”¹: {test_result.actual_packets}åŒ…</span>')
            html.append(f'<span>å‡†ç¡®ç‡: {verification.get("accuracy", 0)*100:.1f}%</span>')
            html.append('</div>')
            
            if result['result'].errors:
                html.append('<div class="errors">')
                html.append('<h4>é”™è¯¯ä¿¡æ¯:</h4>')
                html.append('<ul>')
                for error in result['result'].errors:
                    html.append(f'<li>{error}</li>')
                html.append('</ul>')
                html.append('</div>')
            
            html.append('</div>')
        
        html.append('</div>')
        
        # åå…­è¿›åˆ¶å¯¹æ¯”ï¼ˆå¦‚æœæœ‰æ•°æ®åŒ…å¯¹æ¯”ä¿¡æ¯ï¼‰
        if packet_comparisons:
            html.append('<div class="hex-comparisons">')
            html.append('<h2>ğŸ” æ•°æ®åŒ…åå…­è¿›åˆ¶å¯¹æ¯”</h2>')
            
            for comp in packet_comparisons[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªä¿®æ”¹çš„åŒ…
                if comp.payload_modified:
                    # è¿™é‡Œéœ€è¦åŸå§‹æ•°æ®ï¼Œæš‚æ—¶ç”¨å ä½ç¬¦
                    html.append(f'<div class="packet-comparison">')
                    html.append(f'<h4>æ•°æ®åŒ… #{comp.packet_number}</h4>')
                    html.append(f'<p>æ©ç å­—èŠ‚: {comp.masked_bytes}, ä¿ç•™å­—èŠ‚: {comp.kept_bytes}</p>')
                    html.append(f'<p class="note">æ³¨: è¯¦ç»†åå…­è¿›åˆ¶å¯¹æ¯”éœ€è¦åŸå§‹æ•°æ®åŒ…ä¿¡æ¯</p>')
                    html.append('</div>')
            
            html.append('</div>')
        
        # é¡µè„š
        html.append('<div class="footer">')
        html.append('<p>TCPè½½è·æ©ç å™¨è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶ v2.0 | ç¬¬äº”é˜¶æ®µå¯è§†åŒ–å¢å¼ºç‰ˆ</p>')
        html.append('</div>')
        
        html.append('</body>')
        html.append('</html>')
        
        self.logger.info("âœ… HTMLå¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return '\n'.join(html)
    
    def _get_css_styles(self) -> str:
        """è·å–CSSæ ·å¼"""
        return '''
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f7fa;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .timestamp {
            opacity: 0.9;
            font-size: 1.1rem;
        }
        
        .overview {
            background: white;
            margin: 2rem;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
        }
        
        .overview h2 {
            color: #2c3e50;
            margin-bottom: 1rem;
            border-bottom: 2px solid #3498db;
            padding-bottom: 0.5rem;
        }
        
        .overview-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin-top: 1rem;
        }
        
        .overview-item {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
            border-left: 4px solid #3498db;
        }
        
        .charts-container {
            background: white;
            margin: 2rem;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
        }
        
        .chart {
            margin-bottom: 2rem;
            padding: 1rem;
            background: #fafbfc;
            border-radius: 8px;
        }
        
        .chart h3 {
            color: #2c3e50;
            margin-bottom: 1rem;
        }
        
        .pie-chart {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            background: conic-gradient(#e74c3c 0deg, #e74c3c 144deg, #27ae60 144deg, #27ae60 360deg);
            margin: 0 auto 1rem;
            position: relative;
        }
        
        .chart-legend, .legend {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .color-pass, .color-fail {
            width: 20px;
            height: 20px;
            border-radius: 3px;
        }
        
        .color-pass { background: #27ae60; }
        .color-fail { background: #e74c3c; }
        
        .bar-chart {
            max-width: 800px;
        }
        
        .bar-item {
            margin-bottom: 1rem;
        }
        
        .bar-label {
            font-weight: bold;
            margin-bottom: 0.5rem;
            color: #2c3e50;
        }
        
        .bar-container {
            position: relative;
            background: #ecf0f1;
            border-radius: 20px;
            height: 30px;
            overflow: hidden;
        }
        
        .bar {
            height: 100%;
            border-radius: 20px;
            position: relative;
            transition: width 0.5s ease;
        }
        
        .bar.success {
            background: linear-gradient(90deg, #27ae60, #2ecc71);
        }
        
        .bar.failure {
            background: linear-gradient(90deg, #e74c3c, #c0392b);
        }
        
        .bar-value {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: #2c3e50;
            font-weight: bold;
            font-size: 0.9rem;
        }
        
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
        }
        
        .metric-item {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            text-align: center;
            border: 1px solid #e1e8ed;
        }
        
        .metric-title {
            color: #657786;
            font-size: 0.9rem;
            margin-bottom: 0.5rem;
        }
        
        .metric-value {
            color: #2c3e50;
            font-size: 2rem;
            font-weight: bold;
        }
        
        .scenarios {
            background: white;
            margin: 2rem;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
        }
        
        .scenarios h2 {
            color: #2c3e50;
            margin-bottom: 1rem;
            border-bottom: 2px solid #3498db;
            padding-bottom: 0.5rem;
        }
        
        .scenario-item {
            margin-bottom: 1.5rem;
            padding: 1.5rem;
            border-radius: 8px;
            border-left: 4px solid #3498db;
        }
        
        .scenario-item.success {
            background: #d5f4e6;
            border-left-color: #27ae60;
        }
        
        .scenario-item.failure {
            background: #ffeaa7;
            border-left-color: #e17055;
        }
        
        .scenario-item h3 {
            color: #2c3e50;
            margin-bottom: 0.5rem;
        }
        
        .scenario-metrics {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
            flex-wrap: wrap;
        }
        
        .scenario-metrics span {
            background: rgba(255,255,255,0.7);
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.9rem;
            border: 1px solid rgba(0,0,0,0.1);
        }
        
        .errors {
            margin-top: 1rem;
            padding: 1rem;
            background: #ffebee;
            border-radius: 5px;
            border-left: 4px solid #f44336;
        }
        
        .errors h4 {
            color: #d32f2f;
            margin-bottom: 0.5rem;
        }
        
        .errors ul {
            margin-left: 1.5rem;
        }
        
        .errors li {
            color: #b71c1c;
            margin-bottom: 0.3rem;
        }
        
        .hex-comparisons {
            background: white;
            margin: 2rem;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.1);
        }
        
        .hex-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
        }
        
        .hex-table th, .hex-table td {
            border: 1px solid #ddd;
            padding: 0.5rem;
            text-align: left;
        }
        
        .hex-table th {
            background: #f5f5f5;
            font-weight: bold;
        }
        
        .hex-data {
            font-family: 'Courier New', monospace;
            white-space: nowrap;
        }
        
        .kept { background-color: #d4edda; color: #155724; }
        .masked { background-color: #f8d7da; color: #721c24; }
        .unchanged { background-color: #e2e3e5; color: #383d41; }
        .error { background-color: #fff3cd; color: #856404; }
        
        .legend span {
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-size: 0.8rem;
            margin-right: 0.5rem;
        }
        
        .packet-comparison {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 5px;
            border-left: 4px solid #007bff;
        }
        
        .note {
            font-style: italic;
            color: #6c757d;
            margin-top: 0.5rem;
        }
        
        .footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 1rem;
            margin-top: 2rem;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .overview, .charts-container, .scenarios, .hex-comparisons {
                margin: 1rem;
                padding: 1rem;
            }
            
            .scenario-metrics {
                flex-direction: column;
            }
        }
        '''


class PacketLevelValidator:
    """æ•°æ®åŒ…çº§éªŒè¯å™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def verify_packet_modifications(self, original_pcap: str, modified_pcap: str, 
                                  config: Dict[str, Any]) -> List[PacketComparison]:
        """éªŒè¯æ•°æ®åŒ…çº§åˆ«çš„ä¿®æ”¹æ­£ç¡®æ€§"""
        self.logger.info("ğŸ” å¼€å§‹æ•°æ®åŒ…çº§éªŒè¯...")
        
        # è¯»å–åŸå§‹å’Œä¿®æ”¹åçš„æ•°æ®åŒ…
        try:
            original_packets = rdpcap(original_pcap)
            modified_packets = rdpcap(modified_pcap)
        except Exception as e:
            self.logger.error(f"è¯»å–PCAPæ–‡ä»¶å¤±è´¥: {e}")
            return []
        
        if len(original_packets) != len(modified_packets):
            self.logger.error(f"æ•°æ®åŒ…æ•°é‡ä¸åŒ¹é…: åŸå§‹{len(original_packets)} vs ä¿®æ”¹å{len(modified_packets)}")
            return []
        
        comparisons = []
        for i, (orig_pkt, mod_pkt) in enumerate(zip(original_packets, modified_packets)):
            comparison = self._compare_single_packet(i + 1, orig_pkt, mod_pkt, config)
            comparisons.append(comparison)
        
        self.logger.info(f"âœ… å®Œæˆ{len(comparisons)}ä¸ªæ•°æ®åŒ…çš„éªŒè¯")
        return comparisons
    
    def _compare_single_packet(self, packet_num: int, original: Packet, 
                              modified: Packet, config: Dict[str, Any]) -> PacketComparison:
        """æ¯”è¾ƒå•ä¸ªæ•°æ®åŒ…"""
        comparison = PacketComparison(
            packet_number=packet_num,
            original_size=len(original),
            modified_size=len(modified),
            payload_modified=False,
            header_modified=False,
            modifications=[],
            masked_bytes=0,
            kept_bytes=0
        )
        
        # æ£€æŸ¥æ•°æ®åŒ…å¤§å°
        if comparison.original_size != comparison.modified_size:
            comparison.header_modified = True
            comparison.modifications.append({
                'type': 'size_change',
                'original': comparison.original_size,
                'modified': comparison.modified_size
            })
        
        # æ¯”è¾ƒç½‘ç»œå¤´éƒ¨ï¼ˆåº”è¯¥ä¿æŒä¸å˜ï¼‰
        if original.payload and modified.payload:
            orig_bytes = bytes(original)
            mod_bytes = bytes(modified)
            
            # æ£€æŸ¥è½½è·éƒ¨åˆ†
            if hasattr(original, 'load') and hasattr(modified, 'load'):
                if original.load != modified.load:
                    comparison.payload_modified = True
                    
                    # è®¡ç®—æ©ç å’Œä¿ç•™å­—èŠ‚
                    orig_payload = bytes(original.load) if original.load else b''
                    mod_payload = bytes(modified.load) if modified.load else b''
                    
                    if len(orig_payload) == len(mod_payload):
                        for j, (orig_byte, mod_byte) in enumerate(zip(orig_payload, mod_payload)):
                            if orig_byte != mod_byte:
                                comparison.masked_bytes += 1
                            else:
                                comparison.kept_bytes += 1
        
        return comparison
    
    def generate_packet_diff_report(self, comparisons: List[PacketComparison]) -> str:
        """ç”Ÿæˆæ•°æ®åŒ…å·®å¼‚æŠ¥å‘Š"""
        report = ["## ğŸ“¦ æ•°æ®åŒ…çº§éªŒè¯æŠ¥å‘Š\n"]
        
        modified_packets = [c for c in comparisons if c.payload_modified]
        
        report.append(f"- **æ€»æ•°æ®åŒ…æ•°**: {len(comparisons)}")
        report.append(f"- **ä¿®æ”¹çš„æ•°æ®åŒ…æ•°**: {len(modified_packets)}")
        report.append(f"- **ä¿®æ”¹ç‡**: {len(modified_packets)/len(comparisons)*100:.1f}%")
        report.append("")
        
        if modified_packets:
            report.append("### ä¿®æ”¹çš„æ•°æ®åŒ…è¯¦æƒ…")
            for comp in modified_packets[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                report.append(f"**æ•°æ®åŒ… #{comp.packet_number}**:")
                report.append(f"- è½½è·ä¿®æ”¹: {'æ˜¯' if comp.payload_modified else 'å¦'}")
                report.append(f"- æ©ç å­—èŠ‚: {comp.masked_bytes}")
                report.append(f"- ä¿ç•™å­—èŠ‚: {comp.kept_bytes}")
                report.append("")
        
        return "\n".join(report)


class StatisticalValidator:
    """ç»Ÿè®¡çº§éªŒè¯å™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def verify_processing_statistics(self, expected: Dict[str, Any], 
                                   actual: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("ğŸ“Š å¼€å§‹ç»Ÿè®¡éªŒè¯...")
        
        validation = {
            'success': True,
            'errors': [],
            'comparisons': {},
            'accuracy': 0.0
        }
        
        # éªŒè¯ä¿®æ”¹åŒ…æ•°é‡
        if 'modified_packets' in expected and 'modified_packets' in actual:
            exp_packets = expected['modified_packets']
            act_packets = actual['modified_packets']
            
            validation['comparisons']['modified_packets'] = {
                'expected': exp_packets,
                'actual': act_packets,
                'match': exp_packets == act_packets,
                'accuracy': min(exp_packets, act_packets) / max(exp_packets, act_packets) if max(exp_packets, act_packets) > 0 else 1.0
            }
            
            if exp_packets != act_packets:
                validation['errors'].append(f"ä¿®æ”¹åŒ…æ•°é‡ä¸åŒ¹é…: æœŸæœ›{exp_packets}, å®é™…{act_packets}")
        
        # éªŒè¯æ©ç å­—èŠ‚æ•°
        if 'masked_bytes' in expected and 'masked_bytes' in actual:
            exp_bytes = expected['masked_bytes']
            act_bytes = actual['masked_bytes']
            
            validation['comparisons']['masked_bytes'] = {
                'expected': exp_bytes,
                'actual': act_bytes,
                'match': exp_bytes == act_bytes,
                'accuracy': min(exp_bytes, act_bytes) / max(exp_bytes, act_bytes) if max(exp_bytes, act_bytes) > 0 else 1.0
            }
            
            if exp_bytes != act_bytes:
                validation['errors'].append(f"æ©ç å­—èŠ‚æ•°ä¸åŒ¹é…: æœŸæœ›{exp_bytes}, å®é™…{act_bytes}")
        
        # éªŒè¯ä¿ç•™å­—èŠ‚æ•°
        if 'kept_bytes' in expected and 'kept_bytes' in actual:
            exp_bytes = expected['kept_bytes']
            act_bytes = actual['kept_bytes']
            
            validation['comparisons']['kept_bytes'] = {
                'expected': exp_bytes,
                'actual': act_bytes,
                'match': exp_bytes == act_bytes,
                'accuracy': min(exp_bytes, act_bytes) / max(exp_bytes, act_bytes) if max(exp_bytes, act_bytes) > 0 else 1.0
            }
            
            if exp_bytes != act_bytes:
                validation['errors'].append(f"ä¿ç•™å­—èŠ‚æ•°ä¸åŒ¹é…: æœŸæœ›{exp_bytes}, å®é™…{act_bytes}")
        
        # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
        accuracies = [comp['accuracy'] for comp in validation['comparisons'].values()]
        validation['accuracy'] = sum(accuracies) / len(accuracies) if accuracies else 0.0
        
        if validation['errors']:
            validation['success'] = False
        
        self.logger.info(f"âœ… ç»Ÿè®¡éªŒè¯å®Œæˆï¼Œå‡†ç¡®ç‡: {validation['accuracy']:.1%}")
        return validation


class IntegrityValidator:
    """å®Œæ•´æ€§éªŒè¯å™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def verify_file_integrity(self, original_pcap: str, modified_pcap: str) -> Dict[str, Any]:
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        self.logger.info("ğŸ”’ å¼€å§‹å®Œæ•´æ€§éªŒè¯...")
        
        integrity = {
            'success': True,
            'errors': [],
            'file_sizes': {},
            'packet_counts': {},
            'timestamp_consistency': True,
            'network_headers_preserved': True
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
            orig_path = Path(original_pcap)
            mod_path = Path(modified_pcap)
            
            if not orig_path.exists():
                integrity['errors'].append(f"åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {original_pcap}")
                integrity['success'] = False
                return integrity
            
            if not mod_path.exists():
                integrity['errors'].append(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {modified_pcap}")
                integrity['success'] = False
                return integrity
            
            integrity['file_sizes'] = {
                'original': orig_path.stat().st_size,
                'modified': mod_path.stat().st_size
            }
            
            # è¯»å–æ•°æ®åŒ…
            original_packets = rdpcap(original_pcap)
            modified_packets = rdpcap(modified_pcap)
            
            integrity['packet_counts'] = {
                'original': len(original_packets),
                'modified': len(modified_packets)
            }
            
            # éªŒè¯åŒ…æ•°é‡ä¸€è‡´æ€§
            if len(original_packets) != len(modified_packets):
                integrity['errors'].append(f"æ•°æ®åŒ…æ•°é‡ä¸ä¸€è‡´: {len(original_packets)} vs {len(modified_packets)}")
                integrity['success'] = False
            
            # éªŒè¯æ—¶é—´æˆ³ä¸€è‡´æ€§
            for i, (orig_pkt, mod_pkt) in enumerate(zip(original_packets[:10], modified_packets[:10])):
                if hasattr(orig_pkt, 'time') and hasattr(mod_pkt, 'time'):
                    if abs(orig_pkt.time - mod_pkt.time) > 0.001:  # å…è®¸1msè¯¯å·®
                        integrity['timestamp_consistency'] = False
                        integrity['errors'].append(f"åŒ…{i+1}æ—¶é—´æˆ³ä¸ä¸€è‡´")
                        break
            
            # éªŒè¯ç½‘ç»œå¤´éƒ¨ä¿æŒä¸å˜
            self._verify_network_headers(original_packets[:5], modified_packets[:5], integrity)
            
        except Exception as e:
            integrity['errors'].append(f"å®Œæ•´æ€§éªŒè¯å¼‚å¸¸: {str(e)}")
            integrity['success'] = False
        
        self.logger.info(f"âœ… å®Œæ•´æ€§éªŒè¯å®Œæˆï¼ŒçŠ¶æ€: {'é€šè¿‡' if integrity['success'] else 'å¤±è´¥'}")
        return integrity
    
    def _verify_network_headers(self, original_packets: List[Packet], 
                               modified_packets: List[Packet], 
                               integrity: Dict[str, Any]) -> None:
        """éªŒè¯ç½‘ç»œå¤´éƒ¨ä¿æŒä¸å˜"""
        for i, (orig_pkt, mod_pkt) in enumerate(zip(original_packets, modified_packets)):
            try:
                # æ£€æŸ¥ä»¥å¤ªç½‘å¤´éƒ¨
                if Ether in orig_pkt and Ether in mod_pkt:
                    if orig_pkt[Ether].src != mod_pkt[Ether].src or orig_pkt[Ether].dst != mod_pkt[Ether].dst:
                        integrity['network_headers_preserved'] = False
                        integrity['errors'].append(f"åŒ…{i+1}ä»¥å¤ªç½‘å¤´éƒ¨è¢«ä¿®æ”¹")
                        break
                
                # æ£€æŸ¥IPå¤´éƒ¨
                if IP in orig_pkt and IP in mod_pkt:
                    orig_ip = orig_pkt[IP]
                    mod_ip = mod_pkt[IP]
                    if (orig_ip.src != mod_ip.src or orig_ip.dst != mod_ip.dst or 
                        orig_ip.proto != mod_ip.proto):
                        integrity['network_headers_preserved'] = False
                        integrity['errors'].append(f"åŒ…{i+1}IPå¤´éƒ¨è¢«ä¿®æ”¹")
                        break
                
                # æ£€æŸ¥TCPå¤´éƒ¨ï¼ˆé™¤äº†æ ¡éªŒå’Œï¼‰
                if TCP in orig_pkt and TCP in mod_pkt:
                    orig_tcp = orig_pkt[TCP]
                    mod_tcp = mod_pkt[TCP]
                    if (orig_tcp.sport != mod_tcp.sport or orig_tcp.dport != mod_tcp.dport or
                        orig_tcp.seq != mod_tcp.seq or orig_tcp.ack != mod_tcp.ack):
                        integrity['network_headers_preserved'] = False
                        integrity['errors'].append(f"åŒ…{i+1}TCPå¤´éƒ¨è¢«ä¿®æ”¹")
                        break
                        
            except Exception as e:
                integrity['errors'].append(f"éªŒè¯åŒ…{i+1}å¤´éƒ¨æ—¶å‡ºé”™: {str(e)}")


class TcpMaskerComprehensiveTest:
    """TCPæ©ç å™¨ç»¼åˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.scenarios_dir = Path("test_scenarios")
        self.sample_file = Path("tests/data/tls-single/tls_sample.pcap")
        self.output_dir = Path("test_outputs")
        self.report_dir = Path("test_reports")
        self.test_script = Path("run_tcp_masker_test.py")
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.output_dir.mkdir(exist_ok=True)
        self.report_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logging()
        
        # åˆå§‹åŒ–éªŒè¯å™¨
        self.packet_validator = PacketLevelValidator(self.logger)
        self.stats_validator = StatisticalValidator(self.logger)
        self.integrity_validator = IntegrityValidator(self.logger)
        # åˆå§‹åŒ–å¯è§†åŒ–ç”Ÿæˆå™¨
        self.visualization_generator = VisualizationGenerator(self.logger)
    
    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logger = logging.getLogger('TcpMaskerTest')
        logger.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_test_scenarios(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ‰€æœ‰æµ‹è¯•åœºæ™¯"""
        self.logger.info("ğŸ“ åŠ è½½æµ‹è¯•åœºæ™¯é…ç½®...")
        
        scenarios = []
        scenario_files = sorted(self.scenarios_dir.glob("scenario_*.yaml"))
        
        for scenario_file in scenario_files:
            try:
                with open(scenario_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                scenario = {
                    'name': scenario_file.stem,
                    'file': scenario_file,
                    'config': config
                }
                scenarios.append(scenario)
                
            except Exception as e:
                self.logger.error(f"åŠ è½½åœºæ™¯ {scenario_file} å¤±è´¥: {e}")
        
        self.logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
        return scenarios
    
    def run_single_scenario(self, scenario: Dict[str, Any]) -> TestScenarioResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•åœºæ™¯"""
        scenario_name = scenario['name']
        self.logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œåœºæ™¯: {scenario_name}")
        
        start_time = datetime.datetime.now()
        
        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶
        output_file = self.output_dir / f"{scenario_name}_output.pcap"
        
        result = TestScenarioResult(
            scenario_name=scenario_name,
            success=False,
            execution_time=0.0,
            expected_packets=0,
            actual_packets=0,
            expected_bytes=0,
            actual_bytes=0,
            packet_comparisons=[],
            statistics={},
            errors=[]
        )
        
        try:
            # è·å–é¢„æœŸç»“æœ
            metadata = scenario['config'].get('metadata', {})
            result.expected_packets = metadata.get('expected_modified_packets', 0)
            result.expected_bytes = metadata.get('expected_masked_bytes', 0)
            
            # æ‰§è¡Œæµ‹è¯•
            cmd = [
                sys.executable, str(self.test_script),
                "--input-pcap", str(self.sample_file),
                "--config", str(scenario['file']),
                "--output-pcap", str(output_file),
                "--log-level", "INFO"
            ]
            
            process_result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=60
            )
            
            if process_result.returncode == 0:
                result.success = True
                
                # è§£æè¾“å‡ºç»Ÿè®¡
                stats = self._parse_execution_output(process_result.stdout)
                result.statistics = stats
                result.actual_packets = stats.get('modified_packets', 0)
                result.actual_bytes = stats.get('masked_bytes', 0)
                
                # æ‰§è¡Œè¯¦ç»†éªŒè¯
                result.packet_comparisons = self.packet_validator.verify_packet_modifications(
                    str(self.sample_file), str(output_file), scenario['config']
                )
                
            else:
                result.errors.append(f"æ‰§è¡Œå¤±è´¥: {process_result.stderr}")
                
        except subprocess.TimeoutExpired:
            result.errors.append("æ‰§è¡Œè¶…æ—¶")
        except Exception as e:
            result.errors.append(f"æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        end_time = datetime.datetime.now()
        result.execution_time = (end_time - start_time).total_seconds()
        
        self.logger.info(f"âœ… åœºæ™¯ {scenario_name} æ‰§è¡Œå®Œæˆï¼Œç”¨æ—¶ {result.execution_time:.2f}s")
        return result
    
    def _parse_execution_output(self, stdout: str) -> Dict[str, Any]:
        """è§£ææ‰§è¡Œè¾“å‡ºä¸­çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        lines = stdout.split('\n')
        for line in lines:
            # åŒ¹é…æ ¼å¼: "TCPè½½è·æ©ç å¤„ç†æˆåŠŸ: 1/22 ä¸ªæ•°æ®åŒ…è¢«ä¿®æ”¹, æ©ç å­—èŠ‚: 512, ä¿ç•™å­—èŠ‚: 0"
            if 'TCPè½½è·æ©ç å¤„ç†æˆåŠŸ' in line:
                import re
                # æå–ä¿®æ”¹çš„åŒ…æ•°é‡
                match = re.search(r'(\d+)/\d+\s*ä¸ªæ•°æ®åŒ…è¢«ä¿®æ”¹', line)
                if match:
                    stats['modified_packets'] = int(match.group(1))
                
                # æå–æ©ç å­—èŠ‚æ•°
                mask_match = re.search(r'æ©ç å­—èŠ‚:\s*(\d+)', line)
                if mask_match:
                    stats['masked_bytes'] = int(mask_match.group(1))
                
                # æå–ä¿ç•™å­—èŠ‚æ•°
                keep_match = re.search(r'ä¿ç•™å­—èŠ‚:\s*(\d+)', line)
                if keep_match:
                    stats['kept_bytes'] = int(keep_match.group(1))
        
        return stats
    
    def verify_results(self, scenario: Dict[str, Any], result: TestScenarioResult) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•ç»“æœ"""
        self.logger.info(f"ğŸ” éªŒè¯åœºæ™¯ {result.scenario_name} çš„ç»“æœ...")
        
        verification = {
            'statistical_validation': {},
            'integrity_validation': {},
            'overall_success': True,
            'accuracy_score': 0.0
        }
        
        # ç»Ÿè®¡éªŒè¯
        expected_stats = {
            'modified_packets': result.expected_packets,
            'masked_bytes': result.expected_bytes,
        }
        
        actual_stats = {
            'modified_packets': result.actual_packets,
            'masked_bytes': result.actual_bytes,
        }
        
        verification['statistical_validation'] = self.stats_validator.verify_processing_statistics(
            expected_stats, actual_stats
        )
        
        # å®Œæ•´æ€§éªŒè¯
        output_file = self.output_dir / f"{result.scenario_name}_output.pcap"
        if output_file.exists():
            verification['integrity_validation'] = self.integrity_validator.verify_file_integrity(
                str(self.sample_file), str(output_file)
            )
        
        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        stat_success = verification['statistical_validation'].get('success', False)
        integrity_success = verification['integrity_validation'].get('success', False)
        
        verification['overall_success'] = stat_success and integrity_success and result.success
        
        # è®¡ç®—å‡†ç¡®ç‡åˆ†æ•°
        accuracy_score = verification['statistical_validation'].get('accuracy', 0.0)
        verification['accuracy_score'] = accuracy_score
        
        return verification
    
    def run_all_scenarios(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯"""
        self.logger.info("ğŸ¯ å¼€å§‹æ‰§è¡Œç»¼åˆæµ‹è¯•...")
        
        scenarios = self.load_test_scenarios()
        results = []
        
        for scenario in scenarios:
            # æ‰§è¡Œåœºæ™¯
            result = self.run_single_scenario(scenario)
            
            # éªŒè¯ç»“æœ
            verification = self.verify_results(scenario, result)
            
            results.append({
                'scenario': scenario,
                'result': result,
                'verification': verification
            })
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_results = {
            'execution_time': datetime.datetime.now(),
            'total_scenarios': len(scenarios),
            'results': results,
            'summary': self._generate_comprehensive_summary(results)
        }
        
        return comprehensive_results
    
    def _generate_comprehensive_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æ€»ç»“"""
        total_scenarios = len(results)
        successful_scenarios = sum(1 for r in results if r['verification']['overall_success'])
        
        # è®¡ç®—å¹³å‡å‡†ç¡®ç‡
        accuracy_scores = [r['verification']['accuracy_score'] for r in results]
        avg_accuracy = sum(accuracy_scores) / len(accuracy_scores) if accuracy_scores else 0.0
        
        # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
        execution_times = [r['result'].execution_time for r in results]
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0.0
        
        return {
            'total_scenarios': total_scenarios,
            'successful_scenarios': successful_scenarios,
            'success_rate': successful_scenarios / total_scenarios if total_scenarios > 0 else 0.0,
            'average_accuracy': avg_accuracy,
            'average_execution_time': avg_execution_time,
            'total_execution_time': sum(execution_times)
        }
    
    def generate_comprehensive_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        self.logger.info("ğŸ“„ ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š...")
        
        report = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append("# TCPè½½è·æ©ç å™¨ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        report.append("")
        report.append(f"**æµ‹è¯•æ—¶é—´**: {results['execution_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æµ‹è¯•æ ·æœ¬**: `tests/data/tls-single/tls_sample.pcap`")
        report.append("")
        
        # æ‰§è¡Œæ¦‚è§ˆ
        summary = results['summary']
        report.append("## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ")
        report.append("")
        report.append(f"- **æ€»åœºæ™¯æ•°**: {summary['total_scenarios']}")
        report.append(f"- **æˆåŠŸåœºæ™¯æ•°**: {summary['successful_scenarios']}")
        report.append(f"- **æˆåŠŸç‡**: {summary['success_rate']:.1%}")
        report.append(f"- **å¹³å‡å‡†ç¡®ç‡**: {summary['average_accuracy']:.1%}")
        report.append(f"- **å¹³å‡æ‰§è¡Œæ—¶é—´**: {summary['average_execution_time']:.2f}ç§’")
        report.append(f"- **æ€»æ‰§è¡Œæ—¶é—´**: {summary['total_execution_time']:.2f}ç§’")
        report.append("")
        
        # åœºæ™¯è¯¦ç»†ç»“æœ
        report.append("## ğŸ¯ åœºæ™¯æµ‹è¯•ç»“æœ")
        report.append("")
        
        for item in results['results']:
            scenario = item['scenario']
            result = item['result']
            verification = item['verification']
            
            status = "âœ… é€šè¿‡" if verification['overall_success'] else "âŒ å¤±è´¥"
            
            report.append(f"### {result.scenario_name}")
            report.append(f"- **çŠ¶æ€**: {status}")
            report.append(f"- **æè¿°**: {scenario['config'].get('metadata', {}).get('description', 'N/A')}")
            report.append(f"- **æ‰§è¡Œæ—¶é—´**: {result.execution_time:.2f}ç§’")
            report.append(f"- **é¢„æœŸä¿®æ”¹åŒ…æ•°**: {result.expected_packets}")
            report.append(f"- **å®é™…ä¿®æ”¹åŒ…æ•°**: {result.actual_packets}")
            report.append(f"- **å‡†ç¡®ç‡**: {verification['accuracy_score']:.1%}")
            
            if result.errors:
                report.append(f"- **é”™è¯¯**: {'; '.join(result.errors)}")
            
            report.append("")
        
        # æ•°æ®åŒ…çº§éªŒè¯æ±‡æ€»
        if results['results']:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœä½œä¸ºç¤ºä¾‹
            successful_result = next((r for r in results['results'] if r['verification']['overall_success']), None)
            if successful_result and successful_result['result'].packet_comparisons:
                packet_report = self.packet_validator.generate_packet_diff_report(
                    successful_result['result'].packet_comparisons
                )
                report.append(packet_report)
        
        # æ€§èƒ½æŒ‡æ ‡
        report.append("## âš¡ æ€§èƒ½æŒ‡æ ‡")
        report.append("")
        report.append(f"- **å¹³å‡å¤„ç†é€Ÿåº¦**: {22/summary['average_execution_time']:.0f} pps") # 22åŒ…
        report.append(f"- **æœ€å¿«åœºæ™¯**: {min(r['result'].execution_time for r in results['results']):.2f}ç§’")
        report.append(f"- **æœ€æ…¢åœºæ™¯**: {max(r['result'].execution_time for r in results['results']):.2f}ç§’")
        report.append("")
        
        # å»ºè®®å’Œæ€»ç»“
        report.append("## ğŸ’¡ æµ‹è¯•æ€»ç»“")
        report.append("")
        
        if summary['success_rate'] >= 0.8:
            report.append("ğŸ‰ **æµ‹è¯•ç»“æœä¼˜ç§€**ï¼šå¤§å¤šæ•°åœºæ™¯æµ‹è¯•é€šè¿‡ï¼ŒTCPè½½è·æ©ç å™¨åŠŸèƒ½æ­£å¸¸ã€‚")
        elif summary['success_rate'] >= 0.6:
            report.append("âš ï¸ **æµ‹è¯•ç»“æœè‰¯å¥½**ï¼šéƒ¨åˆ†åœºæ™¯éœ€è¦ä¼˜åŒ–ï¼Œå»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹ã€‚")
        else:
            report.append("ğŸš¨ **æµ‹è¯•ç»“æœéœ€è¦æ”¹è¿›**ï¼šå¤šä¸ªåœºæ™¯æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦é‡ç‚¹ä¿®å¤ç›¸å…³åŠŸèƒ½ã€‚")
        
        report.append("")
        report.append("### æ”¹è¿›å»ºè®®")
        
        if summary['average_accuracy'] < 0.9:
            report.append("- æé«˜åºåˆ—å·åŒ¹é…ç²¾åº¦")
        
        if summary['average_execution_time'] > 5.0:
            report.append("- ä¼˜åŒ–å¤„ç†æ€§èƒ½")
        
        failed_scenarios = [r for r in results['results'] if not r['verification']['overall_success']]
        if failed_scenarios:
            report.append(f"- é‡ç‚¹æ£€æŸ¥å¤±è´¥çš„ {len(failed_scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
        
        return "\n".join(report)
    
    def generate_visual_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¯è§†åŒ–HTMLæŠ¥å‘Š"""
        self.logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–HTMLæŠ¥å‘Š...")
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®åŒ…å¯¹æ¯”ä¿¡æ¯
        all_packet_comparisons = []
        for item in results['results']:
            all_packet_comparisons.extend(item['result'].packet_comparisons)
        
        # ä½¿ç”¨VisualizationGeneratorç”ŸæˆHTMLæŠ¥å‘Š
        html_report = self.visualization_generator.generate_visual_html_report(
            results, all_packet_comparisons
        )
        
        return html_report


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TCPè½½è·æ©ç å™¨ç»¼åˆæµ‹è¯•ç³»ç»Ÿ')
    parser.add_argument('--visual', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–HTMLæŠ¥å‘Š')
    parser.add_argument('--html-only', action='store_true', help='åªç”ŸæˆHTMLæŠ¥å‘Šï¼Œä¸ç”ŸæˆMarkdownæŠ¥å‘Š')
    args = parser.parse_args()
    
    print("ğŸ§ª TCPè½½è·æ©ç å™¨ç»¼åˆæµ‹è¯•ç³»ç»Ÿ v2.0")
    print("ç¬¬äº”é˜¶æ®µå¯è§†åŒ–å¢å¼ºç‰ˆ")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test_suite = TcpMaskerComprehensiveTest()
    
    try:
        # æ‰§è¡Œç»¼åˆæµ‹è¯•
        results = test_suite.run_all_scenarios()
        
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ç”ŸæˆMarkdownæŠ¥å‘Šï¼ˆé™¤éæŒ‡å®šåªç”ŸæˆHTMLï¼‰
        if not args.html_only:
            report = test_suite.generate_comprehensive_report(results)
            report_file = test_suite.report_dir / f"comprehensive_test_report_{timestamp}.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ MarkdownæŠ¥å‘Š: {report_file}")
        
        # ç”ŸæˆHTMLå¯è§†åŒ–æŠ¥å‘Šï¼ˆå¦‚æœè¯·æ±‚ï¼‰
        if args.visual or args.html_only:
            html_report = test_suite.generate_visual_report(results)
            html_file = test_suite.report_dir / f"visual_test_report_{timestamp}.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_report)
            print(f"ğŸ¨ HTMLå¯è§†åŒ–æŠ¥å‘Š: {html_file}")
        
        # æ˜¾ç¤ºæ€»ç»“
        summary = results['summary']
        print(f"\nğŸ¯ æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š æˆåŠŸç‡: {summary['success_rate']:.1%} ({summary['successful_scenarios']}/{summary['total_scenarios']})")
        print(f"âš¡ å¹³å‡å‡†ç¡®ç‡: {summary['average_accuracy']:.1%}")
        print(f"â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.2f}ç§’")
        
        if args.visual or args.html_only:
            print(f"ğŸ¨ å¯è§†åŒ–åŠŸèƒ½: å·²å¯ç”¨")
            print(f"   - äº¤äº’å¼å›¾è¡¨: âœ…")
            print(f"   - åå…­è¿›åˆ¶å¯¹æ¯”: âœ…")
            print(f"   - å“åº”å¼è®¾è®¡: âœ…")
        
        # è¿”å›æˆåŠŸç 
        return 0 if summary['success_rate'] >= 0.8 else 1
        
    except Exception as e:
        test_suite.logger.error(f"ç»¼åˆæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 