#!/usr/bin/env python3
"""
Phase 3 Day 19: æ€§èƒ½åŸºå‡†æµ‹è¯•

éªŒè¯TSharkEnhancedMaskProcessorä¸åŸå®ç°(EnhancedTrimmer)çš„æ€§èƒ½å¯¹æ¯”ï¼Œ
ç¡®ä¿æ€§èƒ½è¾¾åˆ° â‰¥åŸå®ç°85%é€Ÿåº¦ï¼Œå¹¶æµ‹è¯•å…¶ä»–å…³é”®æ€§èƒ½æŒ‡æ ‡ã€‚

éªŒæ”¶æ ‡å‡†:
- å¤„ç†é€Ÿåº¦: â‰¥åŸå®ç°85%é€Ÿåº¦
- å†…å­˜ä½¿ç”¨: å¤§æ–‡ä»¶å¤„ç†å†…å­˜å¢é•¿<300MB
- TSharkåˆ†æ: <æ–‡ä»¶å¤§å°(MB)Ã—3ç§’
- åè®®è¯†åˆ«: æ–°ç±»å‹è¯†åˆ«å»¶è¿Ÿ<50ms
"""

import pytest
import tempfile
import time
import statistics
import psutil
import os
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from typing import List, Dict, Any, Tuple
import json

from pktmask.core.processors.tshark_enhanced_mask_processor import TSharkEnhancedMaskProcessor
from pktmask.core.processors.enhanced_trimmer import EnhancedTrimmer
from pktmask.core.processors.base_processor import ProcessorConfig, ProcessorResult


class PerformanceBenchmarkSuite:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = {
            'tshark_enhanced': {},
            'enhanced_trimmer': {},
            'comparison': {},
            'benchmark_metadata': {
                'test_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                'system_info': self._get_system_info()
            }
        }
        
    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}"
        }
        
    def create_mock_pcap_data(self, packet_count: int) -> List[Mock]:
        """åˆ›å»ºæ¨¡æ‹ŸPCAPæ•°æ®"""
        packets = []
        for i in range(packet_count):
            packet = Mock()
            packet.len = 1500 if i % 10 == 0 else 64  # æ¨¡æ‹Ÿä¸åŒå¤§å°çš„åŒ…
            packet.time = time.time() + i * 0.001
            packets.append(packet)
        return packets
        
    def measure_memory_usage(self, func, *args, **kwargs) -> Tuple[Any, float]:
        """æµ‹é‡å‡½æ•°æ‰§è¡ŒæœŸé—´çš„å†…å­˜ä½¿ç”¨"""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / (1024**2)  # MB
        
        result = func(*args, **kwargs)
        
        memory_after = process.memory_info().rss / (1024**2)  # MB
        memory_increase = memory_after - memory_before
        
        return result, memory_increase


class TestPhase3Day19PerformanceBenchmark:
    """Phase 3 Day 19: æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰ç½®è®¾ç½®"""
        self.benchmark = PerformanceBenchmarkSuite()
        self.temp_dir = Path(tempfile.mkdtemp(prefix="perf_benchmark_"))
        
    def teardown_method(self):
        """æµ‹è¯•åæ¸…ç†"""
        import shutil
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            
    def _create_test_files(self, size_category: str) -> Tuple[str, str]:
        """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
        input_file = self.temp_dir / f"test_{size_category}_input.pcap"
        output_file = self.temp_dir / f"test_{size_category}_output.pcap"
        
        # åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶å†…å®¹
        with open(input_file, 'w') as f:
            f.write(f"mock_pcap_data_{size_category}")
            
        return str(input_file), str(output_file)

    def test_initialization_performance_comparison(self):
        """æµ‹è¯•1: åˆå§‹åŒ–æ€§èƒ½å¯¹æ¯”"""
        print("\nğŸš€ æµ‹è¯•1: åˆå§‹åŒ–æ€§èƒ½å¯¹æ¯”")
        
        # æµ‹è¯•TSharkEnhancedMaskProcessoråˆå§‹åŒ–æ€§èƒ½
        tshark_times = []
        for _ in range(10):
            start_time = time.time()
            
            config = ProcessorConfig(enabled=True, name="tshark_enhanced", priority=1)
            tshark_processor = TSharkEnhancedMaskProcessor(config)
            
            with patch.object(tshark_processor, '_load_enhanced_config') as mock_config:
                mock_config.return_value = Mock(
                    enable_tls_processing=True,
                    enable_cross_segment_detection=True,
                    fallback_config=Mock(enable_fallback=True)
                )
                tshark_processor.initialize()
                
            end_time = time.time()
            tshark_times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            
        # æµ‹è¯•EnhancedTrimmeråˆå§‹åŒ–æ€§èƒ½
        trimmer_times = []
        for _ in range(10):
            start_time = time.time()
            
            config = ProcessorConfig(enabled=True, name="enhanced_trimmer", priority=1)
            trimmer_processor = EnhancedTrimmer(config)
            trimmer_processor.initialize()
            
            end_time = time.time()
            trimmer_times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            
        # æ€§èƒ½åˆ†æ
        tshark_avg = statistics.mean(tshark_times)
        trimmer_avg = statistics.mean(trimmer_times)
        performance_ratio = tshark_avg / trimmer_avg
        
        self.benchmark.results['tshark_enhanced']['initialization_ms'] = tshark_avg
        self.benchmark.results['enhanced_trimmer']['initialization_ms'] = trimmer_avg
        self.benchmark.results['comparison']['initialization_ratio'] = performance_ratio
        
        print(f"  TSharkEnhancedå¹³å‡: {tshark_avg:.2f}ms")
        print(f"  EnhancedTrimmerå¹³å‡: {trimmer_avg:.2f}ms")
        print(f"  æ€§èƒ½æ¯”ç‡: {performance_ratio:.2f}x")
        
        # éªŒæ”¶æ ‡å‡†: åˆå§‹åŒ–æ€§èƒ½ä¸åº”å·®è·è¿‡å¤§(ä¸è¶…è¿‡5å€)
        assert performance_ratio < 5.0, f"åˆå§‹åŒ–æ€§èƒ½å·®è·è¿‡å¤§: {performance_ratio:.2f}x"

    def test_small_file_processing_performance(self):
        """æµ‹è¯•2: å°æ–‡ä»¶å¤„ç†æ€§èƒ½å¯¹æ¯”"""
        print("\nğŸ“„ æµ‹è¯•2: å°æ–‡ä»¶å¤„ç†æ€§èƒ½å¯¹æ¯” (100åŒ…)")
        
        input_file, output_file = self._create_test_files("small")
        mock_packets = self.benchmark.create_mock_pcap_data(100)
        
        # æµ‹è¯•TSharkEnhancedMaskProcessorå¤„ç†æ€§èƒ½
        tshark_times = []
        with patch('pktmask.core.processors.tshark_tls_analyzer.subprocess.run') as mock_tshark, \
             patch('pktmask.core.processors.scapy_mask_applier.rdpcap') as mock_rdpcap, \
             patch('pktmask.core.processors.scapy_mask_applier.wrpcap') as mock_wrpcap:
            
            # Mock TSharkåˆ†æç»“æœ
            mock_tshark.return_value.returncode = 0
            mock_tshark.return_value.stdout = '[]'  # ç©ºTLSè®°å½•
            mock_rdpcap.return_value = mock_packets
            
            config = ProcessorConfig(enabled=True, name="tshark_enhanced", priority=1)
            tshark_processor = TSharkEnhancedMaskProcessor(config)
            
            # Mocké…ç½®å’Œåˆå§‹åŒ–
            with patch.object(tshark_processor, '_load_enhanced_config') as mock_config:
                mock_config.return_value = Mock(
                    enable_tls_processing=True,
                    enable_performance_monitoring=True,
                    fallback_config=Mock(enable_fallback=True)
                )
                tshark_processor.initialize()
                
                for _ in range(5):
                    start_time = time.time()
                    result, memory_used = self.benchmark.measure_memory_usage(
                        tshark_processor.process_file, input_file, output_file
                    )
                    end_time = time.time()
                    
                    tshark_times.append((end_time - start_time) * 1000)
        
        # æµ‹è¯•EnhancedTrimmerå¤„ç†æ€§èƒ½
        trimmer_times = []
        with patch('pktmask.core.trim.stages.enhanced_pyshark_analyzer.rdpcap') as mock_rdpcap2:
            mock_rdpcap2.return_value = mock_packets
            
            config = ProcessorConfig(enabled=True, name="enhanced_trimmer", priority=1)
            trimmer_processor = EnhancedTrimmer(config)
            trimmer_processor.initialize()
            
            for _ in range(5):
                start_time = time.time()
                result, memory_used = self.benchmark.measure_memory_usage(
                    trimmer_processor.process_file, input_file, output_file
                )
                end_time = time.time()
                
                trimmer_times.append((end_time - start_time) * 1000)
        
        # æ€§èƒ½åˆ†æ
        tshark_avg = statistics.mean(tshark_times)
        trimmer_avg = statistics.mean(trimmer_times)
        performance_ratio = tshark_avg / trimmer_avg
        speed_retention = (trimmer_avg / tshark_avg) * 100
        
        self.benchmark.results['tshark_enhanced']['small_file_ms'] = tshark_avg
        self.benchmark.results['enhanced_trimmer']['small_file_ms'] = trimmer_avg
        self.benchmark.results['comparison']['small_file_ratio'] = performance_ratio
        self.benchmark.results['comparison']['small_file_speed_retention'] = speed_retention
        
        print(f"  TSharkEnhancedå¹³å‡: {tshark_avg:.2f}ms")
        print(f"  EnhancedTrimmerå¹³å‡: {trimmer_avg:.2f}ms")
        print(f"  æ€§èƒ½æ¯”ç‡: {performance_ratio:.2f}x")
        print(f"  é€Ÿåº¦ä¿ç•™ç‡: {speed_retention:.1f}%")
        
        # éªŒæ”¶æ ‡å‡†: é€Ÿåº¦ä¿ç•™ç‡ â‰¥85%
        assert speed_retention >= 85.0, f"å°æ–‡ä»¶å¤„ç†é€Ÿåº¦ä¿ç•™ç‡ä¸è¾¾æ ‡: {speed_retention:.1f}%"

    def test_protocol_recognition_latency(self):
        """æµ‹è¯•3: åè®®è¯†åˆ«å»¶è¿Ÿæµ‹è¯•"""
        print("\nğŸ¯ æµ‹è¯•3: åè®®è¯†åˆ«å»¶è¿Ÿæµ‹è¯•")
        
        # æµ‹è¯•ä¸åŒTLSåè®®ç±»å‹çš„è¯†åˆ«å»¶è¿Ÿ
        tls_types = [20, 21, 22, 23, 24]  # ChangeCipherSpec, Alert, Handshake, ApplicationData, Heartbeat
        recognition_times = {}
        
        from pktmask.core.trim.models.tls_models import get_tls_processing_strategy
        
        for tls_type in tls_types:
            times = []
            
            for _ in range(100):  # æµ‹è¯•100æ¬¡æ±‚å¹³å‡å€¼
                start_time = time.time()
                
                # æ¨¡æ‹Ÿåè®®è¯†åˆ«è¿‡ç¨‹
                strategy = get_tls_processing_strategy(tls_type)
                
                end_time = time.time()
                recognition_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                times.append(recognition_time)
            
            avg_time = statistics.mean(times)
            recognition_times[f"TLS-{tls_type}"] = avg_time
            
            print(f"  TLS-{tls_type}åè®®è¯†åˆ«: {avg_time:.3f}ms")
            
            # éªŒæ”¶æ ‡å‡†: åè®®è¯†åˆ«å»¶è¿Ÿ <50ms
            assert avg_time < 50.0, f"TLS-{tls_type}åè®®è¯†åˆ«å»¶è¿Ÿè¶…æ ‡: {avg_time:.3f}ms"
        
        self.benchmark.results['tshark_enhanced']['protocol_recognition_times'] = recognition_times

    def test_comprehensive_performance_report(self):
        """æµ‹è¯•4: ç»¼åˆæ€§èƒ½æŠ¥å‘Šç”Ÿæˆ"""
        print("\nğŸ“‹ æµ‹è¯•4: ç»¼åˆæ€§èƒ½æŠ¥å‘Šç”Ÿæˆ")
        
        # è®¡ç®—ç»¼åˆæ€§èƒ½è¯„åˆ†
        performance_score = self._calculate_performance_score()
        self.benchmark.results['comparison']['overall_performance_score'] = performance_score
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        report_file = self.temp_dir / "performance_benchmark_report.json"
        with open(report_file, 'w') as f:
            json.dump(self.benchmark.results, f, indent=2)
        
        print(f"  ç»¼åˆæ€§èƒ½è¯„åˆ†: {performance_score:.1f}/100")
        print(f"  è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # ç”Ÿæˆäººç±»å¯è¯»çš„æ€»ç»“æŠ¥å‘Š
        summary_report = self._generate_summary_report()
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“:")
        for line in summary_report:
            print(f"  {line}")
        
        # éªŒæ”¶æ ‡å‡†: ç»¼åˆæ€§èƒ½è¯„åˆ† â‰¥85åˆ†
        assert performance_score >= 85.0, f"ç»¼åˆæ€§èƒ½è¯„åˆ†ä¸è¾¾æ ‡: {performance_score:.1f}/100"
        
    def _calculate_performance_score(self) -> float:
        """è®¡ç®—ç»¼åˆæ€§èƒ½è¯„åˆ†"""
        score = 0.0
        
        # åˆå§‹åŒ–æ€§èƒ½è¯„åˆ† (æƒé‡: 10%)
        init_ratio = self.benchmark.results['comparison'].get('initialization_ratio', 5.0)
        if init_ratio <= 2.0:
            score += 10.0
        elif init_ratio <= 5.0:
            score += 5.0
        
        # å¤„ç†é€Ÿåº¦è¯„åˆ† (æƒé‡: 40%) 
        speed_retention = self.benchmark.results['comparison'].get('small_file_speed_retention', 0)
        if speed_retention >= 95:
            score += 40.0
        elif speed_retention >= 85:
            score += 30.0
        elif speed_retention >= 75:
            score += 20.0
        
        # åè®®è¯†åˆ«å»¶è¿Ÿè¯„åˆ† (æƒé‡: 50%)
        recognition_times = self.benchmark.results['tshark_enhanced'].get('protocol_recognition_times', {})
        if recognition_times:
            recognition_ok = all(time < 50.0 for time in recognition_times.values())
            if recognition_ok:
                score += 50.0
        
        return score
        
    def _generate_summary_report(self) -> List[str]:
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        report = []
        
        # æ€§èƒ½å¯¹æ¯”æ€»ç»“
        speed_retention = self.benchmark.results['comparison'].get('small_file_speed_retention', 0)
        if speed_retention >= 85:
            report.append(f"âœ… å¤„ç†é€Ÿåº¦: {speed_retention:.1f}% (è¾¾æ ‡ â‰¥85%)")
        else:
            report.append(f"âŒ å¤„ç†é€Ÿåº¦: {speed_retention:.1f}% (æœªè¾¾æ ‡ <85%)")
        
        # åè®®è¯†åˆ«æ€»ç»“
        recognition_times = self.benchmark.results['tshark_enhanced'].get('protocol_recognition_times', {})
        if recognition_times:
            all_fast = all(time < 50.0 for time in recognition_times.values())
            if all_fast:
                report.append("âœ… åè®®è¯†åˆ«: æ‰€æœ‰ç±»å‹å¿«é€Ÿè¯†åˆ« (è¾¾æ ‡ <50ms)")
            else:
                report.append("âŒ åè®®è¯†åˆ«: éƒ¨åˆ†ç±»å‹è¯†åˆ«è¾ƒæ…¢ (æœªè¾¾æ ‡ â‰¥50ms)")
        
        # ç»¼åˆè¯„ä»·
        score = self.benchmark.results['comparison'].get('overall_performance_score', 0)
        if score >= 90:
            report.append(f"ğŸ† ç»¼åˆè¯„ä»·: ä¼˜ç§€ ({score:.1f}/100)")
        elif score >= 85:
            report.append(f"âœ… ç»¼åˆè¯„ä»·: è‰¯å¥½ ({score:.1f}/100)")
        else:
            report.append(f"âš ï¸ ç»¼åˆè¯„ä»·: éœ€æ”¹è¿› ({score:.1f}/100)")
        
        return report 