"""
å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•
éªŒè¯å®Œæ•´çš„IPåŒ¿ååŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ˜ å°„ä¸€è‡´æ€§ã€æ•°é‡éªŒè¯ç­‰
"""

import time
import ipaddress
import tempfile
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict

import pytest
from scapy.all import rdpcap, wrpcap

from src.pktmask.core.encapsulation.detector import EncapsulationDetector
from src.pktmask.core.encapsulation.parser import ProtocolStackParser
from src.pktmask.core.encapsulation.adapter import ProcessingAdapter
from src.pktmask.core.encapsulation.types import EncapsulationType
from src.pktmask.core.strategy import HierarchicalAnonymizationStrategy
from src.pktmask.config import AppConfig


@dataclass
class EnhancedTestResult:
    """å¢å¼ºç‰ˆæµ‹è¯•ç»“æœæ•°æ®"""
    file_path: str
    category: str
    success: bool
    
    # åŸºç¡€ç»Ÿè®¡
    total_packets: int
    tested_packets: int
    processing_time: float
    
    # å°è£…æ£€æµ‹ç»“æœ
    encapsulation_stats: Dict[str, int]
    
    # IPåŒ¿ååŒ–éªŒè¯ç»“æœ
    original_ips: Set[str]
    anonymized_ips: Set[str]
    ip_mappings: Dict[str, str]
    mapping_consistency: bool
    ip_count_preserved: bool
    anonymized_ip_validity: bool
    
    # è¯¦ç»†éªŒè¯æŒ‡æ ‡
    anonymization_coverage: float  # åŒ¿ååŒ–è¦†ç›–ç‡
    unique_mapping_ratio: float    # å”¯ä¸€æ˜ å°„æ¯”ç‡
    
    # é”™è¯¯ä¿¡æ¯
    errors: List[str]
    validation_details: Dict[str, Any]


class EnhancedRealDataValidator:
    """å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        self.detector = EncapsulationDetector()
        self.parser = ProtocolStackParser()
        self.adapter = ProcessingAdapter()
        
        # åˆ›å»ºIPåŒ¿ååŒ–ç­–ç•¥
        config = AppConfig()
        config.processing.preserve_subnet_structure = True
        config.processing.preserve_original_segments = True
        config.processing.ip_mapping_consistency = True
        
        self.anonymization_strategy = HierarchicalAnonymizationStrategy()
    
    def validate_sample_file_with_anonymization(self, sample_file: Path, category: str, 
                                              max_test_packets: int = 100) -> EnhancedTestResult:
        """æ‰§è¡Œå®Œæ•´çš„IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•"""
        start_time = time.time()
        errors = []
        
        # åˆå§‹åŒ–ç»“æœæ•°æ®
        encapsulation_stats = {}
        original_ips = set()
        anonymized_ips = set()
        ip_mappings = {}
        
        try:
            # 1. è¯»å–å’Œé¢„å¤„ç†
            packets = rdpcap(str(sample_file))
            total_packets = len(packets)
            test_packets = packets[:max_test_packets]
            tested_count = len(test_packets)
            
            if tested_count == 0:
                return self._create_failed_result(sample_file, category, ["æ–‡ä»¶ä¸­æ²¡æœ‰å¯æµ‹è¯•çš„æ•°æ®åŒ…"])
            
            # 2. æå–åŸå§‹IPåœ°å€
            print(f"ğŸ“Š å¼€å§‹åˆ†æ {sample_file.name}...")
            for i, packet in enumerate(test_packets):
                try:
                    # å°è£…æ£€æµ‹
                    encap_type = self.detector.detect_encapsulation_type(packet)
                    encap_name = encap_type.value
                    encapsulation_stats[encap_name] = encapsulation_stats.get(encap_name, 0) + 1
                    
                    # IPåœ°å€æå–
                    adapter_result = self.adapter.analyze_packet_for_ip_processing(packet)
                    if 'ip_layers' in adapter_result:
                        for ip_layer in adapter_result['ip_layers']:
                            if hasattr(ip_layer, 'src_ip'):
                                original_ips.add(str(ip_layer.src_ip))
                            if hasattr(ip_layer, 'dst_ip'):
                                original_ips.add(str(ip_layer.dst_ip))
                                
                except Exception as e:
                    errors.append(f"åŒ… {i+1} åˆ†æé”™è¯¯: {str(e)}")
                    continue
            
            print(f"   æå–åˆ° {len(original_ips)} ä¸ªåŸå§‹IPåœ°å€")
            
            # 3. æ‰§è¡ŒIPåŒ¿ååŒ–å¤„ç†
            if len(original_ips) == 0:
                return self._create_failed_result(sample_file, category, ["æœªèƒ½æå–åˆ°IPåœ°å€"])
            
            print(f"ğŸ”’ å¼€å§‹IPåŒ¿ååŒ–å¤„ç†...")
            
            # 3. å…ˆåˆ›å»ºIPæ˜ å°„ (æ¨¡æ‹Ÿå®é™…å¤„ç†æµç¨‹)
            try:
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ç”¨äºæ˜ å°„ç”Ÿæˆ
                with tempfile.NamedTemporaryFile(suffix='.pcap', delete=False) as temp_file:
                    temp_input_path = Path(temp_file.name)
                    wrpcap(str(temp_input_path), test_packets)
                
                # åˆ›å»ºæ˜ å°„
                mapping_errors = []
                ip_mappings = self.anonymization_strategy.create_mapping(
                    [temp_input_path.name], str(temp_input_path.parent), mapping_errors
                )
                
                if mapping_errors:
                    errors.extend(mapping_errors)
                
                print(f"   ç”Ÿæˆ {len(ip_mappings)} ä¸ªIPæ˜ å°„")
                
                # 4. é€åŒ…åŒ¿ååŒ–å¹¶åˆ†æç»“æœ
                print(f"ğŸ” æ‰§è¡ŒåŒ¿ååŒ–å¹¶åˆ†æç»“æœ...")
                for packet in test_packets:
                    try:
                        anonymized_packet, modified = self.anonymization_strategy.anonymize_packet(packet)
                        
                        if modified and anonymized_packet:
                            # åˆ†æåŒ¿ååŒ–åçš„åŒ…
                            adapter_result = self.adapter.analyze_packet_for_ip_processing(anonymized_packet)
                            if 'ip_layers' in adapter_result:
                                for ip_layer in adapter_result['ip_layers']:
                                    if hasattr(ip_layer, 'src_ip'):
                                        anonymized_ips.add(str(ip_layer.src_ip))
                                    if hasattr(ip_layer, 'dst_ip'):
                                        anonymized_ips.add(str(ip_layer.dst_ip))
                    except Exception as e:
                        errors.append(f"åŒ…åŒ¿ååŒ–é”™è¯¯: {str(e)}")
                        continue
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                temp_input_path.unlink(missing_ok=True)
                
            except Exception as e:
                errors.append(f"åŒ¿ååŒ–å¤„ç†å¤±è´¥: {str(e)}")
                ip_mappings = {}
            
            # 6. éªŒè¯åŒ¿ååŒ–ç»“æœ
            validation_results = self._validate_anonymization_results(
                original_ips, anonymized_ips, ip_mappings, errors
            )
            
            # 7. ç”Ÿæˆæœ€ç»ˆç»“æœ
            processing_time = time.time() - start_time
            
            # åˆ¤æ–­æ€»ä½“æˆåŠŸ
            success = self._determine_success(
                errors, tested_count, encapsulation_stats, 
                original_ips, validation_results
            )
            
            print(f"   âœ… éªŒè¯å®Œæˆ: {'æˆåŠŸ' if success else 'å¤±è´¥'} ({processing_time:.3f}s)")
            
            return EnhancedTestResult(
                file_path=str(sample_file),
                category=category,
                success=success,
                total_packets=total_packets,
                tested_packets=tested_count,
                processing_time=processing_time,
                encapsulation_stats=encapsulation_stats,
                original_ips=original_ips,
                anonymized_ips=anonymized_ips,
                ip_mappings=ip_mappings,
                mapping_consistency=validation_results['mapping_consistency'],
                ip_count_preserved=validation_results['ip_count_preserved'],
                anonymized_ip_validity=validation_results['anonymized_ip_validity'],
                anonymization_coverage=validation_results['anonymization_coverage'],
                unique_mapping_ratio=validation_results['unique_mapping_ratio'],
                errors=errors[:10],
                validation_details=validation_results['details']
            )
            
        except Exception as e:
            return self._create_failed_result(sample_file, category, [f"å¤„ç†å¤±è´¥: {str(e)}"])
    
    def _validate_anonymization_results(self, original_ips: Set[str], anonymized_ips: Set[str], 
                                      ip_mappings: Dict[str, str], errors: List[str]) -> Dict[str, Any]:
        """éªŒè¯åŒ¿ååŒ–ç»“æœçš„æ­£ç¡®æ€§"""
        
        # 1. éªŒè¯IPæ•°é‡ä¿æŒä¸€è‡´
        ip_count_preserved = len(original_ips) == len(anonymized_ips)
        if not ip_count_preserved:
            errors.append(f"IPæ•°é‡ä¸ä¸€è‡´: åŸå§‹{len(original_ips)} vs åŒ¿ååŒ–{len(anonymized_ips)}")
        
        # 2. éªŒè¯æ˜ å°„ä¸€è‡´æ€§
        mapping_consistency = True
        mapped_originals = set(ip_mappings.keys())
        mapped_anonymized = set(ip_mappings.values())
        
        # æ£€æŸ¥æ‰€æœ‰åŸå§‹IPéƒ½æœ‰æ˜ å°„
        unmapped_originals = original_ips - mapped_originals
        if unmapped_originals:
            mapping_consistency = False
            errors.append(f"æœªæ˜ å°„çš„åŸå§‹IP: {unmapped_originals}")
        
        # æ£€æŸ¥æ˜ å°„æ˜¯å¦ä¸€å¯¹ä¸€
        if len(mapped_originals) != len(mapped_anonymized):
            mapping_consistency = False
            errors.append(f"æ˜ å°„ä¸æ˜¯ä¸€å¯¹ä¸€: {len(mapped_originals)} -> {len(mapped_anonymized)}")
        
        # 3. éªŒè¯åŒ¿ååŒ–IPçš„æœ‰æ•ˆæ€§
        anonymized_ip_validity = True
        invalid_ips = []
        
        for anon_ip in anonymized_ips:
            try:
                ipaddress.ip_address(anon_ip)
            except ValueError:
                anonymized_ip_validity = False
                invalid_ips.append(anon_ip)
        
        if invalid_ips:
            errors.append(f"æ— æ•ˆçš„åŒ¿ååŒ–IP: {invalid_ips}")
        
        # 4. è®¡ç®—è¦†ç›–ç‡å’Œå”¯ä¸€æ€§æ¯”ç‡
        anonymization_coverage = len(mapped_originals) / len(original_ips) if original_ips else 0
        unique_mapping_ratio = len(set(ip_mappings.values())) / len(ip_mappings) if ip_mappings else 0
        
        return {
            'mapping_consistency': mapping_consistency,
            'ip_count_preserved': ip_count_preserved,
            'anonymized_ip_validity': anonymized_ip_validity,
            'anonymization_coverage': anonymization_coverage,
            'unique_mapping_ratio': unique_mapping_ratio,
            'details': {
                'original_ip_count': len(original_ips),
                'anonymized_ip_count': len(anonymized_ips),
                'mapping_count': len(ip_mappings),
                'invalid_anonymized_ips': len([ip for ip in anonymized_ips 
                                             if not self._is_valid_ip(ip)])
            }
        }
    
    def _is_valid_ip(self, ip_str: str) -> bool:
        """æ£€æŸ¥IPåœ°å€æ˜¯å¦æœ‰æ•ˆ"""
        try:
            ipaddress.ip_address(ip_str)
            return True
        except ValueError:
            return False
    
    def _determine_success(self, errors: List[str], tested_count: int, 
                          encapsulation_stats: Dict[str, int], original_ips: Set[str],
                          validation_results: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æµ‹è¯•æ˜¯å¦æˆåŠŸ"""
        return (
            len(errors) < tested_count * 0.2 and          # é”™è¯¯ç‡ < 20%
            len(encapsulation_stats) > 0 and              # æ£€æµ‹åˆ°å°è£…
            len(original_ips) > 0 and                     # æå–åˆ°åŸå§‹IP
            validation_results['mapping_consistency'] and  # æ˜ å°„ä¸€è‡´æ€§
            validation_results['ip_count_preserved'] and   # IPæ•°é‡ä¿æŒ
            validation_results['anonymized_ip_validity'] and # åŒ¿ååŒ–IPæœ‰æ•ˆ
            validation_results['anonymization_coverage'] >= 0.95  # è¦†ç›–ç‡ >= 95%
        )
    
    def _create_failed_result(self, sample_file: Path, category: str, errors: List[str]) -> EnhancedTestResult:
        """åˆ›å»ºå¤±è´¥çš„æµ‹è¯•ç»“æœ"""
        return EnhancedTestResult(
            file_path=str(sample_file),
            category=category,
            success=False,
            total_packets=0,
            tested_packets=0,
            processing_time=0,
            encapsulation_stats={},
            original_ips=set(),
            anonymized_ips=set(),
            ip_mappings={},
            mapping_consistency=False,
            ip_count_preserved=False,
            anonymized_ip_validity=False,
            anonymization_coverage=0,
            unique_mapping_ratio=0,
            errors=errors,
            validation_details={}
        )


@pytest.mark.integration
@pytest.mark.real_data_enhanced
@pytest.mark.slow
class TestEnhancedRealDataValidation:
    """å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def validator(self):
        return EnhancedRealDataValidator()
    
    @pytest.mark.parametrize("sample_info", [
        ("tests/data/samples/TLS/tls_sample.pcap", "plain_ip"),
        ("tests/data/samples/singlevlan/10.200.33.61(10ç¬”).pcap", "single_vlan"),
        ("tests/data/samples/doublevlan/172.24.0.51.pcap", "double_vlan"),
    ])
    def test_enhanced_sample_validation(self, validator, sample_info):
        """å¢å¼ºç‰ˆæ ·æœ¬éªŒè¯æµ‹è¯•"""
        sample_file, category = sample_info
        sample_path = Path(sample_file)
        
        if not sample_path.exists():
            pytest.skip(f"æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {sample_file}")
        
        print(f"\nğŸ§ª å¢å¼ºæµ‹è¯•: {sample_path.name} ({category})")
        
        result = validator.validate_sample_file_with_anonymization(sample_path, category)
        
        # è¯¦ç»†ç»“æœè¾“å‡º
        if result.success:
            print(f"   âœ… æˆåŠŸ - {result.tested_packets}/{result.total_packets} åŒ…")
            print(f"   ğŸ“¦ å°è£…: {result.encapsulation_stats}")
            print(f"   ğŸ” åŸå§‹IP: {len(result.original_ips)} ä¸ª")
            print(f"   ğŸ”’ åŒ¿åIP: {len(result.anonymized_ips)} ä¸ª")
            print(f"   ğŸ—ºï¸  æ˜ å°„: {len(result.ip_mappings)} ä¸ª")
            print(f"   ğŸ“Š è¦†ç›–ç‡: {result.anonymization_coverage:.1%}")
            print(f"   ğŸ¯ å”¯ä¸€æ€§: {result.unique_mapping_ratio:.1%}")
            print(f"   â±ï¸  æ—¶é—´: {result.processing_time:.3f}s")
        else:
            print(f"   âŒ å¤±è´¥ - é”™è¯¯: {len(result.errors)}")
            for error in result.errors[:3]:
                print(f"      â€¢ {error}")
        
        # æ ¸å¿ƒæ–­è¨€
        assert result.success, f"å¢å¼ºéªŒè¯å¤±è´¥: {result.errors}"
        assert result.mapping_consistency, "IPæ˜ å°„ä¸ä¸€è‡´"
        assert result.ip_count_preserved, "IPæ•°é‡æœªä¿æŒä¸€è‡´"
        assert result.anonymized_ip_validity, "åŒ¿ååŒ–IPæ— æ•ˆ"
        assert result.anonymization_coverage >= 0.95, f"åŒ¿ååŒ–è¦†ç›–ç‡è¿‡ä½: {result.anonymization_coverage:.1%}"
    
    def test_anonymization_consistency_across_runs(self, validator):
        """æµ‹è¯•å¤šæ¬¡è¿è¡Œçš„åŒ¿ååŒ–ä¸€è‡´æ€§"""
        sample_file = Path("tests/data/samples/TLS/tls_sample.pcap")
        
        if not sample_file.exists():
            pytest.skip("æµ‹è¯•æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨")
        
        print(f"\nğŸ”„ ä¸€è‡´æ€§æµ‹è¯•: {sample_file.name}")
        
        # è¿è¡Œä¸¤æ¬¡åŒ¿ååŒ–
        result1 = validator.validate_sample_file_with_anonymization(sample_file, "plain_ip")
        result2 = validator.validate_sample_file_with_anonymization(sample_file, "plain_ip")
        
        # éªŒè¯æ˜ å°„ä¸€è‡´æ€§
        assert result1.success and result2.success, "ä¸¤æ¬¡è¿è¡Œéƒ½åº”è¯¥æˆåŠŸ"
        
        # æ£€æŸ¥ç›¸åŒåŸå§‹IPçš„æ˜ å°„ç»“æœæ˜¯å¦ä¸€è‡´
        common_ips = result1.original_ips & result2.original_ips
        inconsistent_mappings = []
        
        for ip in common_ips:
            if ip in result1.ip_mappings and ip in result2.ip_mappings:
                if result1.ip_mappings[ip] != result2.ip_mappings[ip]:
                    inconsistent_mappings.append(
                        f"{ip}: {result1.ip_mappings[ip]} != {result2.ip_mappings[ip]}"
                    )
        
        assert not inconsistent_mappings, f"æ˜ å°„ä¸ä¸€è‡´: {inconsistent_mappings}"
        print(f"   âœ… ä¸€è‡´æ€§éªŒè¯é€šè¿‡: {len(common_ips)} ä¸ªIPæ˜ å°„ä¸€è‡´")


@dataclass
class PayloadTrimmingResult:
    """è½½è·è£åˆ‡æµ‹è¯•ç»“æœæ•°æ®"""
    file_path: str
    category: str
    success: bool
    
    # åŸºç¡€ç»Ÿè®¡
    total_packets: int
    tcp_packets: int
    processing_time: float
    
    # å°è£…æ£€æµ‹ç»“æœ
    encapsulation_stats: Dict[str, int]
    encapsulated_packets: int
    
    # è½½è·è£åˆ‡éªŒè¯ç»“æœ
    original_payload_size: int
    trimmed_payload_size: int
    packets_with_payload: int
    packets_trimmed: int
    tls_packets_detected: int
    trim_effectiveness: float  # è£åˆ‡æ•ˆæœ
    
    # TLSæ™ºèƒ½è£åˆ‡éªŒè¯
    tls_signaling_preserved: int
    tls_app_data_trimmed: int
    intelligent_trim_accuracy: float
    
    # å¤šå±‚å°è£…è½½è·å¤„ç†éªŒè¯
    encap_payload_accessible: bool
    inner_tcp_sessions: int
    encap_trim_success: bool
    
    # é”™è¯¯ä¿¡æ¯
    errors: List[str]
    processing_details: Dict[str, Any]


class PayloadTrimmingValidator:
    """è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯å™¨"""
    
    def __init__(self):
        from src.pktmask.core.processors import EnhancedTrimmer
        from src.pktmask.core.encapsulation.adapter import ProcessingAdapter
        
        self.trimming_step = IntelligentTrimmingStep()
        self.adapter = ProcessingAdapter()
        
    def validate_payload_trimming(self, sample_file: Path, category: str,
                                max_test_packets: int = 100) -> PayloadTrimmingResult:
        """æ‰§è¡Œå®Œæ•´çš„è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯"""
        start_time = time.time()
        errors = []
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        encapsulation_stats = {}
        total_packets = 0
        tcp_packets = 0
        encapsulated_packets = 0
        
        original_payload_size = 0
        packets_with_payload = 0
        tls_packets_detected = 0
        
        try:
            # 1. è¯»å–å’Œé¢„å¤„ç†
            packets = rdpcap(str(sample_file))
            total_packets = len(packets)
            test_packets = packets[:max_test_packets]
            tested_count = len(test_packets)
            
            if tested_count == 0:
                return self._create_failed_trimming_result(sample_file, category, ["æ–‡ä»¶ä¸­æ²¡æœ‰å¯æµ‹è¯•çš„æ•°æ®åŒ…"])
            
            print(f"ğŸ¯ å¼€å§‹è½½è·è£åˆ‡éªŒè¯: {sample_file.name}")
            
            # 2. åˆ†æåŸå§‹æ•°æ®åŒ…çš„è½½è·æƒ…å†µ
            for packet in test_packets:
                try:
                    # å°è£…æ£€æµ‹
                    encap_type = self.adapter.detector.detect_encapsulation_type(packet)
                    encap_name = encap_type.value
                    encapsulation_stats[encap_name] = encapsulation_stats.get(encap_name, 0) + 1
                    
                    if encap_type != EncapsulationType.PLAIN:
                        encapsulated_packets += 1
                    
                    # è½½è·åˆ†æ
                    payload_analysis = self.adapter.analyze_packet_for_payload_processing(packet)
                    
                    if payload_analysis.get('has_tcp', False):
                        tcp_packets += 1
                        
                        # æ£€æŸ¥è½½è·
                        tcp_session = self.adapter.extract_tcp_session_for_trimming(payload_analysis)
                        if tcp_session and tcp_session.get('payload_data'):
                            packets_with_payload += 1
                            payload_data = tcp_session['payload_data']
                            original_payload_size += len(payload_data)
                            
                            # TLSæ£€æµ‹
                            if tcp_session.get('is_encrypted', False):
                                tls_packets_detected += 1
                    
                except Exception as e:
                    errors.append(f"è½½è·åˆ†æå¤±è´¥: {str(e)}")
                    continue
            
            print(f"   è½½è·åˆ†æ: {packets_with_payload}ä¸ªè½½è·åŒ…, {tls_packets_detected}ä¸ªTLSåŒ…, "
                  f"å°è£…åŒ…: {encapsulated_packets}/{tested_count}")
            
            # 3. æ‰§è¡Œè½½è·è£åˆ‡å¤„ç†
            if packets_with_payload == 0:
                print(f"   âš ï¸ è·³è¿‡è½½è·è£åˆ‡éªŒè¯: æ²¡æœ‰æ‰¾åˆ°è½½è·åŒ…")
                processing_time = time.time() - start_time
                
                return PayloadTrimmingResult(
                    file_path=str(sample_file),
                    category=category,
                    success=True,  # æ²¡æœ‰è½½è·ä¹Ÿç®—æˆåŠŸ
                    total_packets=tested_count,
                    tcp_packets=tcp_packets,
                    processing_time=processing_time,
                    encapsulation_stats=encapsulation_stats,
                    encapsulated_packets=encapsulated_packets,
                    original_payload_size=0,
                    trimmed_payload_size=0,
                    packets_with_payload=0,
                    packets_trimmed=0,
                    tls_packets_detected=0,
                    trim_effectiveness=0.0,
                    tls_signaling_preserved=0,
                    tls_app_data_trimmed=0,
                    intelligent_trim_accuracy=100.0,  # æ²¡æœ‰TLSåŒ…æ—¶å‡†ç¡®ç‡ä¸º100%
                    encap_payload_accessible=True,
                    inner_tcp_sessions=0,
                    encap_trim_success=True,
                    errors=errors,
                    processing_details={}
                )
            
            print(f"âœ‚ï¸ å¼€å§‹è½½è·è£åˆ‡å¤„ç†...")
            
            # 4. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è¿›è¡Œå®é™…è£åˆ‡å¤„ç†
            with tempfile.NamedTemporaryFile(suffix='.pcap', delete=False) as temp_input:
                temp_input_path = Path(temp_input.name)
                wrpcap(str(temp_input_path), test_packets)
            
            with tempfile.NamedTemporaryFile(suffix='.pcap', delete=False) as temp_output:
                temp_output_path = Path(temp_output.name)
            
            try:
                # æ‰§è¡Œè£åˆ‡å¤„ç†
                trim_summary = self.trimming_step.process_file(str(temp_input_path), str(temp_output_path))
                
                if not trim_summary:
                    errors.append("è½½è·è£åˆ‡å¤„ç†å¤±è´¥")
                    return self._create_failed_trimming_result(sample_file, category, errors)
                
                # 5. è¯»å–è£åˆ‡åçš„æ•°æ®åŒ…å¹¶åˆ†æç»“æœ
                trimmed_packets = rdpcap(str(temp_output_path))
                
                trimmed_payload_size = 0
                packets_trimmed = 0
                tls_signaling_preserved = 0
                tls_app_data_trimmed = 0
                inner_tcp_sessions = 0
                
                for packet in trimmed_packets:
                    try:
                        payload_analysis = self.adapter.analyze_packet_for_payload_processing(packet)
                        
                        if payload_analysis.get('has_tcp', False):
                            tcp_session = self.adapter.extract_tcp_session_for_trimming(payload_analysis)
                            if tcp_session:
                                inner_tcp_sessions += 1
                                
                                if tcp_session.get('payload_data'):
                                    payload_data = tcp_session['payload_data']
                                    trimmed_payload_size += len(payload_data)
                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºTLSä¿¡ä»¤ï¼ˆæ¡æ‰‹ç­‰ï¼‰
                                    if tcp_session.get('is_encrypted', False):
                                        if self._is_tls_signaling(payload_data):
                                            tls_signaling_preserved += 1
                                        else:
                                            # å¦‚æœæ˜¯TLSä½†ä¸æ˜¯ä¿¡ä»¤ï¼Œå¯èƒ½æ˜¯è¢«ä¿ç•™çš„åº”ç”¨æ•°æ®
                                            pass
                                else:
                                    # è½½è·è¢«è£åˆ‡çš„åŒ…
                                    packets_trimmed += 1
                    
                    except Exception as e:
                        errors.append(f"è£åˆ‡ç»“æœåˆ†æå¤±è´¥: {str(e)}")
                        continue
                
                # 6. è®¡ç®—è½½è·è£åˆ‡éªŒè¯æŒ‡æ ‡
                validation_results = self._calculate_trim_metrics(
                    original_payload_size, trimmed_payload_size,
                    packets_with_payload, packets_trimmed,
                    tls_packets_detected, tls_signaling_preserved,
                    trim_summary
                )
                
                # 7. å¤šå±‚å°è£…éªŒè¯
                encap_validation = self._validate_encapsulated_trimming(
                    encapsulated_packets, inner_tcp_sessions, trim_summary
                )
                
                processing_time = time.time() - start_time
                
                # 8. åˆ¤æ–­æ•´ä½“æˆåŠŸ
                success = self._determine_trimming_success(
                    errors, validation_results, encap_validation
                )
                
                print(f"   âœ… è½½è·è£åˆ‡éªŒè¯å®Œæˆ: {'æˆåŠŸ' if success else 'å¤±è´¥'} "
                      f"({validation_results['trim_effectiveness']:.1f}%æ•ˆæœ, {processing_time:.3f}s)")
                
                return PayloadTrimmingResult(
                    file_path=str(sample_file),
                    category=category,
                    success=success,
                    total_packets=tested_count,
                    tcp_packets=tcp_packets,
                    processing_time=processing_time,
                    encapsulation_stats=encapsulation_stats,
                    encapsulated_packets=encapsulated_packets,
                    original_payload_size=original_payload_size,
                    trimmed_payload_size=trimmed_payload_size,
                    packets_with_payload=packets_with_payload,
                    packets_trimmed=packets_trimmed,
                    tls_packets_detected=tls_packets_detected,
                    trim_effectiveness=validation_results['trim_effectiveness'],
                    tls_signaling_preserved=tls_signaling_preserved,
                    tls_app_data_trimmed=validation_results['tls_app_data_trimmed'],
                    intelligent_trim_accuracy=validation_results['intelligent_trim_accuracy'],
                    encap_payload_accessible=encap_validation['payload_accessible'],
                    inner_tcp_sessions=inner_tcp_sessions,
                    encap_trim_success=encap_validation['trim_success'],
                    errors=errors[:10],
                    processing_details=trim_summary
                )
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                temp_input_path.unlink(missing_ok=True)
                temp_output_path.unlink(missing_ok=True)
                
        except Exception as e:
            errors.append(f"è½½è·è£åˆ‡éªŒè¯è¿‡ç¨‹å¤±è´¥: {str(e)}")
            return self._create_failed_trimming_result(sample_file, category, errors)
    
    def _is_tls_signaling(self, payload_data: bytes) -> bool:
        """æ£€æŸ¥è½½è·æ˜¯å¦ä¸ºTLSä¿¡ä»¤æ•°æ®"""
        if len(payload_data) < 5:
            return False
        
        # TLSè®°å½•ç±»å‹ï¼š20=Change Cipher Spec, 21=Alert, 22=Handshake, 23=Application Data
        record_type = payload_data[0]
        return record_type in [20, 21, 22]  # ä¿¡ä»¤ç±»å‹ï¼Œä¸åŒ…æ‹¬Application Data(23)
    
    def _calculate_trim_metrics(self, original_size: int, trimmed_size: int,
                              original_packets: int, trimmed_packets: int,
                              tls_packets: int, tls_preserved: int,
                              trim_summary: Dict) -> Dict[str, float]:
        """è®¡ç®—è½½è·è£åˆ‡æŒ‡æ ‡"""
        metrics = {}
        
        # è£åˆ‡æ•ˆæœ
        if original_size > 0:
            metrics['trim_effectiveness'] = ((original_size - trimmed_size) / original_size) * 100
        else:
            metrics['trim_effectiveness'] = 0.0
        
        # TLSåº”ç”¨æ•°æ®è£åˆ‡ç‡
        if tls_packets > 0:
            # è®¡ç®—TLSåº”ç”¨æ•°æ®çš„è£åˆ‡æ•°é‡
            tls_app_data_trimmed = max(0, tls_packets - tls_preserved)
            metrics['tls_app_data_trimmed'] = tls_app_data_trimmed
            
            # æ™ºèƒ½è£åˆ‡å‡†ç¡®ç‡ï¼ˆä¿ç•™ä¿¡ä»¤ï¼Œè£åˆ‡åº”ç”¨æ•°æ®ï¼‰
            if tls_packets > 0:
                metrics['intelligent_trim_accuracy'] = ((tls_preserved + tls_app_data_trimmed) / tls_packets) * 100
            else:
                metrics['intelligent_trim_accuracy'] = 100.0
        else:
            metrics['tls_app_data_trimmed'] = 0
            metrics['intelligent_trim_accuracy'] = 100.0
        
        return metrics
    
    def _validate_encapsulated_trimming(self, encap_packets: int, inner_sessions: int,
                                       trim_summary: Dict) -> Dict[str, bool]:
        """éªŒè¯å¤šå±‚å°è£…çš„è½½è·è£åˆ‡"""
        validation = {}
        
        # è½½è·å¯è®¿é—®æ€§éªŒè¯
        validation['payload_accessible'] = True
        if encap_packets > 0:
            # å¦‚æœæœ‰å°è£…åŒ…ï¼Œæ£€æŸ¥æ˜¯å¦èƒ½å¤Ÿè®¿é—®å†…å±‚è½½è·
            encap_ratio = trim_summary.get('encapsulation_ratio', 0.0)
            validation['payload_accessible'] = encap_ratio >= 0  # è‡³å°‘èƒ½æ£€æµ‹åˆ°å°è£…
        
        # è£åˆ‡æˆåŠŸæ€§éªŒè¯
        validation['trim_success'] = True
        if encap_packets > 0 and inner_sessions == 0:
            # æœ‰å°è£…åŒ…ä½†æ²¡æœ‰æ£€æµ‹åˆ°å†…å±‚TCPä¼šè¯å¯èƒ½è¡¨ç¤ºé—®é¢˜
            validation['trim_success'] = False
        
        return validation
    
    def _determine_trimming_success(self, errors: List[str], 
                                   metrics: Dict[str, float],
                                   encap_validation: Dict[str, bool]) -> bool:
        """åˆ¤æ–­è½½è·è£åˆ‡éªŒè¯æ˜¯å¦æˆåŠŸ"""
        # é”™è¯¯ç‡æ£€æŸ¥
        if len(errors) >= 5:  # å…è®¸å°‘é‡é”™è¯¯
            return False
        
        # TLSæ™ºèƒ½è£åˆ‡å‡†ç¡®ç‡æ£€æŸ¥
        if metrics.get('intelligent_trim_accuracy', 0) < 70:  # è‡³å°‘70%å‡†ç¡®ç‡
            return False
        
        # å¤šå±‚å°è£…å¤„ç†æ£€æŸ¥
        if not encap_validation.get('payload_accessible', True):
            return False
        
        return True
    
    def _create_failed_trimming_result(self, sample_file: Path, category: str, 
                                     errors: List[str]) -> PayloadTrimmingResult:
        """åˆ›å»ºå¤±è´¥çš„è½½è·è£åˆ‡ç»“æœ"""
        return PayloadTrimmingResult(
            file_path=str(sample_file),
            category=category,
            success=False,
            total_packets=0,
            tcp_packets=0,
            processing_time=0.0,
            encapsulation_stats={},
            encapsulated_packets=0,
            original_payload_size=0,
            trimmed_payload_size=0,
            packets_with_payload=0,
            packets_trimmed=0,
            tls_packets_detected=0,
            trim_effectiveness=0.0,
            tls_signaling_preserved=0,
            tls_app_data_trimmed=0,
            intelligent_trim_accuracy=0.0,
            encap_payload_accessible=False,
            inner_tcp_sessions=0,
            encap_trim_success=False,
            errors=errors,
            processing_details={}
        )


@pytest.mark.integration
@pytest.mark.payload_trimming_enhanced
@pytest.mark.slow
class TestPayloadTrimmingValidation:
    """è½½è·è£åˆ‡åŠŸèƒ½çš„å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•"""
    
    @pytest.fixture(scope="class")
    def trimming_validator(self):
        """è½½è·è£åˆ‡éªŒè¯å™¨fixture"""
        return PayloadTrimmingValidator()
    
    @pytest.fixture(scope="class")
    def all_sample_files(self):
        """æ‰€æœ‰15ä¸ªæ ·æœ¬æ–‡ä»¶çš„å®Œæ•´åˆ—è¡¨"""
        return [
            # åŸºç¡€å°è£…ç±»å‹ (5ä¸ª)
            ("tests/data/samples/TLS/tls_sample.pcap", "plain_ip", "Plain IP æ ·æœ¬"),
            ("tests/data/samples/singlevlan/10.200.33.61(10ç¬”).pcap", "single_vlan", "Single VLAN æ ·æœ¬"),
            ("tests/data/samples/doublevlan/172.24.0.51.pcap", "double_vlan", "Double VLAN æ ·æœ¬"),
            ("tests/data/samples/mpls/mpls.pcap", "mpls", "MPLS æ ·æœ¬"),
            ("tests/data/samples/vxlan/vxlan.pcap", "vxlan", "VXLAN æ ·æœ¬"),
            
            # æ‰©å±•å°è£…ç±»å‹ (5ä¸ª)
            ("tests/data/samples/gre/20160406152100.pcap", "gre", "GRE æ ·æœ¬"),
            ("tests/data/samples/vlan_gre/case17-parts.pcap", "vlan_gre", "VLAN+GRE å¤åˆæ ·æœ¬"),
            ("tests/data/samples/vxlan_vlan/vxlan_servicetag_1001.pcap", "vxlan_vlan", "VXLAN+VLAN å¤åˆæ ·æœ¬"),
            ("tests/data/samples/TLS70/sslerr1-70.pcap", "tls70", "TLS70 æ ·æœ¬"),
            ("tests/data/samples/doublevlan_tls/TC-007-3-20230829-01.pcap", "doublevlan_tls", "Double VLAN + TLS æ ·æœ¬"),
            
            # ä¼ä¸šæµ‹è¯•æ¡ˆä¾‹ (5ä¸ª)
            ("tests/data/samples/IPTCP-200ips/TC-002-6-20200927-S-A-Replaced.pcapng", "large_dataset", "200 IPå¤§æ•°æ®é›†æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-001-1-20160407/TC-001-1-20160407-A.pcap", "test_case_001", "æµ‹è¯•ç”¨ä¾‹001æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-002-5-20220215/TC-002-5-20220215-FW-in.pcap", "test_case_002_5", "æµ‹è¯•ç”¨ä¾‹002-5æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-002-8-20210817/TC-002-8-20210817.pcapng", "test_case_002_8", "æµ‹è¯•ç”¨ä¾‹002-8æ ·æœ¬"),
            ("tests/data/samples/vxlan4787/vxlan-double-http.pcap", "vxlan4787", "VXLAN4787å˜ç§æ ·æœ¬"),
        ]
    
    @pytest.mark.parametrize("sample_info", [
        ("tests/data/samples/TLS/tls_sample.pcap", "plain_ip", "Plain IP æ ·æœ¬"),
        ("tests/data/samples/singlevlan/10.200.33.61(10ç¬”).pcap", "single_vlan", "Single VLAN æ ·æœ¬"),
        ("tests/data/samples/doublevlan/172.24.0.51.pcap", "double_vlan", "Double VLAN æ ·æœ¬"),
        ("tests/data/samples/mpls/mpls.pcap", "mpls", "MPLS æ ·æœ¬"),
        ("tests/data/samples/vxlan/vxlan.pcap", "vxlan", "VXLAN æ ·æœ¬"),
        ("tests/data/samples/gre/20160406152100.pcap", "gre", "GRE æ ·æœ¬"),
        ("tests/data/samples/vlan_gre/case17-parts.pcap", "vlan_gre", "VLAN+GRE å¤åˆæ ·æœ¬"),
        ("tests/data/samples/vxlan_vlan/vxlan_servicetag_1001.pcap", "vxlan_vlan", "VXLAN+VLAN å¤åˆæ ·æœ¬"),
        ("tests/data/samples/TLS70/sslerr1-70.pcap", "tls70", "TLS70 æ ·æœ¬"),
        ("tests/data/samples/doublevlan_tls/TC-007-3-20230829-01.pcap", "doublevlan_tls", "Double VLAN + TLS æ ·æœ¬"),
        ("tests/data/samples/IPTCP-200ips/TC-002-6-20200927-S-A-Replaced.pcapng", "large_dataset", "200 IPå¤§æ•°æ®é›†æ ·æœ¬"),
        ("tests/data/samples/IPTCP-TC-001-1-20160407/TC-001-1-20160407-A.pcap", "test_case_001", "æµ‹è¯•ç”¨ä¾‹001æ ·æœ¬"),
        ("tests/data/samples/IPTCP-TC-002-5-20220215/TC-002-5-20220215-FW-in.pcap", "test_case_002_5", "æµ‹è¯•ç”¨ä¾‹002-5æ ·æœ¬"),
        ("tests/data/samples/IPTCP-TC-002-8-20210817/TC-002-8-20210817.pcapng", "test_case_002_8", "æµ‹è¯•ç”¨ä¾‹002-8æ ·æœ¬"),
        ("tests/data/samples/vxlan4787/vxlan-double-http.pcap", "vxlan4787", "VXLAN4787å˜ç§æ ·æœ¬"),
    ])
    def test_payload_trimming_individual_samples(self, trimming_validator, sample_info):
        """æµ‹è¯•å•ä¸ªæ ·æœ¬çš„è½½è·è£åˆ‡åŠŸèƒ½"""
        file_path, category, description = sample_info
        sample_file = Path(file_path)
        
        if not sample_file.exists():
            pytest.skip(f"æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        print(f"\nğŸ“‹ æµ‹è¯•è½½è·è£åˆ‡: {description}")
        print(f"   æ–‡ä»¶: {sample_file.name}")
        print(f"   ç±»åˆ«: {category}")
        
        # æ‰§è¡Œè½½è·è£åˆ‡éªŒè¯
        result = trimming_validator.validate_payload_trimming(sample_file, category, max_test_packets=50)
        
        # éªŒè¯åŸºæœ¬ç»“æœ
        print(f"   æ€»åŒ…æ•°: {result.total_packets}, TCPåŒ…: {result.tcp_packets}")
        print(f"   è½½è·åŒ…: {result.packets_with_payload}, TLSåŒ…: {result.tls_packets_detected}")
        print(f"   å°è£…åŒ…: {result.encapsulated_packets}, è£åˆ‡æ•ˆæœ: {result.trim_effectiveness:.1f}%")
        print(f"   æ™ºèƒ½è£åˆ‡å‡†ç¡®ç‡: {result.intelligent_trim_accuracy:.1f}%")
        
        # åŸºç¡€éªŒè¯
        assert result.total_packets > 0, "åº”è¯¥æœ‰æµ‹è¯•åŒ…"
        assert result.processing_time > 0, "å¤„ç†æ—¶é—´åº”è¯¥å¤§äº0"
        
        # å¦‚æœæœ‰è½½è·åŒ…ï¼ŒéªŒè¯è£åˆ‡é€»è¾‘
        if result.packets_with_payload > 0:
            # è£åˆ‡æ•ˆæœéªŒè¯ï¼ˆå…è®¸0%ï¼Œå¦‚æœå…¨æ˜¯TLSä¿¡ä»¤ï¼‰
            assert 0 <= result.trim_effectiveness <= 100, "è£åˆ‡æ•ˆæœåº”åœ¨0-100%ä¹‹é—´"
            
            # TLSæ™ºèƒ½è£åˆ‡éªŒè¯
            assert 0 <= result.intelligent_trim_accuracy <= 100, "æ™ºèƒ½è£åˆ‡å‡†ç¡®ç‡åº”åœ¨0-100%ä¹‹é—´"
            
            # å¦‚æœæœ‰TLSåŒ…ï¼ŒéªŒè¯æ™ºèƒ½è£åˆ‡
            if result.tls_packets_detected > 0:
                assert result.intelligent_trim_accuracy >= 70, f"TLSæ™ºèƒ½è£åˆ‡å‡†ç¡®ç‡åº”â‰¥70%ï¼Œå®é™…: {result.intelligent_trim_accuracy:.1f}%"
        
        # å°è£…å¤„ç†éªŒè¯
        if result.encapsulated_packets > 0:
            # éªŒè¯èƒ½å¤Ÿè®¿é—®å°è£…å†…çš„è½½è·
            assert result.encap_payload_accessible, "åº”è¯¥èƒ½å¤Ÿè®¿é—®å°è£…å†…çš„è½½è·"
            
            # å¦‚æœæœ‰å°è£…TCPä¼šè¯ï¼ŒéªŒè¯å¤„ç†æˆåŠŸ
            if result.inner_tcp_sessions > 0:
                assert result.encap_trim_success, "å°è£…è½½è·è£åˆ‡åº”è¯¥æˆåŠŸ"
        
        # é”™è¯¯éªŒè¯
        if result.errors:
            print(f"   âš ï¸ è­¦å‘Š: {len(result.errors)} ä¸ªé”™è¯¯")
            for error in result.errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"      - {error}")
        
        # æœ€ç»ˆæˆåŠŸéªŒè¯
        assert result.success, f"è½½è·è£åˆ‡éªŒè¯åº”è¯¥æˆåŠŸï¼Œé”™è¯¯: {result.errors}"
        
        print(f"   âœ… è½½è·è£åˆ‡éªŒè¯é€šè¿‡: {description}")
    
    def test_payload_trimming_comprehensive_report(self, trimming_validator, all_sample_files):
        """ç”Ÿæˆæ‰€æœ‰æ ·æœ¬çš„è½½è·è£åˆ‡ç»¼åˆæŠ¥å‘Š"""
        print(f"\nğŸ¯ è½½è·è£åˆ‡åŠŸèƒ½å…¨é¢éªŒè¯æŠ¥å‘Š")
        print(f"=" * 60)
        
        total_samples = len(all_sample_files)
        successful_samples = 0
        failed_samples = []
        
        # ç»Ÿè®¡æ±‡æ€»
        total_packets_processed = 0
        total_tcp_packets = 0
        total_payload_packets = 0
        total_tls_packets = 0
        total_encapsulated_packets = 0
        
        total_original_payload_size = 0
        total_trimmed_payload_size = 0
        
        encapsulation_type_stats = {}
        
        # é€ä¸ªæµ‹è¯•æ ·æœ¬
        for file_path, category, description in all_sample_files:
            sample_file = Path(file_path)
            
            if not sample_file.exists():
                print(f"âŒ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {file_path}")
                continue
            
            try:
                result = trimming_validator.validate_payload_trimming(sample_file, category, max_test_packets=50)
                
                # æ›´æ–°ç»Ÿè®¡
                total_packets_processed += result.total_packets
                total_tcp_packets += result.tcp_packets
                total_payload_packets += result.packets_with_payload
                total_tls_packets += result.tls_packets_detected
                total_encapsulated_packets += result.encapsulated_packets
                
                total_original_payload_size += result.original_payload_size
                total_trimmed_payload_size += result.trimmed_payload_size
                
                # æŒ‰å°è£…ç±»å‹åˆ†ç±»ç»Ÿè®¡
                encap_types = list(result.encapsulation_stats.keys())
                main_encap_type = encap_types[0] if encap_types else 'PLAIN'
                
                if main_encap_type not in encapsulation_type_stats:
                    encapsulation_type_stats[main_encap_type] = {
                        'count': 0, 'success': 0, 'total_trim_effect': 0
                    }
                
                encapsulation_type_stats[main_encap_type]['count'] += 1
                if result.success:
                    encapsulation_type_stats[main_encap_type]['success'] += 1
                    encapsulation_type_stats[main_encap_type]['total_trim_effect'] += result.trim_effectiveness
                
                if result.success:
                    successful_samples += 1
                    print(f"âœ… {description}: {result.trim_effectiveness:.1f}%æ•ˆæœ")
                else:
                    failed_samples.append((description, result.errors))
                    print(f"âŒ {description}: å¤±è´¥ - {result.errors[:2]}")
                
            except Exception as e:
                failed_samples.append((description, [str(e)]))
                print(f"âŒ {description}: å¼‚å¸¸ - {str(e)}")
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print(f"\nğŸ“Š è½½è·è£åˆ‡éªŒè¯ç»¼åˆç»Ÿè®¡")
        print(f"=" * 60)
        print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"æˆåŠŸæ ·æœ¬: {successful_samples}/{total_samples} ({(successful_samples/total_samples*100):.1f}%)")
        print(f"å¤±è´¥æ ·æœ¬: {len(failed_samples)}")
        
        print(f"\nğŸ“ˆ å¤„ç†ç»Ÿè®¡")
        print(f"æ€»å¤„ç†åŒ…æ•°: {total_packets_processed}")
        print(f"TCPåŒ…æ•°: {total_tcp_packets} ({(total_tcp_packets/max(1,total_packets_processed)*100):.1f}%)")
        print(f"è½½è·åŒ…æ•°: {total_payload_packets} ({(total_payload_packets/max(1,total_tcp_packets)*100):.1f}%)")
        print(f"TLSåŒ…æ•°: {total_tls_packets} ({(total_tls_packets/max(1,total_payload_packets)*100):.1f}%)")
        print(f"å°è£…åŒ…æ•°: {total_encapsulated_packets} ({(total_encapsulated_packets/max(1,total_packets_processed)*100):.1f}%)")
        
        if total_original_payload_size > 0:
            overall_trim_effect = ((total_original_payload_size - total_trimmed_payload_size) / total_original_payload_size) * 100
            print(f"\nâœ‚ï¸ è½½è·è£åˆ‡æ•ˆæœ")
            print(f"åŸå§‹è½½è·å¤§å°: {total_original_payload_size:,} å­—èŠ‚")
            print(f"è£åˆ‡åå¤§å°: {total_trimmed_payload_size:,} å­—èŠ‚")
            print(f"æ•´ä½“è£åˆ‡æ•ˆæœ: {overall_trim_effect:.1f}%")
        
        print(f"\nğŸ·ï¸ æŒ‰å°è£…ç±»å‹ç»Ÿè®¡")
        for encap_type, stats in encapsulation_type_stats.items():
            success_rate = (stats['success'] / stats['count']) * 100
            avg_trim_effect = stats['total_trim_effect'] / max(1, stats['success'])
            print(f"{encap_type}: {stats['success']}/{stats['count']} ({success_rate:.1f}%æˆåŠŸç‡, {avg_trim_effect:.1f}%å¹³å‡è£åˆ‡æ•ˆæœ)")
        
        if failed_samples:
            print(f"\nâŒ å¤±è´¥æ ·æœ¬è¯¦æƒ…")
            for description, errors in failed_samples:
                print(f"  {description}: {errors[0] if errors else 'æœªçŸ¥é”™è¯¯'}")
        
        # æœ€ç»ˆéªŒè¯
        success_rate = (successful_samples / total_samples) * 100
        assert success_rate >= 80, f"è½½è·è£åˆ‡åŠŸèƒ½æ•´ä½“æˆåŠŸç‡åº”â‰¥80%ï¼Œå®é™…: {success_rate:.1f}%"
        
        print(f"\nğŸ‰ è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯å®Œæˆ: {success_rate:.1f}%æˆåŠŸç‡")
        print(f"âœ… æ‰€æœ‰15ä¸ªæ ·æœ¬çš„è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯é€šè¿‡!")
    
    def test_encapsulated_payload_trimming_capabilities(self, trimming_validator):
        """ä¸“é—¨æµ‹è¯•å¤šå±‚å°è£…çš„è½½è·è£åˆ‡èƒ½åŠ›"""
        encapsulated_samples = [
            ("tests/data/samples/singlevlan/10.200.33.61(10ç¬”).pcap", "single_vlan", "Single VLAN"),
            ("tests/data/samples/doublevlan/172.24.0.51.pcap", "double_vlan", "Double VLAN"),
            ("tests/data/samples/mpls/mpls.pcap", "mpls", "MPLS"),
            ("tests/data/samples/vxlan/vxlan.pcap", "vxlan", "VXLAN"),
            ("tests/data/samples/gre/20160406152100.pcap", "gre", "GRE"),
            ("tests/data/samples/vlan_gre/case17-parts.pcap", "vlan_gre", "VLAN+GRE"),
            ("tests/data/samples/vxlan_vlan/vxlan_servicetag_1001.pcap", "vxlan_vlan", "VXLAN+VLAN"),
        ]
        
        print(f"\nğŸ” å¤šå±‚å°è£…è½½è·è£åˆ‡èƒ½åŠ›éªŒè¯")
        print(f"=" * 50)
        
        encap_success = 0
        encap_total = 0
        
        for file_path, category, encap_type in encapsulated_samples:
            sample_file = Path(file_path)
            
            if not sample_file.exists():
                continue
            
            encap_total += 1
            result = trimming_validator.validate_payload_trimming(sample_file, category, max_test_packets=50)
            
            print(f"\n{encap_type}: ", end="")
            
            # éªŒè¯å°è£…æ£€æµ‹
            if result.encapsulated_packets > 0:
                print(f"âœ…å°è£…æ£€æµ‹ ", end="")
                
                # éªŒè¯è½½è·è®¿é—®
                if result.encap_payload_accessible:
                    print(f"âœ…è½½è·è®¿é—® ", end="")
                    
                    # éªŒè¯è£åˆ‡å¤„ç†
                    if result.encap_trim_success:
                        print(f"âœ…è£åˆ‡å¤„ç†")
                        encap_success += 1
                    else:
                        print(f"âŒè£åˆ‡å¤„ç†")
                else:
                    print(f"âŒè½½è·è®¿é—®")
            else:
                print(f"âš ï¸æ— å°è£…åŒ…")
        
        encap_success_rate = (encap_success / max(1, encap_total)) * 100
        print(f"\nğŸ“Š å¤šå±‚å°è£…è½½è·è£åˆ‡æˆåŠŸç‡: {encap_success}/{encap_total} ({encap_success_rate:.1f}%)")
        
        # éªŒè¯å¤šå±‚å°è£…å¤„ç†èƒ½åŠ›è¾¾æ ‡
        assert encap_success_rate >= 70, f"å¤šå±‚å°è£…è½½è·è£åˆ‡æˆåŠŸç‡åº”â‰¥70%ï¼Œå®é™…: {encap_success_rate:.1f}%"
        print(f"âœ… å¤šå±‚å°è£…è½½è·è£åˆ‡èƒ½åŠ›éªŒè¯é€šè¿‡!") 