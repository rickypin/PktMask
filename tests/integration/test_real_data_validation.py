#!/usr/bin/env python3
"""
PktMask çœŸå®æ ·æœ¬æ•°æ®å®Œæ•´éªŒè¯æµ‹è¯•
è¦†ç›– tests/data/samples/ ä¸‹çš„æ‰€æœ‰ç›®å½•
"""
import pytest
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from scapy.all import rdpcap, Packet

# å¯¼å…¥PktMaskæ ¸å¿ƒç»„ä»¶
from src.pktmask.core.encapsulation.detector import EncapsulationDetector
from src.pktmask.core.encapsulation.parser import ProtocolStackParser
from src.pktmask.core.encapsulation.adapter import ProcessingAdapter
from src.pktmask.core.strategy import HierarchicalAnonymizationStrategy
from src.pktmask.core.processors import EnhancedTrimmer


@dataclass
class SampleFileInfo:
    """æ ·æœ¬æ–‡ä»¶ä¿¡æ¯"""
    path: Path
    category: str
    expected_encapsulation: str
    description: str
    min_packets: int = 1
    max_test_packets: int = 100  # é™åˆ¶æµ‹è¯•åŒ…æ•°é‡ï¼Œé¿å…è¿‡æ…¢


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®"""
    file_path: str
    category: str
    success: bool
    total_packets: int
    tested_packets: int
    encapsulation_stats: Dict[str, int]
    ip_count: int
    tcp_sessions: int
    processing_time: float
    errors: List[str]
    validation_details: Dict


class RealDataValidator:
    """çœŸå®æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        self.detector = EncapsulationDetector()
        self.parser = ProtocolStackParser()
        self.adapter = ProcessingAdapter()
        self.ip_strategy = HierarchicalAnonymizationStrategy()
        self.trimming = IntelligentTrimmingStep()
        self.logger = logging.getLogger(__name__)
        
    def get_sample_file_map(self) -> Dict[str, List[SampleFileInfo]]:
        """è·å–æ‰€æœ‰æ ·æœ¬æ–‡ä»¶çš„åˆ†ç±»æ˜ å°„"""
        samples_dir = Path("tests/data/samples")
        
        # å®šä¹‰æ‰€æœ‰ç›®å½•çš„é¢„æœŸå°è£…ç±»å‹å’Œæè¿°
        directory_config = {
            "TLS": {
                "category": "plain_ip",
                "encapsulation": "plain",
                "description": "åŸºç¡€TCP/IP + TLSæµé‡",
                "pattern": "*.pcap"
            },
            "TLS70": {
                "category": "plain_ip_tls70",
                "encapsulation": "plain",
                "description": "TLS 7.0ç‰ˆæœ¬æµé‡",
                "pattern": "*.pcap"
            },
            "singlevlan": {
                "category": "single_vlan",
                "encapsulation": "vlan",
                "description": "å•å±‚VLANå°è£…(802.1Q)",
                "pattern": "*.pcap"
            },
            "doublevlan": {
                "category": "double_vlan",
                "encapsulation": "double_vlan",
                "description": "åŒå±‚VLANå°è£…(802.1ad QinQ)",
                "pattern": "*.pcap"
            },
            "doublevlan_tls": {
                "category": "double_vlan_tls",
                "encapsulation": "double_vlan",
                "description": "åŒå±‚VLAN + TLSç»„åˆ",
                "pattern": "*.pcap"
            },
            "mpls": {
                "category": "mpls",
                "encapsulation": "mpls",
                "description": "MPLSæ ‡ç­¾äº¤æ¢",
                "pattern": "*.pcap"
            },
            "gre": {
                "category": "gre_tunnel",
                "encapsulation": "gre",
                "description": "GREéš§é“å°è£…",
                "pattern": "*.pcap"
            },
            "vxlan": {
                "category": "vxlan",
                "encapsulation": "vxlan",
                "description": "VXLANè™šæ‹ŸåŒ–ç½‘ç»œ",
                "pattern": "*.pcap"
            },
            "vxlan4787": {
                "category": "vxlan_custom",
                "encapsulation": "vxlan",
                "description": "VXLANè‡ªå®šä¹‰ç«¯å£4787",
                "pattern": "*.pcap"
            },
            "vxlan_vlan": {
                "category": "vxlan_vlan_composite",
                "encapsulation": "composite",
                "description": "VXLAN + VLANå¤åˆå°è£…",
                "pattern": "*.pcap"
            },
            "vlan_gre": {
                "category": "vlan_gre_composite",
                "encapsulation": "composite",
                "description": "VLAN + GREå¤åˆå°è£…",
                "pattern": "*.pcap"
            },
            "IPTCP-200ips": {
                "category": "large_ip_set",
                "encapsulation": "plain",
                "description": "å¤§IPåœ°å€é›†æµ‹è¯•æ•°æ®",
                "pattern": "*.pcap*"
            },
            "IPTCP-TC-001-1-20160407": {
                "category": "test_case_001",
                "encapsulation": "mixed",
                "description": "æµ‹è¯•ç”¨ä¾‹001ç³»åˆ—",
                "pattern": "*.pcap*"
            },
            "IPTCP-TC-002-5-20220215": {
                "category": "test_case_002_5",
                "encapsulation": "mixed",
                "description": "æµ‹è¯•ç”¨ä¾‹002-5ç³»åˆ—",
                "pattern": "*.pcap*"
            },
            "IPTCP-TC-002-8-20210817": {
                "category": "test_case_002_8",
                "encapsulation": "mixed",
                "description": "æµ‹è¯•ç”¨ä¾‹002-8ç³»åˆ—",
                "pattern": "*.pcap*"
            },
            "empty": {
                "category": "empty_directory",
                "encapsulation": "none",
                "description": "ç©ºç›®å½•ï¼ˆè·³è¿‡æµ‹è¯•ï¼‰",
                "pattern": "*.pcap*"
            }
        }
        
        file_map = {}
        
        for dir_name, config in directory_config.items():
            dir_path = samples_dir / dir_name
            if not dir_path.exists():
                self.logger.warning(f"ç›®å½•ä¸å­˜åœ¨: {dir_path}")
                continue
                
            # è·³è¿‡ç©ºç›®å½•
            if config["category"] == "empty_directory":
                continue
                
            files = list(dir_path.glob(config["pattern"]))
            # è¿‡æ»¤æ‰.DS_Storeç­‰ç³»ç»Ÿæ–‡ä»¶
            files = [f for f in files if not f.name.startswith('.') and f.suffix in ['.pcap', '.pcapng']]
            
            if not files:
                self.logger.warning(f"ç›®å½• {dir_name} ä¸­æ²¡æœ‰æ‰¾åˆ°pcapæ–‡ä»¶")
                continue
                
            category = config["category"]
            if category not in file_map:
                file_map[category] = []
                
            for file_path in files:
                file_info = SampleFileInfo(
                    path=file_path,
                    category=category,
                    expected_encapsulation=config["encapsulation"],
                    description=config["description"]
                )
                file_map[category].append(file_info)
                
        return file_map
    
    def validate_sample_file(self, sample_info: SampleFileInfo) -> TestResult:
        """éªŒè¯å•ä¸ªæ ·æœ¬æ–‡ä»¶"""
        start_time = time.time()
        errors = []
        encapsulation_stats = {}
        ip_addresses = set()
        tcp_sessions = 0
        
        try:
            # è¯»å–pcapæ–‡ä»¶
            packets = rdpcap(str(sample_info.path))
            total_packets = len(packets)
            
            if total_packets == 0:
                errors.append("æ–‡ä»¶ä¸­æ²¡æœ‰æ•°æ®åŒ…")
                return TestResult(
                    file_path=str(sample_info.path),
                    category=sample_info.category,
                    success=False,
                    total_packets=0,
                    tested_packets=0,
                    encapsulation_stats={},
                    ip_count=0,
                    tcp_sessions=0,
                    processing_time=time.time() - start_time,
                    errors=errors,
                    validation_details={}
                )
            
            # é™åˆ¶æµ‹è¯•åŒ…æ•°é‡
            test_packets = packets[:sample_info.max_test_packets]
            tested_count = len(test_packets)
            
            # å¤„ç†æ¯ä¸ªæ•°æ®åŒ…
            for i, packet in enumerate(test_packets):
                try:
                    # 1. å°è£…ç±»å‹æ£€æµ‹
                    encap_type = self.detector.detect_encapsulation_type(packet)
                    encap_name = encap_type.value
                    encapsulation_stats[encap_name] = encapsulation_stats.get(encap_name, 0) + 1
                    
                    # 2. åè®®æ ˆè§£æ
                    layer_info = self.parser.parse_packet_layers(packet)
                    
                    # 3. IPåœ°å€æå–
                    adapter_result = self.adapter.analyze_packet_for_ip_processing(packet)
                    if 'ip_layers' in adapter_result:
                        for ip_layer in adapter_result['ip_layers']:
                            if hasattr(ip_layer, 'src_ip'):
                                ip_addresses.add(str(ip_layer.src_ip))
                            if hasattr(ip_layer, 'dst_ip'):
                                ip_addresses.add(str(ip_layer.dst_ip))
                    
                    # 4. TCPä¼šè¯è®¡æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    if packet.haslayer('TCP'):
                        tcp_sessions += 1
                        
                except Exception as e:
                    errors.append(f"åŒ… {i+1} å¤„ç†é”™è¯¯: {str(e)}")
                    continue
            
            # éªŒè¯ç»“æœ
            validation_details = {
                "expected_encapsulation": sample_info.expected_encapsulation,
                "detected_encapsulations": encapsulation_stats,
                "layer_analysis_success": len(errors) < tested_count * 0.1,  # 90%æˆåŠŸç‡
                "ip_extraction_success": len(ip_addresses) > 0,
                "file_size_mb": sample_info.path.stat().st_size / (1024 * 1024)
            }
            
            # åˆ¤æ–­æµ‹è¯•æ˜¯å¦æˆåŠŸ
            success = (
                len(errors) < tested_count * 0.2 and  # é”™è¯¯ç‡å°äº20%
                len(encapsulation_stats) > 0 and     # è‡³å°‘æ£€æµ‹åˆ°ä¸€ç§å°è£…
                len(ip_addresses) > 0                # è‡³å°‘æå–åˆ°ä¸€ä¸ªIP
            )
            
            processing_time = time.time() - start_time
            
            return TestResult(
                file_path=str(sample_info.path),
                category=sample_info.category,
                success=success,
                total_packets=total_packets,
                tested_packets=tested_count,
                encapsulation_stats=encapsulation_stats,
                ip_count=len(ip_addresses),
                tcp_sessions=tcp_sessions,
                processing_time=processing_time,
                errors=errors[:10],  # åªä¿ç•™å‰10ä¸ªé”™è¯¯
                validation_details=validation_details
            )
            
        except Exception as e:
            errors.append(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
            return TestResult(
                file_path=str(sample_info.path),
                category=sample_info.category,
                success=False,
                total_packets=0,
                tested_packets=0,
                encapsulation_stats={},
                ip_count=0,
                tcp_sessions=0,
                processing_time=time.time() - start_time,
                errors=errors,
                validation_details={}
            )


@pytest.mark.integration
@pytest.mark.real_data
@pytest.mark.slow
class TestRealDataValidation:
    """çœŸå®æ•°æ®éªŒè¯æµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def validator(self):
        """åˆ›å»ºéªŒè¯å™¨å®ä¾‹"""
        return RealDataValidator()
    
    @pytest.fixture(scope="class")
    def sample_files(self, validator):
        """è·å–æ‰€æœ‰æ ·æœ¬æ–‡ä»¶"""
        return validator.get_sample_file_map()
    
    def test_all_sample_directories_covered(self, sample_files):
        """æµ‹è¯•ç¡®ä¿æ‰€æœ‰ç›®å½•éƒ½è¢«è¦†ç›–"""
        samples_dir = Path("tests/data/samples")
        all_dirs = [d for d in samples_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]
        
        covered_dirs = set()
        for category, files in sample_files.items():
            for file_info in files:
                covered_dirs.add(file_info.path.parent.name)
        
        # æ’é™¤emptyç›®å½•
        expected_dirs = {d.name for d in all_dirs if d.name != "empty"}
        
        missing_dirs = expected_dirs - covered_dirs
        assert not missing_dirs, f"ä»¥ä¸‹ç›®å½•æ²¡æœ‰æµ‹è¯•è¦†ç›–: {missing_dirs}"
        
        print(f"âœ… ç›®å½•è¦†ç›–æ£€æŸ¥é€šè¿‡: {len(covered_dirs)}/{len(expected_dirs)} ä¸ªç›®å½•")
    
    @pytest.mark.parametrize("category", [
        "plain_ip", "plain_ip_tls70", "single_vlan", "double_vlan", 
        "double_vlan_tls", "mpls", "gre_tunnel", "vxlan", "vxlan_custom",
        "vxlan_vlan_composite", "vlan_gre_composite", "large_ip_set",
        "test_case_001", "test_case_002_5", "test_case_002_8"
    ])
    def test_sample_category_validation(self, validator, sample_files, category):
        """æµ‹è¯•ç‰¹å®šç±»åˆ«çš„æ ·æœ¬æ–‡ä»¶"""
        if category not in sample_files:
            pytest.skip(f"ç±»åˆ« {category} æ²¡æœ‰å¯ç”¨çš„æ ·æœ¬æ–‡ä»¶")
        
        category_files = sample_files[category]
        results = []
        
        for sample_info in category_files:
            print(f"\nğŸ§ª æµ‹è¯•æ–‡ä»¶: {sample_info.path.name} ({category})")
            result = validator.validate_sample_file(sample_info)
            results.append(result)
            
            # æ‰“å°ç»“æœæ‘˜è¦
            if result.success:
                print(f"   âœ… æˆåŠŸ - {result.tested_packets}/{result.total_packets} åŒ…")
                print(f"   ğŸ“¦ å°è£…ç±»å‹: {result.encapsulation_stats}")
                print(f"   ğŸŒ IPåœ°å€: {result.ip_count} ä¸ª")
                print(f"   â±ï¸  å¤„ç†æ—¶é—´: {result.processing_time:.3f}s")
            else:
                print(f"   âŒ å¤±è´¥ - é”™è¯¯: {len(result.errors)}")
                for error in result.errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                    print(f"      â€¢ {error}")
        
        # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªæ–‡ä»¶æµ‹è¯•æˆåŠŸ
        successful_files = [r for r in results if r.success]
        total_files = len(results)
        success_rate = len(successful_files) / total_files if total_files > 0 else 0
        
        assert success_rate >= 0.8, f"ç±»åˆ« {category} æˆåŠŸç‡å¤ªä½: {success_rate:.1%} ({len(successful_files)}/{total_files})"
        
        print(f"\nğŸ“Š ç±»åˆ« {category} æµ‹è¯•å®Œæˆ:")
        print(f"   æˆåŠŸç‡: {success_rate:.1%} ({len(successful_files)}/{total_files})")
    
    def test_comprehensive_real_data_validation(self, validator, sample_files):
        """ç»¼åˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•"""
        all_results = []
        category_stats = {}
        
        print("\nğŸš€ å¼€å§‹ç»¼åˆçœŸå®æ•°æ®éªŒè¯")
        print("=" * 60)
        
        for category, files in sample_files.items():
            print(f"\nğŸ“ å¤„ç†ç±»åˆ«: {category} ({len(files)} ä¸ªæ–‡ä»¶)")
            category_results = []
            
            for sample_info in files:
                result = validator.validate_sample_file(sample_info)
                category_results.append(result)
                all_results.append(result)
            
            # è®¡ç®—ç±»åˆ«ç»Ÿè®¡
            successful = [r for r in category_results if r.success]
            category_stats[category] = {
                "total_files": len(files),
                "successful_files": len(successful),
                "success_rate": len(successful) / len(files) if files else 0,
                "total_packets": sum(r.total_packets for r in category_results),
                "avg_processing_time": sum(r.processing_time for r in category_results) / len(category_results) if category_results else 0
            }
            
            print(f"   âœ… æˆåŠŸ: {len(successful)}/{len(files)} æ–‡ä»¶")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self._generate_validation_report(all_results, category_stats)
        
        # æ•´ä½“éªŒè¯
        total_files = len(all_results)
        successful_files = len([r for r in all_results if r.success])
        overall_success_rate = successful_files / total_files if total_files > 0 else 0
        
        print(f"\nğŸ¯ ç»¼åˆéªŒè¯ç»“æœ:")
        print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"   æˆåŠŸæ–‡ä»¶æ•°: {successful_files}")
        print(f"   æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1%}")
        
        # è¦æ±‚æ•´ä½“æˆåŠŸç‡è‡³å°‘90%
        assert overall_success_rate >= 0.9, f"æ•´ä½“æˆåŠŸç‡å¤ªä½: {overall_success_rate:.1%}"
        assert total_files >= 8, f"æµ‹è¯•æ–‡ä»¶æ•°é‡å¤ªå°‘: {total_files}"
    
    def _generate_validation_report(self, results: List[TestResult], category_stats: Dict):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_data = {
            "test_summary": {
                "total_files": len(results),
                "successful_files": len([r for r in results if r.success]),
                "success_rate": len([r for r in results if r.success]) / len(results) if results else 0,
                "test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "categories_tested": len(category_stats)
            },
            "category_stats": category_stats,
            "detailed_results": [
                {
                    "file": result.file_path,
                    "category": result.category,
                    "success": result.success,
                    "total_packets": result.total_packets,
                    "tested_packets": result.tested_packets,
                    "encapsulation_stats": result.encapsulation_stats,
                    "ip_count": result.ip_count,
                    "tcp_sessions": result.tcp_sessions,
                    "processing_time": result.processing_time,
                    "validation_details": result.validation_details,
                    "errors": result.errors
                }
                for result in results
            ]
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_file = reports_dir / "real_data_validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


# ç‹¬ç«‹è¿è¡Œæ”¯æŒ
if __name__ == "__main__":
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    validator = RealDataValidator()
    sample_files = validator.get_sample_file_map()
    
    print("ğŸ” å‘ç°çš„æ ·æœ¬æ–‡ä»¶:")
    for category, files in sample_files.items():
        print(f"  {category}: {len(files)} ä¸ªæ–‡ä»¶")
    
    # è¿è¡Œå¿«é€ŸéªŒè¯
    print("\nğŸš€ è¿è¡Œå¿«é€ŸéªŒè¯...")
    for category, files in sample_files.items():
        if files:
            sample = files[0]  # æµ‹è¯•æ¯ä¸ªç±»åˆ«çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶
            result = validator.validate_sample_file(sample)
            status = "âœ…" if result.success else "âŒ"
            print(f"  {status} {category}: {sample.path.name}") 