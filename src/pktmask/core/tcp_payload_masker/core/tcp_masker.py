"""
TCPè½½è·æ©ç å¤„ç†å™¨ä¸»è¦APIå®ç°

è¿™æ˜¯æ¨¡å—çš„æ ¸å¿ƒAPIç±»ï¼Œä¸“ç”¨äºTCPè½½è·çš„ä¿ç•™èŒƒå›´æ©ç å¤„ç†ã€‚
"""

import time
import threading
from typing import Dict, Optional, Any, List, Tuple, Callable
import logging
from pathlib import Path

from .keep_range_models import TcpKeepRangeEntry, TcpMaskingResult, TcpKeepRangeTable
from .config import ConfigManager, create_config_manager
from .protocol_control import ProtocolBindingController
from ..exceptions import (
    TcpPayloadMaskerError,
    ProtocolBindingError, 
    FileConsistencyError,
    ValidationError
)
from .file_handler import PcapFileHandler
from .keep_range_applier import MaskApplier


class TcpPayloadMasker:
    """TCPè½½è·æ©ç å¤„ç†å™¨
    
    ä¸“ç”¨äºTCPè½½è·çš„ä¿ç•™èŒƒå›´æ©ç å¤„ç†ã€‚é‡‡ç”¨éšç§ä¼˜å…ˆè®¾è®¡ç†å¿µï¼š
    é»˜è®¤æ©ç æ‰€æœ‰TCPè½½è·ï¼Œä½†ä¿ç•™æŒ‡å®šçš„åè®®å¤´éƒ¨èŒƒå›´ã€‚
    
    ä¸»è¦ç‰¹æ€§ï¼š
    - TCPä¸“ç”¨ï¼šåªå¤„ç†TCPåè®®ï¼Œä¸æ”¯æŒå…¶ä»–åè®®
    - ä¿ç•™èŒƒå›´ï¼šè®°å½•è¦ä¿ç•™çš„å­—èŠ‚èŒƒå›´ï¼Œå…¶ä½™å…¨éƒ¨æ©ç ä¸º0x00
    - éšç§ä¼˜å…ˆï¼šé»˜è®¤æ©ç æ‰€æœ‰è½½è·ï¼Œæœ€å¤§åŒ–éšç§ä¿æŠ¤
    - åè®®ä¿ç•™ï¼šæ”¯æŒTLS/HTTP/SSHç­‰åè®®å¤´éƒ¨è‡ªåŠ¨ä¿ç•™
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ©ç å¤„ç†å™¨
        
        Args:
            config: å¯é€‰é…ç½®å‚æ•°ï¼Œä¼šä¸é»˜è®¤é…ç½®åˆå¹¶
        """
        # é…ç½®ç®¡ç†
        self.config_manager = create_config_manager(config)
        self.logger = logging.getLogger(__name__)
        
        # åè®®ç»‘å®šæ§åˆ¶å™¨ï¼ˆPhase 2æ–°å¢ï¼‰
        self.protocol_controller = ProtocolBindingController(self.logger)
        
        # çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºåè®®ç»‘å®šæ“ä½œï¼‰
        self._binding_lock = threading.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._processing_stats = {
            'total_files_processed': 0,
            'total_packets_processed': 0,
            'total_packets_modified': 0,
            'total_bytes_masked': 0,
            'total_bytes_kept': 0,
            'total_tcp_streams_processed': 0,
            'total_processing_time': 0.0
        }
        
        self.logger.info("âœ… TCPè½½è·æ©ç å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.debug(f"é…ç½®æ‘˜è¦: {self.config_manager.export_summary()}")
    
    def mask_tcp_payloads_with_keep_ranges(
        self,
        input_pcap: str,
        keep_range_table: TcpKeepRangeTable,
        output_pcap: str
    ) -> TcpMaskingResult:
        """ä¸»è¦APIæ¥å£ï¼šå¯¹TCPè½½è·åº”ç”¨ä¿ç•™èŒƒå›´æ©ç 
        
        é‡‡ç”¨éšç§ä¼˜å…ˆåŸåˆ™ï¼šé»˜è®¤æ©ç æ‰€æœ‰TCPè½½è·ï¼Œåªä¿ç•™æŒ‡å®šçš„å­—èŠ‚èŒƒå›´ã€‚
        ä¸“ç”¨äºTCPåè®®ï¼Œä¸å¤„ç†å…¶ä»–åè®®ç±»å‹ã€‚
        
        Args:
            input_pcap: è¾“å…¥PCAPæ–‡ä»¶è·¯å¾„
            keep_range_table: TCPä¿ç•™èŒƒå›´è¡¨
            output_pcap: è¾“å‡ºPCAPæ–‡ä»¶è·¯å¾„
            
        Returns:
            TcpMaskingResult: å¤„ç†ç»“æœå’Œè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            
        Raises:
            ValidationError: è¾“å…¥å‚æ•°æ— æ•ˆ
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ProtocolBindingError: åè®®è§£ææ§åˆ¶å¤±è´¥
            FileConsistencyError: æ–‡ä»¶ä¸€è‡´æ€§éªŒè¯å¤±è´¥
            TcpPayloadMaskerError: å…¶ä»–å¤„ç†é”™è¯¯
            
        Example:
            >>> masker = TcpPayloadMasker()
            >>> keep_range_table = TcpKeepRangeTable()
            >>> keep_range_table.add_keep_range_entry(TcpKeepRangeEntry(
            ...     stream_id="TCP_1.2.3.4:443_5.6.7.8:1234_forward",
            ...     sequence_start=1000,
            ...     sequence_end=2000,
            ...     keep_ranges=[(0, 5)],  # ä¿ç•™TLSå¤´éƒ¨5å­—èŠ‚
            ...     protocol_hint="TLS"
            ... ))
            >>> result = masker.mask_tcp_payloads_with_keep_ranges(
            ...     "input.pcap", keep_range_table, "output.pcap"
            ... )
            >>> print(f"æˆåŠŸå¤„ç† {result.modified_packets} ä¸ªTCPæ•°æ®åŒ…")
        """
        start_time = time.time()
        
        # åˆå§‹åŒ–ç»“æœå¯¹è±¡
        result = TcpMaskingResult(
            success=False,
            total_packets=0,
            modified_packets=0,
            bytes_masked=0,
            bytes_kept=0,
            tcp_streams_processed=0,
            processing_time=0.0
        )
        
        try:
            self.logger.info(f"ğŸš€ å¼€å§‹å¤„ç†PCAPæ–‡ä»¶: {input_pcap} -> {output_pcap}")
            
            # é˜¶æ®µ1: è¾“å…¥éªŒè¯
            self._validate_inputs(input_pcap, keep_range_table, output_pcap)
            self.logger.debug("âœ… è¾“å…¥éªŒè¯é€šè¿‡")
            
            # é˜¶æ®µ2: åè®®è§£ææ§åˆ¶ï¼ˆPhase 2å®ç°ï¼‰
            if self.config_manager.should_disable_protocol_parsing():
                self.protocol_controller.disable_protocol_parsing()
                self.logger.debug("âœ… åè®®è§£æå·²ç¦ç”¨")
            
            try:
                # é˜¶æ®µ3: æ ¸å¿ƒå¤„ç†é€»è¾‘
                result = self._process_pcap_file(input_pcap, keep_range_table, output_pcap, start_time)
                
                # é˜¶æ®µ4: ä¸€è‡´æ€§éªŒè¯
                if self.config_manager.is_strict_mode():
                    self._verify_file_consistency(input_pcap, output_pcap, result)
                    self.logger.debug("âœ… æ–‡ä»¶ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
                
            finally:
                # é˜¶æ®µ5: æ¢å¤åè®®è§£æçŠ¶æ€ï¼ˆPhase 2å®ç°ï¼‰
                if self.protocol_controller.is_protocol_parsing_disabled():
                    self.protocol_controller.restore_protocol_parsing()
                    self.logger.debug("âœ… åè®®è§£æçŠ¶æ€å·²æ¢å¤")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_global_stats(result)
            
            self.logger.info(f"ğŸ‰ å¤„ç†å®Œæˆ: {result.get_summary()}")
            return result
            
        except Exception as e:
            result.error_message = str(e)
            result.processing_time = time.time() - start_time
            
            self.logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
            
            # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿæ¢å¤åè®®ç»‘å®šï¼ˆPhase 2å®ç°ï¼‰
            if self.protocol_controller.is_protocol_parsing_disabled():
                try:
                    self.protocol_controller.restore_protocol_parsing()
                except Exception as restore_error:
                    self.logger.error(f"æ¢å¤åè®®è§£ææ—¶å‘ç”Ÿé”™è¯¯: {restore_error}")
            
            return result
    
    def _validate_inputs(
        self,
        input_pcap: str,
        keep_range_table: TcpKeepRangeTable,
        output_pcap: str
    ) -> None:
        """éªŒè¯è¾“å…¥å‚æ•°
        
        Args:
            input_pcap: è¾“å…¥æ–‡ä»¶è·¯å¾„
            keep_range_table: TCPä¿ç•™èŒƒå›´è¡¨
            output_pcap: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Raises:
            ValidationError: è¾“å…¥å‚æ•°æ— æ•ˆæ—¶
        """
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        input_path = Path(input_pcap)
        if not input_path.exists():
            raise ValidationError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_pcap}")
        
        if not input_path.is_file():
            raise ValidationError(f"è¾“å…¥è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {input_pcap}")
        
        if not self.config_manager.validate_file_format(input_pcap):
            supported = self.config_manager.get('supported_formats', [])
            raise ValidationError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {input_pcap}ï¼Œæ”¯æŒçš„æ ¼å¼: {supported}")
        
        # éªŒè¯TCPä¿ç•™èŒƒå›´è¡¨
        if not isinstance(keep_range_table, TcpKeepRangeTable):
            raise ValidationError("keep_range_tableå¿…é¡»æ˜¯TcpKeepRangeTableç±»å‹")
        
        if keep_range_table.get_total_entries() == 0:
            raise ValidationError("TCPä¿ç•™èŒƒå›´è¡¨ä¸ºç©ºï¼Œæ²¡æœ‰éœ€è¦å¤„ç†çš„æ¡ç›®")
        
        # éªŒè¯ä¿ç•™èŒƒå›´è¡¨ä¸€è‡´æ€§
        consistency_issues = keep_range_table.validate_consistency()
        if consistency_issues:
            raise ValidationError(f"TCPä¿ç•™èŒƒå›´è¡¨ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {'; '.join(consistency_issues)}")
        
        # éªŒè¯è¾“å‡ºè·¯å¾„
        output_path = Path(output_pcap)
        if output_path.exists() and output_path.is_dir():
            raise ValidationError(f"è¾“å‡ºè·¯å¾„æ˜¯ç›®å½•: {output_pcap}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.logger.debug(
            f"è¾“å…¥éªŒè¯å®Œæˆ: è¾“å…¥æ–‡ä»¶={input_path.stat().st_size}å­—èŠ‚, "
            f"TCPä¿ç•™èŒƒå›´æ¡ç›®={keep_range_table.get_total_entries()}ä¸ª, "
            f"TCPæµæ•°é‡={keep_range_table.get_streams_count()}ä¸ª"
        )
    
    def _process_pcap_file(
        self,
        input_pcap: str,
        keep_range_table: TcpKeepRangeTable,
        output_pcap: str,
        start_time: float
    ) -> TcpMaskingResult:
        """å¤„ç†PCAPæ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘
        
        Args:
            input_pcap: è¾“å…¥æ–‡ä»¶è·¯å¾„
            keep_range_table: TCPä¿ç•™èŒƒå›´è¡¨
            output_pcap: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´
            
        Returns:
            TcpMaskingResult: å¤„ç†ç»“æœ
        """
        # åˆå§‹åŒ–ç»„ä»¶
        file_handler = PcapFileHandler(self.logger)
        keep_range_masker = MaskApplier(
            mask_byte_value=self.config_manager.get('mask_byte_value', 0x00),
            logger=self.logger
        )
        
        try:
            # é˜¶æ®µ1: è¯»å–æ•°æ®åŒ…
            self.logger.info(f"è¯»å–PCAPæ–‡ä»¶: {input_pcap}")
            packets = file_handler.read_packets(input_pcap)
            total_packets = len(packets)
            
            self.logger.info(f"æˆåŠŸè¯»å– {total_packets} ä¸ªæ•°æ®åŒ…")
            
            # é˜¶æ®µ2: åº”ç”¨TCPä¿ç•™èŒƒå›´æ©ç 
            self.logger.info("å¼€å§‹åº”ç”¨TCPä¿ç•™èŒƒå›´æ©ç ...")
            modified_packets, keep_range_stats = keep_range_masker.apply_keep_ranges_to_packets(
                packets, keep_range_table
            )
            
            # é˜¶æ®µ3: å†™å…¥è¾“å‡ºæ–‡ä»¶
            self.logger.info(f"å†™å…¥è¾“å‡ºæ–‡ä»¶: {output_pcap}")
            file_handler.write_packets(modified_packets, output_pcap)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # ç”Ÿæˆç»“æœ
            result = TcpMaskingResult(
                success=True,
                total_packets=total_packets,
                modified_packets=keep_range_stats.get('tcp_packets_modified', 0),
                bytes_masked=keep_range_stats.get('bytes_masked', 0),
                bytes_kept=keep_range_stats.get('bytes_kept', 0),
                tcp_streams_processed=keep_range_stats.get('tcp_streams_processed', 0),
                processing_time=processing_time
            )
            
            # æ·»åŠ è¯¦ç»†ä¿ç•™èŒƒå›´ç»Ÿè®¡ä¿¡æ¯
            result.add_keep_range_statistic('keep_range_table_entries', keep_range_table.get_total_entries())
            result.add_keep_range_statistic('keep_range_table_streams', keep_range_table.get_streams_count())
            result.add_keep_range_statistic('keep_ranges_applied', keep_range_stats.get('keep_ranges_applied', 0))
            result.add_keep_range_statistic('protocol_detections', len(keep_range_stats.get('protocol_detections', {})))
            
            # éªŒè¯åè®®è§£æç¦ç”¨æ•ˆæœ
            if self.config_manager.should_disable_protocol_parsing():
                protocol_stats = keep_range_masker.payload_extractor.verify_raw_layer_dominance(packets)
                result.add_keep_range_statistic('protocol_parsing_verification', len(protocol_stats))
                
                if not protocol_stats.get('protocol_parsing_disabled', False):
                    self.logger.warning(
                        f"åè®®è§£æç¦ç”¨æ•ˆæœä¸ä½³: Rawå±‚å­˜åœ¨ç‡ {protocol_stats.get('raw_layer_rate', 0):.2%}"
                    )
            
            self.logger.info(f"âœ… æ ¸å¿ƒå¤„ç†å®Œæˆ: {result.get_summary()}")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            
            self.logger.error(f"æ ¸å¿ƒå¤„ç†å¤±è´¥: {e}")
            
            return TcpMaskingResult(
                success=False,
                total_packets=0,
                modified_packets=0,
                bytes_masked=0,
                bytes_kept=0,
                tcp_streams_processed=0,
                processing_time=processing_time,
                error_message=str(e)
            )
    
    def verify_protocol_parsing_disabled(self, packets: list) -> Dict[str, Any]:
        """éªŒè¯åè®®è§£æç¦ç”¨æ•ˆæœï¼ˆPhase 2æ–°å¢æ–¹æ³•ï¼‰
        
        å§”æ‰˜ç»™åè®®æ§åˆ¶å™¨è¿›è¡ŒRawå±‚å­˜åœ¨ç‡éªŒè¯
        
        Args:
            packets: è¦éªŒè¯çš„æ•°æ®åŒ…åˆ—è¡¨
            
        Returns:
            Dict: éªŒè¯ç»“æœç»Ÿè®¡
        """
        return self.protocol_controller.verify_raw_layer_presence(packets)
    
    def get_protocol_binding_stats(self) -> Dict[str, Any]:
        """è·å–åè®®ç»‘å®šç»Ÿè®¡ä¿¡æ¯ï¼ˆPhase 2æ–°å¢æ–¹æ³•ï¼‰"""
        return self.protocol_controller.get_binding_statistics()
    
    def _verify_file_consistency(
        self,
        input_pcap: str,
        output_pcap: str,
        result: TcpMaskingResult
    ) -> None:
        """éªŒè¯è¾“å‡ºæ–‡ä»¶ä¸è¾“å…¥æ–‡ä»¶çš„ä¸€è‡´æ€§
        
        è¿™æ˜¯Phase 3çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œç›®å‰æ˜¯å ä½ç¬¦å®ç°ã€‚
        """
        self.logger.info("âš ï¸  æ–‡ä»¶ä¸€è‡´æ€§éªŒè¯å ä½ç¬¦ - å°†åœ¨Phase 3å®ç°")
    
    def _update_global_stats(self, result: TcpMaskingResult) -> None:
        """æ›´æ–°å…¨å±€ç»Ÿè®¡ä¿¡æ¯"""
        self._processing_stats['total_files_processed'] += 1
        self._processing_stats['total_packets_processed'] += result.total_packets
        self._processing_stats['total_packets_modified'] += result.modified_packets
        self._processing_stats['total_bytes_masked'] += result.bytes_masked
        self._processing_stats['total_bytes_kept'] = self._processing_stats.get('total_bytes_kept', 0) + result.bytes_kept
        self._processing_stats['total_tcp_streams_processed'] = self._processing_stats.get('total_tcp_streams_processed', 0) + result.tcp_streams_processed
        self._processing_stats['total_processing_time'] += result.processing_time
    
    def get_global_statistics(self) -> Dict[str, Any]:
        """è·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯"""
        stats = self._processing_stats.copy()
        
        # è®¡ç®—å¹³å‡å€¼
        if stats['total_files_processed'] > 0:
            stats['avg_packets_per_file'] = stats['total_packets_processed'] / stats['total_files_processed']
            stats['avg_processing_time_per_file'] = stats['total_processing_time'] / stats['total_files_processed']
        
        if stats['total_processing_time'] > 0:
            stats['avg_processing_speed_pps'] = stats['total_packets_processed'] / stats['total_processing_time']
        
        return stats
    
    def reset_statistics(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self._processing_stats = {
            'total_files_processed': 0,
            'total_packets_processed': 0,
            'total_packets_modified': 0,
            'total_bytes_masked': 0,
            'total_processing_time': 0.0
        }
        self.logger.debug("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def get_config_summary(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦"""
        return self.config_manager.export_summary()
    
    def update_config(self, updates: Dict[str, Any]) -> None:
        """æ›´æ–°é…ç½®å‚æ•°
        
        Args:
            updates: è¦æ›´æ–°çš„é…ç½®å‚æ•°
        """
        self.config_manager.update(updates)
        self.logger.debug(f"é…ç½®å·²æ›´æ–°: {updates}")
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£ï¼Œç¡®ä¿èµ„æºæ¸…ç†ï¼ˆPhase 2æ›´æ–°ï¼‰"""
        if self.protocol_controller.is_protocol_parsing_disabled():
            try:
                self.protocol_controller.restore_protocol_parsing()
            except Exception as e:
                self.logger.error(f"æ¸…ç†åè®®è§£æçŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def __repr__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        stats = self.get_global_statistics()
        return (
            f"TcpPayloadMasker("
            f"files_processed={stats['total_files_processed']}, "
            f"tcp_packets_processed={stats['total_packets_processed']}, "
            f"bytes_kept={stats.get('total_bytes_kept', 0)}, "
            f"config_hash={hash(str(self.config_manager.get_all()))}"
            f")"
        )
    
    def mask_tcp_payloads_batch(
        self,
        batch_jobs: List[Dict[str, Any]],
        progress_callback: Optional[Callable[[int, int, str], None]] = None
    ) -> List[TcpMaskingResult]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªTCPè½½è·æ©ç ä»»åŠ¡
        
        ä¼˜åŒ–æ€§èƒ½çš„æ‰¹é‡å¤„ç†æ¥å£ï¼Œæ”¯æŒè¿›åº¦å›è°ƒå’Œå¹¶å‘å¤„ç†ã€‚
        
        Args:
            batch_jobs: æ‰¹é‡ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«:
                - input_pcap: è¾“å…¥PCAPæ–‡ä»¶è·¯å¾„
                - keep_range_table: TCPä¿ç•™èŒƒå›´è¡¨
                - output_pcap: è¾“å‡ºPCAPæ–‡ä»¶è·¯å¾„
            progress_callback: å¯é€‰çš„è¿›åº¦å›è°ƒå‡½æ•°(å½“å‰ä»»åŠ¡, æ€»ä»»åŠ¡, çŠ¶æ€ä¿¡æ¯)
            
        Returns:
            List[TcpMaskingResult]: æ‰€æœ‰ä»»åŠ¡çš„å¤„ç†ç»“æœåˆ—è¡¨
            
        Example:
            >>> masker = TcpPayloadMasker()
            >>> jobs = [
            ...     {
            ...         "input_pcap": "input1.pcap",
            ...         "keep_range_table": table1,
            ...         "output_pcap": "output1.pcap"
            ...     },
            ...     {
            ...         "input_pcap": "input2.pcap", 
            ...         "keep_range_table": table2,
            ...         "output_pcap": "output2.pcap"
            ...     }
            ... ]
            >>> results = masker.mask_tcp_payloads_batch(jobs)
        """
        self.logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(batch_jobs)} ä¸ªTCPè½½è·æ©ç ä»»åŠ¡")
        
        results = []
        start_time = time.time()
        
        for i, job in enumerate(batch_jobs):
            current_task = i + 1
            total_tasks = len(batch_jobs)
            
            # æ›´æ–°è¿›åº¦
            if progress_callback:
                progress_callback(current_task, total_tasks, f"å¤„ç†ä»»åŠ¡ {current_task}/{total_tasks}")
            
            self.logger.info(f"ğŸ“ å¤„ç†ä»»åŠ¡ {current_task}/{total_tasks}: {job.get('input_pcap', 'Unknown')}")
            
            try:
                # éªŒè¯ä»»åŠ¡å‚æ•°
                if not all(key in job for key in ['input_pcap', 'keep_range_table', 'output_pcap']):
                    raise ValidationError(f"ä»»åŠ¡ {current_task} ç¼ºå°‘å¿…è¦å‚æ•°")
                
                # æ‰§è¡Œå•ä¸ªä»»åŠ¡
                result = self.mask_tcp_payloads_with_keep_ranges(
                    job['input_pcap'],
                    job['keep_range_table'],
                    job['output_pcap']
                )
                
                # æ·»åŠ æ‰¹é‡ä»»åŠ¡ä¿¡æ¯
                result.add_keep_range_statistic('batch_task_index', current_task)
                result.add_keep_range_statistic('batch_total_tasks', total_tasks)
                
                results.append(result)
                
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    status = "æˆåŠŸ" if result.success else "å¤±è´¥"
                    progress_callback(current_task, total_tasks, f"ä»»åŠ¡ {current_task} {status}")
                
            except Exception as e:
                self.logger.error(f"âŒ ä»»åŠ¡ {current_task} å¤„ç†å¤±è´¥: {e}")
                
                # åˆ›å»ºå¤±è´¥ç»“æœ 
                failed_result = TcpMaskingResult(
                    success=False,
                    total_packets=0,
                    modified_packets=0,
                    bytes_masked=0,
                    bytes_kept=0,
                    tcp_streams_processed=0,
                    processing_time=0.0,
                    error_message=str(e)
                )
                failed_result.add_keep_range_statistic('batch_task_index', current_task)
                failed_result.add_keep_range_statistic('batch_total_tasks', total_tasks)
                
                results.append(failed_result)
                
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    progress_callback(current_task, total_tasks, f"ä»»åŠ¡ {current_task} å¤±è´¥: {str(e)[:50]}")
        
        # æ‰¹é‡å¤„ç†ç»Ÿè®¡
        total_time = time.time() - start_time
        successful_tasks = sum(1 for r in results if r.success)
        
        self.logger.info(
            f"ğŸ¯ æ‰¹é‡å¤„ç†å®Œæˆ: {successful_tasks}/{len(batch_jobs)} ä¸ªä»»åŠ¡æˆåŠŸ, "
            f"æ€»è€—æ—¶: {total_time:.2f}ç§’, å¹³å‡: {total_time/len(batch_jobs):.2f}ç§’/ä»»åŠ¡"
        )
        
        return results
    
    def optimize_keep_range_table(self, keep_range_table: TcpKeepRangeTable) -> TcpKeepRangeTable:
        """ä¼˜åŒ–TCPä¿ç•™èŒƒå›´è¡¨ä»¥æå‡å¤„ç†æ€§èƒ½
        
        æ‰§è¡Œä»¥ä¸‹ä¼˜åŒ–ï¼š
        1. åˆå¹¶é‡å çš„ä¿ç•™èŒƒå›´
        2. æ’åºæ¡ç›®ä»¥æå‡æŸ¥æ‰¾æ•ˆç‡
        3. é¢„è®¡ç®—å¸¸ç”¨æŸ¥è¯¢ç»“æœ
        4. ä¼˜åŒ–å†…å­˜å¸ƒå±€
        
        Args:
            keep_range_table: å¾…ä¼˜åŒ–çš„ä¿ç•™èŒƒå›´è¡¨
            
        Returns:
            TcpKeepRangeTable: ä¼˜åŒ–åçš„ä¿ç•™èŒƒå›´è¡¨
        """
        self.logger.info("ğŸ”§ å¼€å§‹ä¼˜åŒ–TCPä¿ç•™èŒƒå›´è¡¨")
        
        optimization_start = time.time()
        
        # åˆ›å»ºä¼˜åŒ–åçš„è¡¨
        optimized_table = TcpKeepRangeTable()
        
        # æŒ‰æµIDåˆ†ç»„å¤„ç†
        stream_entries = {}
        for entry in keep_range_table.get_all_entries():
            stream_id = entry.stream_id
            if stream_id not in stream_entries:
                stream_entries[stream_id] = []
            stream_entries[stream_id].append(entry)
        
        total_optimizations = 0
        
        for stream_id, entries in stream_entries.items():
            # æŒ‰åºåˆ—å·æ’åº
            entries.sort(key=lambda e: e.sequence_start)
            
            # åˆå¹¶ç›¸é‚»æˆ–é‡å çš„æ¡ç›®
            merged_entries = []
            current_entry = None
            
            for entry in entries:
                if current_entry is None:
                    current_entry = entry
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå¹¶ï¼ˆåºåˆ—å·èŒƒå›´è¿ç»­æˆ–é‡å ï¼‰
                if (current_entry.sequence_end >= entry.sequence_start and 
                    current_entry.protocol_hint == entry.protocol_hint):
                    
                    # åˆå¹¶æ¡ç›®
                    merged_ranges = current_entry.keep_ranges + entry.keep_ranges
                    merged_ranges = self._merge_overlapping_ranges(merged_ranges)
                    
                    current_entry = TcpKeepRangeEntry(
                        stream_id=stream_id,
                        sequence_start=min(current_entry.sequence_start, entry.sequence_start),
                        sequence_end=max(current_entry.sequence_end, entry.sequence_end),
                        keep_ranges=merged_ranges,
                        protocol_hint=current_entry.protocol_hint
                    )
                    
                    total_optimizations += 1
                else:
                    # ä¸èƒ½åˆå¹¶ï¼Œä¿å­˜å½“å‰æ¡ç›®
                    merged_entries.append(current_entry)
                    current_entry = entry
            
            # ä¿å­˜æœ€åä¸€ä¸ªæ¡ç›®
            if current_entry:
                merged_entries.append(current_entry)
            
            # æ·»åŠ åˆ°ä¼˜åŒ–è¡¨ä¸­
            for entry in merged_entries:
                optimized_table.add_keep_range_entry(entry)
        
        optimization_time = time.time() - optimization_start
        
        original_count = keep_range_table.get_total_entries()
        optimized_count = optimized_table.get_total_entries()
        reduction_rate = (original_count - optimized_count) / original_count * 100 if original_count > 0 else 0
        
        self.logger.info(
            f"âœ… TCPä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–å®Œæˆ: {original_count} â†’ {optimized_count} æ¡ç›® "
            f"({reduction_rate:.1f}% å‡å°‘), {total_optimizations} æ¬¡åˆå¹¶, "
            f"è€—æ—¶: {optimization_time:.4f}ç§’"
        )
        
        return optimized_table
    
    def _merge_overlapping_ranges(self, ranges: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """åˆå¹¶é‡å çš„ä¿ç•™èŒƒå›´"""
        if not ranges:
            return []
        
        # æŒ‰èµ·å§‹ä½ç½®æ’åº
        sorted_ranges = sorted(ranges)
        merged = [sorted_ranges[0]]
        
        for current in sorted_ranges[1:]:
            last = merged[-1]
            
            # æ£€æŸ¥é‡å æˆ–ç›¸é‚»
            if current[0] <= last[1]:
                # åˆå¹¶èŒƒå›´
                merged[-1] = (last[0], max(last[1], current[1]))
            else:
                # æ·»åŠ æ–°èŒƒå›´
                merged.append(current)
        
        return merged
    
    def estimate_processing_time(
        self,
        input_pcap: str,
        keep_range_table: TcpKeepRangeTable
    ) -> Dict[str, float]:
        """ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆç”¨äºæ‰¹é‡å¤„ç†è§„åˆ’ï¼‰
        
        åŸºäºæ–‡ä»¶å¤§å°ã€ä¿ç•™èŒƒå›´è¡¨å¤æ‚åº¦ç­‰å› ç´ ä¼°ç®—å¤„ç†æ—¶é—´ã€‚
        
        Args:
            input_pcap: è¾“å…¥PCAPæ–‡ä»¶è·¯å¾„
            keep_range_table: TCPä¿ç•™èŒƒå›´è¡¨
            
        Returns:
            Dict[str, float]: ä¼°ç®—ç»“æœï¼ŒåŒ…å«:
                - estimated_time: é¢„ä¼°å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
                - confidence: ä¼°ç®—ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
                - file_size_mb: æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
                - complexity_score: å¤æ‚åº¦è¯„åˆ†
        """
        try:
            # è·å–æ–‡ä»¶å¤§å°
            file_size = Path(input_pcap).stat().st_size
            file_size_mb = file_size / (1024 * 1024)
            
            # è®¡ç®—å¤æ‚åº¦è¯„åˆ†
            complexity_score = (
                keep_range_table.get_total_entries() * 0.1 +
                keep_range_table.get_streams_count() * 0.5 +
                len(keep_range_table.get_all_stream_ids()) * 0.3
            )
            
            # åŸºäºå†å²ç»Ÿè®¡ä¼°ç®—å¤„ç†æ—¶é—´
            # åŸºå‡†ï¼š1MBæ–‡ä»¶çº¦éœ€0.1ç§’ï¼Œå¤æ‚åº¦æ¯å¢åŠ 1åˆ†çº¦å¢åŠ 0.05ç§’
            base_time = file_size_mb * 0.1
            complexity_time = complexity_score * 0.05
            estimated_time = base_time + complexity_time
            
            # ç½®ä¿¡åº¦åŸºäºç»Ÿè®¡æ•°æ®é‡
            global_stats = self.get_global_statistics()
            files_processed = global_stats.get('total_files_processed', 0)
            confidence = min(0.9, files_processed * 0.1)  # æœ€é«˜0.9
            
            return {
                'estimated_time': estimated_time,
                'confidence': confidence,
                'file_size_mb': file_size_mb,
                'complexity_score': complexity_score
            }
            
        except Exception as e:
            self.logger.warning(f"å¤„ç†æ—¶é—´ä¼°ç®—å¤±è´¥: {e}")
            return {
                'estimated_time': 1.0,  # é»˜è®¤ä¼°ç®—
                'confidence': 0.1,
                'file_size_mb': 0.0,
                'complexity_score': 0.0
            }
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
        
        Returns:
            Dict[str, Any]: æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…å«:
                - processing_speed: å¤„ç†é€Ÿåº¦ï¼ˆåŒ…/ç§’ï¼‰
                - throughput: ååé‡ï¼ˆMB/ç§’ï¼‰
                - efficiency_metrics: æ•ˆç‡æŒ‡æ ‡
                - resource_usage: èµ„æºä½¿ç”¨æƒ…å†µ
        """
        stats = self.get_global_statistics()
        
        # è®¡ç®—å¤„ç†é€Ÿåº¦
        total_time = stats.get('total_processing_time', 0.001)  # é¿å…é™¤é›¶
        total_packets = stats.get('total_packets_processed', 0)
        processing_speed = total_packets / total_time if total_time > 0 else 0
        
        # ä¼°ç®—ååé‡ï¼ˆå‡è®¾å¹³å‡åŒ…å¤§å°1KBï¼‰
        estimated_data_mb = total_packets * 1024 / (1024 * 1024)
        throughput_mbps = estimated_data_mb / total_time if total_time > 0 else 0
        
        # æ•ˆç‡æŒ‡æ ‡
        modification_efficiency = (
            stats.get('total_packets_modified', 0) / total_packets * 100 
            if total_packets > 0 else 0
        )
        
        stream_efficiency = (
            stats.get('total_tcp_streams_processed', 0) / 
            stats.get('total_files_processed', 1)  # å¹³å‡æ¯æ–‡ä»¶æµæ•°
        )
        
        return {
            'processing_speed': {
                'packets_per_second': processing_speed,
                'files_per_hour': stats.get('total_files_processed', 0) / (total_time / 3600) if total_time > 0 else 0
            },
            'throughput': {
                'mbps': throughput_mbps,
                'estimated_data_processed_mb': estimated_data_mb
            },
            'efficiency_metrics': {
                'modification_rate_percent': modification_efficiency,
                'avg_streams_per_file': stream_efficiency,
                'avg_processing_time_per_file': stats.get('avg_processing_time_per_file', 0)
            },
            'resource_usage': {
                'total_files_processed': stats.get('total_files_processed', 0),
                'total_processing_time': total_time,
                'avg_bytes_masked_per_stream': (
                    stats.get('total_bytes_masked', 0) / 
                    max(1, stats.get('total_tcp_streams_processed', 1))
                ),
                'avg_bytes_kept_per_stream': (
                    stats.get('total_bytes_kept', 0) / 
                    max(1, stats.get('total_tcp_streams_processed', 1))
                )
            }
        }
    
    def enable_performance_optimization(self, enable: bool = True) -> None:
        """å¯ç”¨/ç¦ç”¨æ€§èƒ½ä¼˜åŒ–æ¨¡å¼
        
        æ€§èƒ½ä¼˜åŒ–æ¨¡å¼åŒ…æ‹¬ï¼š
        - è‡ªåŠ¨ä¼˜åŒ–ä¿ç•™èŒƒå›´è¡¨
        - å¯ç”¨æ‰¹é‡å¤„ç†
        - é¢„ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢
        - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        
        Args:
            enable: æ˜¯å¦å¯ç”¨æ€§èƒ½ä¼˜åŒ–
        """
        self.config_manager.update({'performance_optimization_enabled': enable})
        
        if enable:
            self.logger.info("ğŸš€ æ€§èƒ½ä¼˜åŒ–æ¨¡å¼å·²å¯ç”¨")
            
            # å¯ç”¨ç›¸å…³ä¼˜åŒ–é€‰é¡¹
            optimizations = {
                'auto_optimize_keep_range_table': True,
                'enable_batch_processing': True,
                'cache_query_results': True,
                'optimize_memory_usage': True
            }
            
            self.config_manager.update(optimizations)
        else:
            self.logger.info("âš ï¸  æ€§èƒ½ä¼˜åŒ–æ¨¡å¼å·²ç¦ç”¨")
            
            # ç¦ç”¨ä¼˜åŒ–é€‰é¡¹
            optimizations = {
                'auto_optimize_keep_range_table': False,
                'enable_batch_processing': False,
                'cache_query_results': False,
                'optimize_memory_usage': False
            }
            
            self.config_manager.update(optimizations)
    
    def cleanup_resources(self) -> None:
        """æ¸…ç†èµ„æºå’Œä¸´æ—¶ç¼“å­˜
        
        é‡Šæ”¾å†…å­˜å ç”¨ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œé‡ç½®ç¼“å­˜ç­‰ã€‚
        é€‚ç”¨äºé•¿æ—¶é—´è¿è¡Œçš„æ‰¹é‡å¤„ç†ä»»åŠ¡ã€‚
        """
        self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†èµ„æº...")
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯ä¸­çš„å¤§å¯¹è±¡
        if hasattr(self, '_processing_stats'):
            # ä¿ç•™é‡è¦ç»Ÿè®¡ï¼Œæ¸…ç†è¯¦ç»†æ•°æ®
            essential_stats = {
                'total_files_processed': self._processing_stats.get('total_files_processed', 0),
                'total_processing_time': self._processing_stats.get('total_processing_time', 0.0)
            }
            self._processing_stats.clear()
            self._processing_stats.update(essential_stats)
        
        # æ¸…ç†åè®®æ§åˆ¶å™¨ç¼“å­˜
        if hasattr(self.protocol_controller, 'clear_cache'):
            self.protocol_controller.clear_cache()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ") 