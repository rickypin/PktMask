"""
TSharkå¢å¼ºæ©ç å¤„ç†å™¨

åŸºäºTSharkæ·±åº¦åè®®è§£æçš„å¢å¼ºæ©ç å¤„ç†å™¨ã€‚
æ•´åˆTSharkåˆ†æã€æ©ç è§„åˆ™ç”Ÿæˆã€Scapyåº”ç”¨çš„ä¸‰é˜¶æ®µæµç¨‹ã€‚
æ”¯æŒTLS 20-24æ‰€æœ‰åè®®ç±»å‹çš„æ™ºèƒ½åˆ†ç±»å¤„ç†ã€‚

ç‰¹æ€§:
- ä¸‰é˜¶æ®µå¤„ç†æµç¨‹ï¼šTShark â†’ è§„åˆ™ç”Ÿæˆ â†’ Scapyåº”ç”¨
- TLSåè®®ç±»å‹å®Œæ•´æ”¯æŒï¼š20/21/22/23/24
- è·¨TCPæ®µTLSæ¶ˆæ¯è¯†åˆ«å’Œå¤„ç†
- æ™ºèƒ½é™çº§æœºåˆ¶ï¼šç¡®ä¿ç³»ç»Ÿå¥å£®æ€§
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- å¢å¼ºçš„é”™è¯¯åˆ†ç±»ã€é‡è¯•å’Œè¯Šæ–­ç³»ç»Ÿ (Phase 2, Day 13)

é™çº§ç­–ç•¥:
1. TSharkä¸å¯ç”¨ â†’ é™çº§åˆ°EnhancedTrimmer
2. åè®®è§£æå¤±è´¥ â†’ é™çº§åˆ°æ ‡å‡†MaskStage
3. å…¶ä»–é”™è¯¯ â†’ é”™è¯¯æ¢å¤+é‡è¯•æœºåˆ¶

ä½œè€…: PktMask Team
åˆ›å»ºæ—¶é—´: 2025-07-02
ç‰ˆæœ¬: 1.0.0 (Phase 1, Day 5)
æ›´æ–°æ—¶é—´: 2025-01-22 (Phase 2, Day 13 - é”™è¯¯å¤„ç†å®Œå–„)
"""

import os
import tempfile
import shutil
from typing import Optional, Dict, Any, List, Union
from pathlib import Path
import logging
import time
import traceback
from dataclasses import dataclass, field
from enum import Enum

from .base_processor import BaseProcessor, ProcessorConfig, ProcessorResult
from ...infrastructure.logging import get_logger


class ErrorCategory(Enum):
    """é”™è¯¯åˆ†ç±»æšä¸¾"""
    DEPENDENCY_ERROR = "dependency_error"         # ä¾èµ–å·¥å…·é”™è¯¯ï¼ˆTSharkç­‰ï¼‰
    CONFIGURATION_ERROR = "configuration_error"   # é…ç½®é”™è¯¯
    INITIALIZATION_ERROR = "initialization_error" # åˆå§‹åŒ–é”™è¯¯
    PROCESSING_ERROR = "processing_error"         # å¤„ç†è¿‡ç¨‹é”™è¯¯
    IO_ERROR = "io_error"                        # æ–‡ä»¶I/Oé”™è¯¯
    MEMORY_ERROR = "memory_error"                # å†…å­˜é”™è¯¯
    TIMEOUT_ERROR = "timeout_error"              # è¶…æ—¶é”™è¯¯
    PROTOCOL_ERROR = "protocol_error"            # åè®®è§£æé”™è¯¯
    VALIDATION_ERROR = "validation_error"        # è¾“å…¥éªŒè¯é”™è¯¯
    UNKNOWN_ERROR = "unknown_error"              # æœªçŸ¥é”™è¯¯


class ErrorSeverity(Enum):
    """é”™è¯¯ä¸¥é‡æ€§æšä¸¾"""
    LOW = "low"           # å¯å¿½ç•¥çš„é”™è¯¯
    MEDIUM = "medium"     # ä¸­ç­‰ä¸¥é‡æ€§ï¼Œå¯ä»¥é™çº§å¤„ç†
    HIGH = "high"         # é«˜ä¸¥é‡æ€§ï¼Œéœ€è¦ç«‹å³å¤„ç†
    CRITICAL = "critical" # ä¸¥é‡é”™è¯¯ï¼Œåœæ­¢å¤„ç†


@dataclass
class ErrorContext:
    """é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    category: ErrorCategory
    severity: ErrorSeverity
    error_code: str
    message: str
    exception: Optional[Exception] = None
    stack_trace: Optional[str] = None
    timestamp: float = field(default_factory=time.time)
    file_context: Optional[str] = None
    stage_context: Optional[str] = None
    retry_count: int = 0
    recovery_attempted: bool = False
    mitigation_suggestions: List[str] = field(default_factory=list)


@dataclass
class RetryConfig:
    """é‡è¯•é…ç½®"""
    max_retries: int = 3
    base_delay: float = 1.0
    max_delay: float = 30.0
    exponential_backoff: bool = True
    retry_on_categories: List[ErrorCategory] = field(default_factory=lambda: [
        ErrorCategory.TIMEOUT_ERROR,
        ErrorCategory.PROCESSING_ERROR,
        ErrorCategory.IO_ERROR
    ])


class FallbackMode(Enum):
    """é™çº§æ¨¡å¼æšä¸¾"""
    NONE = "none"                    # æ— é™çº§ï¼Œç›´æ¥å¤±è´¥
    ENHANCED_TRIMMER = "enhanced_trimmer"   # é™çº§åˆ°EnhancedTrimmer
    MASK_STAGE = "mask_stage"        # é™çº§åˆ°æ ‡å‡†MaskStage
    RETRY = "retry"                  # é”™è¯¯æ¢å¤+é‡è¯•


@dataclass
class FallbackConfig:
    """é™çº§æœºåˆ¶é…ç½®"""
    enable_fallback: bool = True
    max_retries: int = 2
    retry_delay_seconds: float = 1.0
    tshark_check_timeout: float = 5.0
    fallback_on_tshark_unavailable: bool = True
    fallback_on_parse_error: bool = True
    fallback_on_other_errors: bool = True
    preferred_fallback_order: List[FallbackMode] = field(
        default_factory=lambda: [
            FallbackMode.ENHANCED_TRIMMER,
            FallbackMode.MASK_STAGE
        ]
    )


@dataclass
class TSharkEnhancedConfig:
    """TSharkå¢å¼ºæ©ç å¤„ç†å™¨é…ç½®"""
    # æ ¸å¿ƒåŠŸèƒ½é…ç½®
    enable_tls_processing: bool = True
    enable_cross_segment_detection: bool = True
    
    # TLSåè®®ç­–ç•¥é…ç½®  
    tls_20_strategy: str = "keep_all"  # ChangeCipherSpecå®Œå…¨ä¿ç•™
    tls_21_strategy: str = "keep_all"  # Alertå®Œå…¨ä¿ç•™
    tls_22_strategy: str = "keep_all"  # Handshakeå®Œå…¨ä¿ç•™
    tls_23_strategy: str = "mask_payload"  # ApplicationDataæ™ºèƒ½æ©ç 
    tls_24_strategy: str = "keep_all"  # Heartbeatå®Œå…¨ä¿ç•™
    tls_23_header_preserve_bytes: int = 5
    
    # æ€§èƒ½å’Œèµ„æºé…ç½®
    chunk_size: int = 1000
    max_memory_mb: int = 512
    enable_parallel_processing: bool = False
    temp_dir: Optional[str] = None
    cleanup_temp_files: bool = True
    
    # è°ƒè¯•å’Œè¯Šæ–­é…ç½®
    enable_detailed_logging: bool = False
    enable_performance_monitoring: bool = True
    enable_boundary_safety: bool = True
    
    # é™çº§æœºåˆ¶é…ç½®
    fallback_config: FallbackConfig = field(default_factory=FallbackConfig)
    
    # Phase 2, Day 13: å¢å¼ºé”™è¯¯å¤„ç†é…ç½®
    retry_config: RetryConfig = field(default_factory=RetryConfig)
    enable_error_analytics: bool = True
    error_report_detail_level: str = "detailed"  # basic, detailed, verbose


class ErrorTracker:
    """é”™è¯¯è·Ÿè¸ªå’Œåˆ†æå™¨"""
    
    def __init__(self):
        self.error_history: List[ErrorContext] = []
        self.error_patterns: Dict[str, int] = {}
        self.recovery_success_rate: Dict[ErrorCategory, float] = {}
        self.logger = get_logger('error_tracker')
    
    def record_error(self, error_context: ErrorContext):
        """è®°å½•é”™è¯¯"""
        self.error_history.append(error_context)
        
        # æ›´æ–°é”™è¯¯æ¨¡å¼ç»Ÿè®¡
        pattern_key = f"{error_context.category.value}:{error_context.error_code}"
        self.error_patterns[pattern_key] = self.error_patterns.get(pattern_key, 0) + 1
        
        self.logger.debug(f"è®°å½•é”™è¯¯: {error_context.category.value} - {error_context.message}")
    
    def analyze_error_patterns(self) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        if not self.error_history:
            return {"total_errors": 0, "patterns": {}}
            
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_stats = {}
        for error in self.error_history:
            category = error.category.value
            category_stats[category] = category_stats.get(category, 0) + 1
        
        # æŒ‰ä¸¥é‡æ€§ç»Ÿè®¡
        severity_stats = {}
        for error in self.error_history:
            severity = error.severity.value
            severity_stats[severity] = severity_stats.get(severity, 0) + 1
        
        # æœ€è¿‘é”™è¯¯è¶‹åŠ¿
        recent_errors = [e for e in self.error_history if time.time() - e.timestamp < 3600]  # æœ€è¿‘1å°æ—¶
        
        return {
            "total_errors": len(self.error_history),
            "recent_errors": len(recent_errors),
            "category_distribution": category_stats,
            "severity_distribution": severity_stats,
            "most_common_patterns": dict(sorted(self.error_patterns.items(), 
                                              key=lambda x: x[1], reverse=True)[:5]),
            "recovery_success_rate": self.recovery_success_rate.copy()
        }
    
    def suggest_mitigations(self, error_context: ErrorContext) -> List[str]:
        """åŸºäºé”™è¯¯å†å²å’Œæ¨¡å¼å»ºè®®ç¼“è§£æªæ–½"""
        suggestions = []
        
        # åŸºäºé”™è¯¯ç±»åˆ«çš„é€šç”¨å»ºè®®
        if error_context.category == ErrorCategory.DEPENDENCY_ERROR:
            suggestions.extend([
                "æ£€æŸ¥TSharkæ˜¯å¦æ­£ç¡®å®‰è£…",
                "éªŒè¯TSharkç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆæ¨è4.0+ï¼‰",
                "æ£€æŸ¥ç³»ç»ŸPATHç¯å¢ƒå˜é‡",
                "è€ƒè™‘ä½¿ç”¨é™çº§å¤„ç†æ¨¡å¼"
            ])
        elif error_context.category == ErrorCategory.MEMORY_ERROR:
            suggestions.extend([
                "å‡å°‘å¤„ç†æ‰¹æ¬¡å¤§å°",
                "å¯ç”¨ä¸´æ—¶æ–‡ä»¶æ¸…ç†",
                "æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å†…å­˜",
                "è€ƒè™‘åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶"
            ])
        elif error_context.category == ErrorCategory.TIMEOUT_ERROR:
            suggestions.extend([
                "å¢åŠ è¶…æ—¶æ—¶é—´è®¾ç½®",
                "æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "ä¼˜åŒ–å¤„ç†å‚æ•°",
                "ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨è®¾å¤‡"
            ])
        elif error_context.category == ErrorCategory.PROTOCOL_ERROR:
            suggestions.extend([
                "éªŒè¯è¾“å…¥æ–‡ä»¶æ ¼å¼",
                "æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸå",
                "å°è¯•ä½¿ç”¨ä¸åŒçš„åè®®è§£æå‚æ•°",
                "è€ƒè™‘é¢„å¤„ç†è¾“å…¥æ–‡ä»¶"
            ])
        
        # åŸºäºé”™è¯¯æ¨¡å¼çš„ç‰¹å®šå»ºè®®
        error_pattern = f"{error_context.category.value}:{error_context.error_code}"
        if self.error_patterns.get(error_pattern, 0) > 3:
            suggestions.append("æ­¤é”™è¯¯æ¨¡å¼é¢‘ç¹å‡ºç°ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–è¾“å…¥æ•°æ®è´¨é‡")
        
        return suggestions


class TSharkEnhancedMaskProcessor(BaseProcessor):
    """
    TSharkå¢å¼ºæ©ç å¤„ç†å™¨
    
    åŸºäºTSharkæ·±åº¦åè®®è§£æçš„ä¸‰é˜¶æ®µæ©ç å¤„ç†å™¨ï¼š
    1. TShark TLSåˆ†æï¼šæ·±åº¦åè®®è§£æï¼Œè¯†åˆ«è·¨TCPæ®µTLSæ¶ˆæ¯
    2. æ©ç è§„åˆ™ç”Ÿæˆï¼šå°†TLSåˆ†æç»“æœè½¬æ¢ä¸ºç²¾ç¡®æ©ç è§„åˆ™
    3. Scapyæ©ç åº”ç”¨ï¼šæ ¹æ®è§„åˆ™è¿›è¡Œå­—èŠ‚çº§ç²¾ç¡®æ©ç æ“ä½œ
    
    æ”¯æŒå®Œæ•´çš„TLSåè®®ç±»å‹å¤„ç†ï¼š
    - TLS-20 (ChangeCipherSpec): å®Œå…¨ä¿ç•™
    - TLS-21 (Alert): å®Œå…¨ä¿ç•™
    - TLS-22 (Handshake): å®Œå…¨ä¿ç•™  
    - TLS-23 (ApplicationData): æ™ºèƒ½æ©ç ï¼ˆä¿ç•™5å­—èŠ‚å¤´éƒ¨ï¼‰
    - TLS-24 (Heartbeat): å®Œå…¨ä¿ç•™
    
    æä¾›æ™ºèƒ½é™çº§æœºåˆ¶ï¼š
    - TSharkä¸å¯ç”¨æ—¶é™çº§åˆ°EnhancedTrimmer
    - åè®®è§£æå¤±è´¥æ—¶é™çº§åˆ°æ ‡å‡†MaskStage
    - å…¶ä»–é”™è¯¯æ—¶è¿›è¡Œé”™è¯¯æ¢å¤å’Œé‡è¯•
    
    Phase 2, Day 13 å¢å¼ºï¼š
    - è¯¦ç»†é”™è¯¯åˆ†ç±»å’Œä¸Šä¸‹æ–‡è®°å½•
    - æ™ºèƒ½é‡è¯•æœºåˆ¶å’ŒæŒ‡æ•°é€€é¿
    - é”™è¯¯æ¨¡å¼åˆ†æå’Œç¼“è§£å»ºè®®
    - å®Œæ•´çš„é”™è¯¯ç»Ÿè®¡å’ŒæŠ¥å‘Šç³»ç»Ÿ
    """
    
    def __init__(self, config: ProcessorConfig):
        super().__init__(config)
        self._logger = get_logger('tshark_enhanced_mask_processor')
        
        # å¢å¼ºé…ç½®ï¼ˆä»AppConfigåŠ è½½ï¼‰
        self.enhanced_config = self._load_enhanced_config()
        
        # æ ¸å¿ƒç»„ä»¶ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._tshark_analyzer: Optional[Any] = None
        self._rule_generator: Optional[Any] = None  
        self._scapy_applier: Optional[Any] = None
        
        # é™çº§å¤„ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._fallback_processors: Dict[FallbackMode, Any] = {}
        self._current_fallback_mode: Optional[FallbackMode] = None
        
        # Phase 2, Day 13: å¢å¼ºé”™è¯¯å¤„ç†ç³»ç»Ÿ
        self._error_tracker = ErrorTracker()
        self._retry_history: Dict[str, List[float]] = {}  # æ–‡ä»¶è·¯å¾„ -> é‡è¯•æ—¶é—´æˆ³åˆ—è¡¨
        
        # å¤„ç†ç»Ÿè®¡
        self._processing_stats = {
            'total_files_processed': 0,
            'successful_files': 0,
            'fallback_usage': {},
            'tls_records_processed': 0,
            'mask_rules_generated': 0,
            'packets_modified': 0,
            'stage_performance': {},
            'error_recovery_count': 0,
            # Phase 2, Day 13: å¢å¼ºç»Ÿè®¡
            'error_statistics': {},
            'retry_statistics': {},
            'recovery_success_rate': 0.0
        }
        
        # ä¸´æ—¶å·¥ä½œç›®å½•
        self._temp_dir: Optional[Path] = None
    
    def _create_error_context(self, category: ErrorCategory, severity: ErrorSeverity,
                            error_code: str, message: str, exception: Optional[Exception] = None,
                            file_context: Optional[str] = None, stage_context: Optional[str] = None) -> ErrorContext:
        """åˆ›å»ºè¯¦ç»†çš„é”™è¯¯ä¸Šä¸‹æ–‡"""
        context = ErrorContext(
            category=category,
            severity=severity,
            error_code=error_code,
            message=message,
            exception=exception,
            stack_trace=traceback.format_exc() if exception else None,
            file_context=file_context,
            stage_context=stage_context
        )
        
        # æ·»åŠ ç¼“è§£å»ºè®®
        context.mitigation_suggestions = self._error_tracker.suggest_mitigations(context)
        
        return context
    
    def _handle_error_with_context(self, error_context: ErrorContext) -> bool:
        """å¸¦ä¸Šä¸‹æ–‡çš„é”™è¯¯å¤„ç†ï¼Œè¿”å›æ˜¯å¦å¯ä»¥ç»§ç»­å¤„ç†"""
        # è®°å½•é”™è¯¯
        self._error_tracker.record_error(error_context)
        
        # æ ¹æ®é”™è¯¯ä¸¥é‡æ€§å†³å®šå¤„ç†ç­–ç•¥
        if error_context.severity == ErrorSeverity.CRITICAL:
            self._logger.critical(f"ä¸¥é‡é”™è¯¯: {error_context.message}")
            return False
        elif error_context.severity == ErrorSeverity.HIGH:
            self._logger.error(f"é«˜çº§é”™è¯¯: {error_context.message}")
            return self._attempt_error_recovery(error_context)
        elif error_context.severity == ErrorSeverity.MEDIUM:
            self._logger.warning(f"ä¸­çº§é”™è¯¯: {error_context.message}")
            return self._attempt_error_recovery(error_context)
        else:  # LOW
            self._logger.debug(f"ä½çº§é”™è¯¯: {error_context.message}")
            return True
    
    def _attempt_error_recovery(self, error_context: ErrorContext) -> bool:
        """å°è¯•é”™è¯¯æ¢å¤"""
        error_context.recovery_attempted = True
        
        # æ ¹æ®é”™è¯¯ç±»åˆ«å°è¯•ä¸åŒçš„æ¢å¤ç­–ç•¥
        if error_context.category == ErrorCategory.DEPENDENCY_ERROR:
            return self._recover_from_dependency_error(error_context)
        elif error_context.category == ErrorCategory.MEMORY_ERROR:
            return self._recover_from_memory_error(error_context)
        elif error_context.category == ErrorCategory.TIMEOUT_ERROR:
            return self._recover_from_timeout_error(error_context)
        elif error_context.category == ErrorCategory.PROTOCOL_ERROR:
            return self._recover_from_protocol_error(error_context)
        else:
            # é€šç”¨æ¢å¤ç­–ç•¥ï¼šå°è¯•é™çº§å¤„ç†
            return self._can_use_fallback()
    
    def _recover_from_dependency_error(self, error_context: ErrorContext) -> bool:
        """ä»ä¾èµ–é”™è¯¯ä¸­æ¢å¤"""
        self._logger.info("å°è¯•ä»ä¾èµ–é”™è¯¯ä¸­æ¢å¤ï¼Œæ£€æŸ¥é™çº§é€‰é¡¹...")
        return self._can_use_fallback()
    
    def _recover_from_memory_error(self, error_context: ErrorContext) -> bool:
        """ä»å†…å­˜é”™è¯¯ä¸­æ¢å¤"""
        self._logger.info("å°è¯•ä»å†…å­˜é”™è¯¯ä¸­æ¢å¤ï¼Œè°ƒæ•´å¤„ç†å‚æ•°...")
        
        # å‡å°‘å—å¤§å°
        if hasattr(self.enhanced_config, 'chunk_size') and self.enhanced_config.chunk_size > 100:
            self.enhanced_config.chunk_size = max(100, self.enhanced_config.chunk_size // 2)
            self._logger.info(f"è°ƒæ•´å—å¤§å°ä¸º: {self.enhanced_config.chunk_size}")
            return True
        
        return self._can_use_fallback()
    
    def _recover_from_timeout_error(self, error_context: ErrorContext) -> bool:
        """ä»è¶…æ—¶é”™è¯¯ä¸­æ¢å¤"""
        self._logger.info("å°è¯•ä»è¶…æ—¶é”™è¯¯ä¸­æ¢å¤ï¼Œè°ƒæ•´è¶…æ—¶å‚æ•°...")
        
        # å¢åŠ è¶…æ—¶æ—¶é—´
        if hasattr(self.enhanced_config.fallback_config, 'tshark_check_timeout'):
            self.enhanced_config.fallback_config.tshark_check_timeout *= 1.5
            self._logger.info(f"è°ƒæ•´è¶…æ—¶æ—¶é—´ä¸º: {self.enhanced_config.fallback_config.tshark_check_timeout}ç§’")
            return True
        
        return self._can_use_fallback()
    
    def _recover_from_protocol_error(self, error_context: ErrorContext) -> bool:
        """ä»åè®®é”™è¯¯ä¸­æ¢å¤"""
        self._logger.info("å°è¯•ä»åè®®é”™è¯¯ä¸­æ¢å¤ï¼Œä½¿ç”¨é™çº§å¤„ç†...")
        return self._can_use_fallback()
    
    def _can_use_fallback(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨é™çº§å¤„ç†"""
        return (self.enhanced_config.fallback_config.enable_fallback and 
                len(self._fallback_processors) > 0)
    
    def _should_retry(self, error_context: ErrorContext, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•å¤„ç†"""
        retry_config = self.enhanced_config.retry_config
        
        # æ£€æŸ¥é”™è¯¯ç±»åˆ«æ˜¯å¦æ”¯æŒé‡è¯•
        if error_context.category not in retry_config.retry_on_categories:
            return False
        
        # æ£€æŸ¥é‡è¯•æ¬¡æ•°é™åˆ¶
        if error_context.retry_count >= retry_config.max_retries:
            return False
        
        # æ£€æŸ¥æœ€è¿‘é‡è¯•é¢‘ç‡ï¼ˆé˜²æ­¢é‡è¯•é£æš´ï¼‰
        current_time = time.time()
        if file_path in self._retry_history:
            recent_retries = [t for t in self._retry_history[file_path] 
                            if current_time - t < 300]  # 5åˆ†é’Ÿå†…çš„é‡è¯•
            if len(recent_retries) >= retry_config.max_retries:
                return False
        
        return True
    
    def _calculate_retry_delay(self, retry_count: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        retry_config = self.enhanced_config.retry_config
        
        if retry_config.exponential_backoff:
            delay = retry_config.base_delay * (2 ** retry_count)
            return min(delay, retry_config.max_delay)
        else:
            return retry_config.base_delay
    
    def _execute_with_retry(self, func, *args, **kwargs):
        """å¸¦é‡è¯•æœºåˆ¶çš„å‡½æ•°æ‰§è¡Œ"""
        retry_config = self.enhanced_config.retry_config
        last_error = None
        
        for attempt in range(retry_config.max_retries + 1):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                last_error = e
                
                if attempt < retry_config.max_retries:
                    delay = self._calculate_retry_delay(attempt)
                    self._logger.warning(f"æ‰§è¡Œå¤±è´¥ï¼Œ{delay}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{retry_config.max_retries + 1}): {e}")
                    time.sleep(delay)
                else:
                    self._logger.error(f"é‡è¯•å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯
        raise last_error
    
    def _load_enhanced_config(self) -> TSharkEnhancedConfig:
        """ä»AppConfigåŠ è½½TSharkå¢å¼ºé…ç½®"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from ...config.settings import get_app_config
            
            app_config = get_app_config()
            enhanced_settings = app_config.tools.tshark_enhanced
            
            # åˆ›å»ºFallbackConfig
            fallback_config = FallbackConfig(
                enable_fallback=enhanced_settings.fallback_config.enable_fallback,
                max_retries=enhanced_settings.fallback_config.max_retries,
                retry_delay_seconds=enhanced_settings.fallback_config.retry_delay_seconds,
                tshark_check_timeout=enhanced_settings.fallback_config.tshark_check_timeout,
                fallback_on_tshark_unavailable=enhanced_settings.fallback_config.fallback_on_tshark_unavailable,
                fallback_on_parse_error=enhanced_settings.fallback_config.fallback_on_parse_error,
                fallback_on_other_errors=enhanced_settings.fallback_config.fallback_on_other_errors,
                preferred_fallback_order=[
                    FallbackMode(mode) for mode in enhanced_settings.fallback_config.preferred_fallback_order
                ]
            )
            
            # åˆ›å»ºTSharkEnhancedConfig
            enhanced_config = TSharkEnhancedConfig(
                # æ ¸å¿ƒåŠŸèƒ½é…ç½®
                enable_tls_processing=enhanced_settings.enable_tls_processing,
                enable_cross_segment_detection=enhanced_settings.enable_cross_segment_detection,
                enable_boundary_safety=enhanced_settings.enable_boundary_safety,
                
                # TLSåè®®ç±»å‹å¤„ç†é…ç½®
                tls_20_strategy=enhanced_settings.tls_20_strategy,
                tls_21_strategy=enhanced_settings.tls_21_strategy,
                tls_22_strategy=enhanced_settings.tls_22_strategy,
                tls_23_strategy=enhanced_settings.tls_23_strategy,
                tls_24_strategy=enhanced_settings.tls_24_strategy,
                tls_23_header_preserve_bytes=enhanced_settings.tls_23_header_preserve_bytes,
                
                # æ€§èƒ½é…ç½®
                temp_dir=enhanced_settings.temp_dir,
                cleanup_temp_files=enhanced_settings.cleanup_temp_files,
                enable_parallel_processing=enhanced_settings.enable_parallel_processing,
                chunk_size=enhanced_settings.chunk_size,
                
                # è°ƒè¯•é…ç½®
                enable_detailed_logging=enhanced_settings.enable_detailed_logging,
                enable_performance_monitoring=enhanced_settings.enable_performance_monitoring,
                
                # é™çº§æœºåˆ¶é…ç½®
                fallback_config=fallback_config
            )
            
            self._logger.info("TShark enhanced configuration loaded from AppConfig")
            self._logger.debug(f"TLS processing: {enhanced_config.enable_tls_processing}")
            self._logger.debug(f"Cross-segment detection: {enhanced_config.enable_cross_segment_detection}")
            self._logger.debug(f"Fallback mechanism: {enhanced_config.fallback_config.enable_fallback}")
            
            return enhanced_config
            
        except Exception as e:
            self._logger.warning(f"Failed to load configuration from AppConfig, using default configuration: {e}")
            return TSharkEnhancedConfig()  # å›é€€åˆ°é»˜è®¤é…ç½®
        
    def _initialize_impl(self):
        """åˆå§‹åŒ–TSharkå¢å¼ºæ©ç å¤„ç†å™¨ï¼ˆPhase 2, Day 13 å¢å¼ºç‰ˆï¼‰"""
        try:
            self._logger.info("Starting TShark enhanced mask processor initialization...")
            
            # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
            self._setup_temp_directory()
            
            # æ£€æŸ¥TSharkå¯ç”¨æ€§
            if not self._check_tshark_availability():
                error_context = self._create_error_context(
                    ErrorCategory.DEPENDENCY_ERROR,
                    ErrorSeverity.HIGH,
                    "TSHARK_UNAVAILABLE",
                    "TShark tool unavailable, cannot perform deep protocol analysis"
                )
                
                if self.enhanced_config.fallback_config.fallback_on_tshark_unavailable:
                    self._logger.warning("TShark unavailable, preparing to fallback to backup processor")
                    if self._handle_error_with_context(error_context):
                        return self._initialize_fallback_processors()
                else:
                    self._handle_error_with_context(error_context)
                    raise RuntimeError("TShark unavailable and fallback functionality is disabled")
            
            # åˆå§‹åŒ–ä¸‰é˜¶æ®µå¤„ç†ç»„ä»¶
            self._initialize_core_components()
            
            # é¢„åˆå§‹åŒ–é™çº§å¤„ç†å™¨ï¼ˆä¿é™©æªæ–½ï¼‰
            if self.enhanced_config.fallback_config.enable_fallback:
                self._initialize_fallback_processors()
            
            self._logger.info("TShark enhanced mask processor initialization successful")
            self._logger.info(f"Working directory: {self._temp_dir}")
            self._logger.info(f"TLS processing configuration: 20-24 protocol type support")
            self._logger.info(f"Fallback mechanism: {'Enabled' if self.enhanced_config.fallback_config.enable_fallback else 'Disabled'}")
            self._logger.info(f"Error analysis: {'Enabled' if self.enhanced_config.enable_error_analytics else 'Disabled'}")
            
        except Exception as e:
            error_context = self._create_error_context(
                ErrorCategory.INITIALIZATION_ERROR,
                ErrorSeverity.HIGH,
                "INIT_FAILED",
                f"TShark enhanced mask processor initialization failed: {e}",
                exception=e
            )
            
            # å°è¯•é™çº§åˆå§‹åŒ–
            if self.enhanced_config.fallback_config.enable_fallback and self._handle_error_with_context(error_context):
                self._logger.info("Attempting fallback initialization...")
                return self._initialize_fallback_processors()
            else:
                raise
                
    def _setup_temp_directory(self):
        """è®¾ç½®ä¸´æ—¶å·¥ä½œç›®å½•"""
        if self.enhanced_config.temp_dir:
            self._temp_dir = Path(self.enhanced_config.temp_dir)
        else:
            self._temp_dir = Path(tempfile.mkdtemp(prefix="tshark_enhanced_mask_"))
        
        self._temp_dir.mkdir(parents=True, exist_ok=True)
        self._logger.debug(f"Temporary working directory created: {self._temp_dir}")
        
    def _check_tshark_availability(self) -> bool:
        """æ£€æŸ¥TSharkå·¥å…·çš„å¯ç”¨æ€§"""
        try:
            import subprocess
            import signal
            
            # å»¶è¿Ÿå¯¼å…¥TSharkè·¯å¾„é…ç½®
            from ...config.defaults import get_tshark_paths
            
            tshark_paths = get_tshark_paths()
            timeout = self.enhanced_config.fallback_config.tshark_check_timeout
            
            for tshark_path in tshark_paths:
                try:
                    # ä½¿ç”¨è¶…æ—¶æ£€æŸ¥TSharkç‰ˆæœ¬
                    result = subprocess.run(
                        [tshark_path, '--version'],
                        capture_output=True,
                        text=True,
                        timeout=timeout
                    )
                    
                    if result.returncode == 0 and 'TShark' in result.stdout:
                        self._logger.info(f"TShark available: {tshark_path}")
                        version_line = result.stdout.split('\n')[0]
                        self._logger.info(f"Version information: {version_line}")
                        return True
                        
                except (subprocess.TimeoutExpired, FileNotFoundError, OSError) as e:
                    self._logger.debug(f"TShark path check failed {tshark_path}: {e}")
                    continue
            
            self._logger.warning("All TShark path checks failed")
            return False
            
        except Exception as e:
            self._logger.error(f"TShark availability check exception: {e}")
            return False
            
    def _initialize_core_components(self):
        """åˆå§‹åŒ–ä¸‰é˜¶æ®µæ ¸å¿ƒç»„ä»¶"""
        try:
            # Stage 1: TShark TLSåˆ†æå™¨
            from .tshark_tls_analyzer import TSharkTLSAnalyzer
            self._tshark_analyzer = TSharkTLSAnalyzer(self._create_analyzer_config())
            # åˆå§‹åŒ– TSharkTLSAnalyzerï¼Œç¡®ä¿ TShark å¯ç”¨
            if not self._tshark_analyzer.initialize():
                raise RuntimeError("TShark TLS analyzer initialization failed")
            
            # Stage 2: TLSæ©ç è§„åˆ™ç”Ÿæˆå™¨  
            from .tls_mask_rule_generator import TLSMaskRuleGenerator
            self._rule_generator = TLSMaskRuleGenerator(self._create_generator_config())
            
            # Stage 3: Scapyæ©ç åº”ç”¨å™¨
            from .scapy_mask_applier import ScapyMaskApplier  
            self._scapy_applier = ScapyMaskApplier(self._create_applier_config())
            
            self._logger.info("Three-stage core components initialization successful")
            
        except ImportError as e:
            self._logger.error(f"Core component import failed: {e}")
            raise RuntimeError(f"Core components unavailable: {e}")
        except Exception as e:
            self._logger.error(f"Core component initialization failed: {e}")
            raise
            
    def _initialize_fallback_processors(self) -> bool:
        """åˆå§‹åŒ–é™çº§å¤„ç†å™¨"""
        fallback_initialized = False
        
        for fallback_mode in self.enhanced_config.fallback_config.preferred_fallback_order:
            try:
                if fallback_mode == FallbackMode.ENHANCED_TRIMMER:
                    self._initialize_enhanced_trimmer_fallback()
                    fallback_initialized = True
                    self._logger.info("EnhancedTrimmer fallback processor initialization successful")
                    
                elif fallback_mode == FallbackMode.MASK_STAGE:
                    self._initialize_mask_stage_fallback()
                    fallback_initialized = True 
                    self._logger.info("MaskStage fallback processor initialization successful")
                    
            except Exception as e:
                self._logger.warning(f"Fallback processor {fallback_mode.value} initialization failed: {e}")
                continue
        
        if not fallback_initialized:
            self._logger.error("All fallback processor initialization failed")
            return False
            
        return True
        
    def _initialize_enhanced_trimmer_fallback(self):
        """åˆå§‹åŒ–EnhancedTrimmeré™çº§å¤„ç†å™¨"""
        try:
            from .enhanced_trimmer import EnhancedTrimmer
            
            fallback_config = ProcessorConfig(
                enabled=True,
                name="enhanced_trimmer_fallback",
                priority=1
            )
            
            trimmer = EnhancedTrimmer(fallback_config)
            if trimmer.initialize():
                self._fallback_processors[FallbackMode.ENHANCED_TRIMMER] = trimmer
            else:
                raise RuntimeError("EnhancedTrimmer initialization returned False")
                
        except Exception as e:
            self._logger.warning(f"EnhancedTrimmer fallback processor initialization failed: {e}")
            raise
            
    def _initialize_mask_stage_fallback(self):
        """åˆå§‹åŒ–MaskStageé™çº§å¤„ç†å™¨"""
        try:
            from ..pipeline.stages.mask_payload.stage import MaskStage
            
            # åˆ›å»ºåŸºç¡€æ¨¡å¼çš„MaskStageé…ç½®
            mask_stage_config = {
                "mode": "basic",  # ä½¿ç”¨åŸºç¡€æ¨¡å¼
                "preserve_ratio": 0.3,
                "min_preserve_bytes": 100
            }
            
            mask_stage = MaskStage(mask_stage_config)
            mask_stage.initialize()
            
            self._fallback_processors[FallbackMode.MASK_STAGE] = mask_stage
            
        except Exception as e:
            self._logger.warning(f"MaskStageé™çº§å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
            
    def _create_analyzer_config(self) -> Dict[str, Any]:
        """åˆ›å»ºTSharkåˆ†æå™¨é…ç½®"""
        return {
            'enable_tls_processing': self.enhanced_config.enable_tls_processing,
            'enable_cross_segment_detection': self.enhanced_config.enable_cross_segment_detection,
            'enable_detailed_logging': self.enhanced_config.enable_detailed_logging,
            'temp_dir': str(self._temp_dir),
            'chunk_size': self.enhanced_config.chunk_size
        }
        
    def _create_generator_config(self) -> Dict[str, Any]:
        """åˆ›å»ºæ©ç è§„åˆ™ç”Ÿæˆå™¨é…ç½®"""
        return {
            'tls_20_strategy': self.enhanced_config.tls_20_strategy,
            'tls_21_strategy': self.enhanced_config.tls_21_strategy,
            'tls_22_strategy': self.enhanced_config.tls_22_strategy,
            'tls_23_strategy': self.enhanced_config.tls_23_strategy,
            'tls_24_strategy': self.enhanced_config.tls_24_strategy,
            'tls_23_header_preserve_bytes': self.enhanced_config.tls_23_header_preserve_bytes,
            'enable_boundary_safety': self.enhanced_config.enable_boundary_safety,
            'enable_detailed_logging': self.enhanced_config.enable_detailed_logging
        }
        
    def _create_applier_config(self) -> Dict[str, Any]:
        """åˆ›å»ºScapyæ©ç åº”ç”¨å™¨é…ç½®"""
        return {
            'enable_boundary_safety': self.enhanced_config.enable_boundary_safety,
            'enable_detailed_logging': self.enhanced_config.enable_detailed_logging,
            'enable_checksum_recalculation': True,
            'enable_error_recovery': True
        }
        
    def process_file(self, input_path: str, output_path: str) -> ProcessorResult:
        """å¤„ç†æ–‡ä»¶çš„æ ¸å¿ƒæ–¹æ³• - å¼ºåˆ¶åè®®é€‚é…æ¨¡å¼ç‰ˆæœ¬ï¼ˆç¦ç”¨æ‰€æœ‰é™çº§æœºåˆ¶ï¼‰"""
        start_time = time.time()
        
        # è¾“å…¥éªŒè¯
        self.validate_inputs(input_path, output_path)
        
        # å¼ºåˆ¶æ£€æŸ¥æ ¸å¿ƒç»„ä»¶å¯ç”¨æ€§
        if not self._has_core_components():
            raise RuntimeError(
                "æ ¸å¿ƒç»„ä»¶ä¸å¯ç”¨ï¼å¼ºåˆ¶åè®®é€‚é…æ¨¡å¼è¦æ±‚æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å¿…é¡»å¯ç”¨ã€‚"
                f"TSharkåˆ†æå™¨: {'âœ“' if self._tshark_analyzer else 'âœ—'}, "
                f"è§„åˆ™ç”Ÿæˆå™¨: {'âœ“' if self._rule_generator else 'âœ—'}, "
                f"Scapyåº”ç”¨å™¨: {'âœ“' if self._scapy_applier else 'âœ—'}"
            )
        
        # å¼ºåˆ¶ä½¿ç”¨åè®®é€‚é…æ¨¡å¼ï¼Œä¸æ•è·å¼‚å¸¸ï¼Œè®©æ‰€æœ‰é”™è¯¯ç›´æ¥æŠ›å‡º
        self._logger.info("ğŸš€ [Forced Protocol Adapter Mode] Starting three-stage processing pipeline")
        
        result = self._process_with_core_pipeline(input_path, output_path)
        
        if result.success:
            self._update_success_stats(result, time.time() - start_time)
            self._logger.info("ğŸš€ [Forced Protocol Adapter Mode] Processing completed successfully")
            return result
        else:
            raise RuntimeError(f"åè®®é€‚é…æ¨¡å¼å¤„ç†å¤±è´¥: {result.error}")
    
    def _process_with_core_pipeline_safe(self, input_path: str, output_path: str) -> ProcessorResult:
        """å®‰å…¨çš„æ ¸å¿ƒå¤„ç†æµç¨‹ï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯å¤„ç†"""
        try:
            return self._process_with_core_pipeline(input_path, output_path)
        except MemoryError as e:
            error_context = self._create_error_context(
                ErrorCategory.MEMORY_ERROR,
                ErrorSeverity.HIGH,
                "MEMORY_EXHAUSTED",
                f"å†…å­˜ä¸è¶³: {e}",
                exception=e,
                file_context=input_path,
                stage_context="core_pipeline"
            )
            self._handle_error_with_context(error_context)
            raise
        except TimeoutError as e:
            error_context = self._create_error_context(
                ErrorCategory.TIMEOUT_ERROR,
                ErrorSeverity.MEDIUM,
                "PROCESSING_TIMEOUT",
                f"å¤„ç†è¶…æ—¶: {e}",
                exception=e,
                file_context=input_path,
                stage_context="core_pipeline"
            )
            self._handle_error_with_context(error_context)
            raise
        except FileNotFoundError as e:
            error_context = self._create_error_context(
                ErrorCategory.IO_ERROR,
                ErrorSeverity.HIGH,
                "FILE_NOT_FOUND",
                f"æ–‡ä»¶ä¸å­˜åœ¨: {e}",
                exception=e,
                file_context=input_path,
                stage_context="core_pipeline"
            )
            self._handle_error_with_context(error_context)
            raise
        except Exception as e:
            error_context = self._create_error_context(
                ErrorCategory.PROCESSING_ERROR,
                ErrorSeverity.MEDIUM,
                "PIPELINE_ERROR",
                f"å¤„ç†æµç¨‹é”™è¯¯: {e}",
                exception=e,
                file_context=input_path,
                stage_context="core_pipeline"
            )
            self._handle_error_with_context(error_context)
            raise
                
    def _has_core_components(self) -> bool:
        """æ£€æŸ¥æ ¸å¿ƒç»„ä»¶æ˜¯å¦å¯ç”¨"""
        return (self._tshark_analyzer is not None and 
                self._rule_generator is not None and 
                self._scapy_applier is not None)
                
    def _process_with_core_pipeline(self, input_path: str, output_path: str) -> ProcessorResult:
        """ä½¿ç”¨ä¸‰é˜¶æ®µæ ¸å¿ƒæµç¨‹å¤„ç†æ–‡ä»¶ - å¼ºåˆ¶åè®®é€‚é…æ¨¡å¼ç‰ˆæœ¬"""
        # è½¬æ¢è¾“å…¥è¾“å‡ºè·¯å¾„ä¸º Path å¯¹è±¡ï¼Œé¿å…å­—ç¬¦ä¸²è°ƒç”¨ .exists() å‡ºé”™
        input_path = Path(input_path)
        output_path = Path(output_path)
        
        self._logger.info(f"ğŸš€ [Forced Protocol Adapter Mode] Starting three-stage processing: {input_path}")
        
        # Stage 1: TShark TLSåˆ†æ - ä¸æ•è·å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
        stage1_start = time.time()
        self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Processing] Starting Stage 1: TShark TLS Analysis")
        tls_records = self._tshark_analyzer.analyze_file(input_path)
        stage1_duration = time.time() - stage1_start
        
        if not tls_records:
            self._logger.warning("TShark analysis found no TLS records")
        else:
            # ç»Ÿè®¡TLSè®°å½•ç±»å‹å’Œè·¨åŒ…æƒ…å†µ
            tls_23_records = [r for r in tls_records if r.content_type == 23]
            cross_packet_records = [r for r in tls_records if len(r.spans_packets) > 1]
            tls_23_cross_packet = [r for r in tls_23_records if len(r.spans_packets) > 1]
            
            self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Statistics] TLS record analysis results:")
            self._logger.info(f"ğŸš€   Total TLS records: {len(tls_records)}")
            self._logger.info(f"ğŸš€   TLS-23 records: {len(tls_23_records)}")
            self._logger.info(f"ğŸš€   Cross-packet records: {len(cross_packet_records)}")
            self._logger.info(f"ğŸš€   TLS-23 cross-packet records: {len(tls_23_cross_packet)}")
            
        self._logger.info(f"Stage 1 completed: Found {len(tls_records)} TLS records, took {stage1_duration:.2f} seconds")
        
        # Stage 2: ç”Ÿæˆæ©ç è§„åˆ™ - ä¸æ•è·å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
        stage2_start = time.time()
        self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Processing] Starting Stage 2: Mask Rule Generation")
        mask_rules = self._rule_generator.generate_rules(tls_records)
        stage2_duration = time.time() - stage2_start
        
        # ç»Ÿè®¡æ©ç è§„åˆ™
        tls_23_rules = [r for r in mask_rules if r.tls_record_type == 23]
        mask_payload_rules = [r for r in mask_rules if r.action.value == "mask_payload"]
        segment_rules = [r for r in mask_rules if "åˆ†æ®µæ©ç " in r.reason]
        
        self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Statistics] Mask rule generation results:")
        self._logger.info(f"ğŸš€   Total mask rules: {len(mask_rules)}")
        self._logger.info(f"ğŸš€   TLS-23 rules: {len(tls_23_rules)}")
        self._logger.info(f"ğŸš€   Mask payload rules: {len(mask_payload_rules)}")
        self._logger.info(f"ğŸš€   Segment mask rules: {len(segment_rules)}")
        
        self._logger.info(f"Stage 2 completed: Generated {len(mask_rules)} mask rules, took {stage2_duration:.2f} seconds")
        
        # Stage 3: Scapyåº”ç”¨æ©ç  - ä¸æ•è·å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
        stage3_start = time.time()
        self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Processing] Starting Stage 3: Scapy Mask Application")
        apply_result = self._scapy_applier.apply_masks(input_path, output_path, mask_rules)
        stage3_duration = time.time() - stage3_start
        
        self._logger.info(f"ğŸš€ [TLS-23 Cross-Packet Statistics] Mask application results:")
        self._logger.info(f"ğŸš€   Packets processed: {apply_result.get('packets_processed', 0)}")
        self._logger.info(f"ğŸš€   Packets modified: {apply_result.get('packets_modified', 0)}")
        self._logger.info(f"ğŸš€   Masked bytes: {apply_result.get('masked_bytes', 0)}")
        
        self._logger.info(f"Stage 3 completed: Processing finished, took {stage3_duration:.2f} seconds")
        
        # æ±‡æ€»ç»“æœ
        total_duration = stage1_duration + stage2_duration + stage3_duration
        
        return ProcessorResult(
            success=True,
            stats={
                'tls_records_found': len(tls_records),
                'mask_rules_generated': len(mask_rules),
                'packets_processed': apply_result.get('packets_processed', 0),
                'packets_modified': apply_result.get('packets_modified', 0),
                'processing_mode': 'tshark_enhanced_forced',  # æ ‡è®°ä¸ºå¼ºåˆ¶åè®®é€‚é…æ¨¡å¼
                'stage_performance': {
                    'stage1_tshark_analysis': stage1_duration,
                    'stage2_rule_generation': stage2_duration,  
                    'stage3_scapy_application': stage3_duration,
                    'total_duration': total_duration
                }
            }
        )
            
    def _process_with_fallback(self, input_path: str, output_path: str, start_time: float, 
                              error_context: Optional[str] = None) -> ProcessorResult:
        """ä½¿ç”¨é™çº§æœºåˆ¶å¤„ç†æ–‡ä»¶"""
        
        # ç¡®å®šé™çº§ç­–ç•¥
        fallback_mode = self._determine_fallback_mode(error_context)
        
        # å°è¯•é™çº§å¤„ç†
        for mode in self.enhanced_config.fallback_config.preferred_fallback_order:
            if mode in self._fallback_processors:
                try:
                    self._logger.info(f"Using fallback processor: {mode.value}")
                    result = self._execute_fallback_processor(mode, input_path, output_path)
                    
                    if result.success:
                        duration = time.time() - start_time
                        self._update_fallback_stats(mode, result, duration)
                        
                        # åœ¨ç»“æœä¸­æ ‡è®°é™çº§æ¨¡å¼
                        if result.stats:
                            result.stats['processing_mode'] = f'fallback_{mode.value}'
                            result.stats['fallback_reason'] = error_context or 'primary_pipeline_failed'
                        
                        return result
                        
                except Exception as e:
                    self._logger.warning(f"Fallback processor {mode.value} execution failed: {e}")
                    continue
                    
        # æ‰€æœ‰é™çº§å¤„ç†å™¨éƒ½å¤±è´¥
        return ProcessorResult(
            success=False,
            error=f"Primary processing pipeline and all fallback processors failed. Original error: {error_context}"
        )
        
    def _determine_fallback_mode(self, error_context: Optional[str]) -> FallbackMode:
        """æ ¹æ®é”™è¯¯ä¸Šä¸‹æ–‡ç¡®å®šé™çº§æ¨¡å¼"""
        if not error_context:
            return FallbackMode.ENHANCED_TRIMMER
            
        error_lower = error_context.lower()
        
        if 'tshark' in error_lower or 'unavailable' in error_lower:
            return FallbackMode.ENHANCED_TRIMMER
        elif 'protocol' in error_lower:
            return FallbackMode.MASK_STAGE  
        else:
            return FallbackMode.ENHANCED_TRIMMER
            
    def _execute_fallback_processor(self, mode: FallbackMode, input_path: str, output_path: str) -> ProcessorResult:
        """æ‰§è¡ŒæŒ‡å®šçš„é™çº§å¤„ç†å™¨"""
        processor = self._fallback_processors[mode]
        
        if mode == FallbackMode.ENHANCED_TRIMMER:
            # EnhancedTrimmerä½¿ç”¨BaseProcessoræ¥å£
            return processor.process_file(input_path, output_path)
            
        elif mode == FallbackMode.MASK_STAGE:
            # MaskStageä½¿ç”¨StageBaseæ¥å£ï¼Œéœ€è¦é€‚é…
            result = processor.process_file(input_path, output_path)
            
            # å°†StageStatsè½¬æ¢ä¸ºProcessorResult
            if hasattr(result, 'packets_processed'):
                return ProcessorResult(
                    success=True,
                    stats={
                        'packets_processed': getattr(result, 'packets_processed', 0),
                        'packets_modified': getattr(result, 'packets_modified', 0),
                        'duration_ms': getattr(result, 'duration_ms', 0)
                    }
                )
            else:
                return ProcessorResult(success=False, error="MaskStage processing result format exception")
                
        else:
            raise ValueError(f"Unsupported fallback mode: {mode}")
            
    def _update_success_stats(self, result: ProcessorResult, duration: float):
        """æ›´æ–°æˆåŠŸå¤„ç†ç»Ÿè®¡"""
        self._processing_stats['total_files_processed'] += 1
        self._processing_stats['successful_files'] += 1
        
        if result.stats:
            self._processing_stats['tls_records_processed'] += result.stats.get('tls_records_found', 0)
            self._processing_stats['mask_rules_generated'] += result.stats.get('mask_rules_generated', 0)
            self._processing_stats['packets_modified'] += result.stats.get('packets_modified', 0)
            
    def _update_fallback_stats(self, mode: FallbackMode, result: ProcessorResult, duration: float):
        """æ›´æ–°é™çº§å¤„ç†ç»Ÿè®¡"""
        self._processing_stats['total_files_processed'] += 1
        
        mode_key = mode.value
        if mode_key not in self._processing_stats['fallback_usage']:
            self._processing_stats['fallback_usage'][mode_key] = 0
        self._processing_stats['fallback_usage'][mode_key] += 1
        
        if result.success:
            self._processing_stats['successful_files'] += 1
            
    def get_display_name(self) -> str:
        """è·å–ç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºåç§°"""
        return "TShark Enhanced Mask Processor"
        
    def get_description(self) -> str:
        """è·å–å¤„ç†å™¨æè¿°"""
        return ("Enhanced mask processor based on TShark deep protocol analysis, "
                "supporting intelligent classification processing for TLS 20-24 protocol types, "
                "including complete fallback mechanisms to ensure system robustness")
                
    def get_enhanced_stats(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats().copy()
        stats.update(self._processing_stats)
        
        # æ·»åŠ é™çº§ä½¿ç”¨ç‡ç»Ÿè®¡
        total_files = self._processing_stats['total_files_processed']
        if total_files > 0:
            fallback_total = sum(self._processing_stats['fallback_usage'].values())
            stats['primary_success_rate'] = (total_files - fallback_total) / total_files
            stats['fallback_usage_rate'] = fallback_total / total_files
        else:
            stats['primary_success_rate'] = 0.0
            stats['fallback_usage_rate'] = 0.0
            
        return stats
        
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if (self._temp_dir and 
                self._temp_dir.exists() and 
                self.enhanced_config.cleanup_temp_files):
                shutil.rmtree(self._temp_dir, ignore_errors=True)
                self._logger.debug(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {self._temp_dir}")
                self._temp_dir = None  # é‡è¦ï¼šæ¸…ç†åè®¾ç½®ä¸ºNone
                
            # æ¸…ç†é™çº§å¤„ç†å™¨
            for processor in self._fallback_processors.values():
                if hasattr(processor, 'cleanup'):
                    processor.cleanup()
                    
        except Exception as e:
            self._logger.warning(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")
            
    def _process_with_fallback_enhanced(self, input_path: str, output_path: str, start_time: float, 
                                      error_context: Optional[str] = None) -> ProcessorResult:
        """ä½¿ç”¨å¢å¼ºé™çº§æœºåˆ¶å¤„ç†æ–‡ä»¶ï¼ˆPhase 2, Day 13 å¢å¼ºç‰ˆï¼‰"""
        
        # è®°å½•é™çº§å°è¯•
        if input_path not in self._retry_history:
            self._retry_history[input_path] = []
        self._retry_history[input_path].append(time.time())
        
        # ç¡®å®šé™çº§ç­–ç•¥
        fallback_mode = self._determine_fallback_mode(error_context)
        
        # å°è¯•é™çº§å¤„ç†
        for mode in self.enhanced_config.fallback_config.preferred_fallback_order:
            if mode in self._fallback_processors:
                try:
                    self._logger.info(f"ä½¿ç”¨é™çº§å¤„ç†å™¨: {mode.value}")
                    
                    # ä½¿ç”¨é‡è¯•æœºåˆ¶æ‰§è¡Œé™çº§å¤„ç†å™¨
                    result = self._execute_with_retry(
                        self._execute_fallback_processor_safe,
                        mode, input_path, output_path
                    )
                    
                    if result.success:
                        duration = time.time() - start_time
                        self._update_fallback_stats(mode, result, duration)
                        
                        # åœ¨ç»“æœä¸­æ ‡è®°é™çº§æ¨¡å¼
                        if result.stats:
                            result.stats['processing_mode'] = f'fallback_{mode.value}'
                            result.stats['fallback_reason'] = error_context or 'primary_pipeline_failed'
                            result.stats['fallback_duration'] = duration
                        
                        # è®°å½•æˆåŠŸæ¢å¤
                        self._processing_stats['error_recovery_count'] += 1
                        return result
                        
                except Exception as e:
                    fallback_error_context = self._create_error_context(
                        ErrorCategory.PROCESSING_ERROR,
                        ErrorSeverity.MEDIUM,
                        f"FALLBACK_{mode.value.upper()}_FAILED",
                        f"é™çº§å¤„ç†å™¨{mode.value}æ‰§è¡Œå¤±è´¥: {e}",
                        exception=e,
                        file_context=input_path,
                        stage_context=f"fallback_{mode.value}"
                    )
                    self._handle_error_with_context(fallback_error_context)
                    continue
                    
        # æ‰€æœ‰é™çº§å¤„ç†å™¨éƒ½å¤±è´¥
        final_error_context = self._create_error_context(
            ErrorCategory.PROCESSING_ERROR,
            ErrorSeverity.CRITICAL,
            "ALL_FALLBACKS_FAILED",
            f"ä¸»è¦å¤„ç†æµç¨‹å’Œæ‰€æœ‰é™çº§å¤„ç†å™¨éƒ½å¤±è´¥ã€‚åŸå§‹é”™è¯¯: {error_context}",
            file_context=input_path
        )
        self._handle_error_with_context(final_error_context)
        
        return ProcessorResult(
            success=False,
            error=f"ä¸»è¦å¤„ç†æµç¨‹å’Œæ‰€æœ‰é™çº§å¤„ç†å™¨éƒ½å¤±è´¥ã€‚åŸå§‹é”™è¯¯: {error_context}"
        )
    
    def _execute_fallback_processor_safe(self, mode: FallbackMode, input_path: str, output_path: str) -> ProcessorResult:
        """å®‰å…¨çš„é™çº§å¤„ç†å™¨æ‰§è¡Œï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯å¤„ç†"""
        try:
            return self._execute_fallback_processor(mode, input_path, output_path)
        except Exception as e:
            error_context = self._create_error_context(
                ErrorCategory.PROCESSING_ERROR,
                ErrorSeverity.MEDIUM,
                f"FALLBACK_{mode.value.upper()}_ERROR",
                f"é™çº§å¤„ç†å™¨{mode.value}æ‰§è¡Œå¼‚å¸¸: {e}",
                exception=e,
                file_context=input_path,
                stage_context=f"fallback_{mode.value}"
            )
            self._handle_error_with_context(error_context)
            raise
    
    def get_error_report(self, detail_level: str = None) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çš„é”™è¯¯æŠ¥å‘Šï¼ˆPhase 2, Day 13 æ–°å¢ï¼‰"""
        if detail_level is None:
            detail_level = self.enhanced_config.error_report_detail_level
        
        error_analysis = self._error_tracker.analyze_error_patterns()
        
        report = {
            "processor_info": {
                "name": self.get_display_name(),
                "version": "1.0.0 (Phase 2, Day 13)",
                "error_analytics_enabled": self.enhanced_config.enable_error_analytics
            },
            "error_summary": error_analysis,
            "processing_stats": self._processing_stats.copy(),
            "configuration": {
                "retry_config": {
                    "max_retries": self.enhanced_config.retry_config.max_retries,
                    "base_delay": self.enhanced_config.retry_config.base_delay,
                    "exponential_backoff": self.enhanced_config.retry_config.exponential_backoff
                },
                "fallback_enabled": self.enhanced_config.fallback_config.enable_fallback,
                "fallback_order": [mode.value for mode in self.enhanced_config.fallback_config.preferred_fallback_order]
            }
        }
        
        if detail_level in ["detailed", "verbose"]:
            # æ·»åŠ è¯¦ç»†é”™è¯¯å†å²
            report["error_history"] = []
            for error in self._error_tracker.error_history[-10:]:  # æœ€è¿‘10ä¸ªé”™è¯¯
                error_detail = {
                    "timestamp": error.timestamp,
                    "category": error.category.value,
                    "severity": error.severity.value,
                    "error_code": error.error_code,
                    "message": error.message,
                    "file_context": error.file_context,
                    "stage_context": error.stage_context,
                    "retry_count": error.retry_count,
                    "recovery_attempted": error.recovery_attempted,
                    "mitigation_suggestions": error.mitigation_suggestions[:3]  # å‰3ä¸ªå»ºè®®
                }
                
                if detail_level == "verbose" and error.exception:
                    error_detail["exception_type"] = type(error.exception).__name__
                    if error.stack_trace:
                        error_detail["stack_trace"] = error.stack_trace.split('\n')[:5]  # å‰5è¡Œå †æ ˆ
                
                report["error_history"].append(error_detail)
            
            # æ·»åŠ é‡è¯•å†å²ç»Ÿè®¡
            report["retry_history"] = {}
            current_time = time.time()
            for file_path, retry_times in self._retry_history.items():
                recent_retries = [t for t in retry_times if current_time - t < 3600]
                if recent_retries:
                    report["retry_history"][file_path] = {
                        "total_retries": len(retry_times),
                        "recent_retries": len(recent_retries),
                        "last_retry": max(retry_times) if retry_times else None
                    }
        
        if detail_level == "verbose":
            # æ·»åŠ ç³»ç»Ÿè¯Šæ–­ä¿¡æ¯
            report["system_diagnostics"] = {
                "temp_dir": str(self._temp_dir) if self._temp_dir else None,
                "temp_dir_exists": self._temp_dir.exists() if self._temp_dir else False,
                "fallback_processors_available": list(self._fallback_processors.keys()),
                "core_components_available": self._has_core_components(),
                "current_fallback_mode": self._current_fallback_mode.value if self._current_fallback_mode else None
            }
        
        return report
    
    def generate_mitigation_recommendations(self) -> List[str]:
        """åŸºäºé”™è¯¯å†å²ç”Ÿæˆç¼“è§£å»ºè®®ï¼ˆPhase 2, Day 13 æ–°å¢ï¼‰"""
        error_analysis = self._error_tracker.analyze_error_patterns()
        recommendations = []
        
        # åŸºäºé”™è¯¯æ¨¡å¼çš„å»ºè®®
        if error_analysis.get("total_errors", 0) > 0:
            category_stats = error_analysis.get("category_distribution", {})
            
            # ä¾èµ–é”™è¯¯å»ºè®®
            if category_stats.get("dependency_error", 0) > 0:
                recommendations.extend([
                    "éªŒè¯TSharkå®‰è£…å’Œç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆæ¨è4.0+ï¼‰",
                    "æ£€æŸ¥ç³»ç»ŸPATHç¯å¢ƒå˜é‡åŒ…å«TSharkè·¯å¾„",
                    "è€ƒè™‘å¯ç”¨é™çº§å¤„ç†æ¨¡å¼ä»¥æé«˜ç³»ç»Ÿå¥å£®æ€§"
                ])
            
            # å†…å­˜é”™è¯¯å»ºè®®
            if category_stats.get("memory_error", 0) > 0:
                recommendations.extend([
                    f"å‡å°‘å¤„ç†æ‰¹æ¬¡å¤§å°ï¼ˆå½“å‰: {self.enhanced_config.chunk_size}ï¼‰",
                    "å¯ç”¨ä¸´æ—¶æ–‡ä»¶è‡ªåŠ¨æ¸…ç†åŠŸèƒ½",
                    "è€ƒè™‘åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶ä»¥å‡å°‘å†…å­˜ä½¿ç”¨"
                ])
            
            # è¶…æ—¶é”™è¯¯å»ºè®®
            if category_stats.get("timeout_error", 0) > 0:
                recommendations.extend([
                    f"å¢åŠ è¶…æ—¶æ—¶é—´è®¾ç½®ï¼ˆå½“å‰: {self.enhanced_config.fallback_config.tshark_check_timeout}sï¼‰",
                    "ä¼˜åŒ–å¤„ç†å‚æ•°ä»¥æå‡æ€§èƒ½",
                    "æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½å’Œå¯ç”¨èµ„æº"
                ])
            
            # åè®®é”™è¯¯å»ºè®®
            if category_stats.get("protocol_error", 0) > 0:
                recommendations.extend([
                    "éªŒè¯è¾“å…¥æ–‡ä»¶æ ¼å¼å’Œå®Œæ•´æ€§",
                    "æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„PCAP/PCAPNGæ ¼å¼",
                    "è€ƒè™‘ä½¿ç”¨æ–‡ä»¶é¢„å¤„ç†å·¥å…·ä¿®å¤æŸåçš„æ•°æ®åŒ…"
                ])
        
        # åŸºäºç»Ÿè®¡çš„å»ºè®®
        total_files = self._processing_stats.get('total_files_processed', 0)
        if total_files > 0:
            fallback_usage = sum(self._processing_stats.get('fallback_usage', {}).values())
            fallback_rate = fallback_usage / total_files
            
            if fallback_rate > 0.3:  # é™çº§ä½¿ç”¨ç‡è¶…è¿‡30%
                recommendations.append(
                    f"é™çº§ä½¿ç”¨ç‡è¾ƒé«˜ï¼ˆ{fallback_rate:.1%}ï¼‰ï¼Œå»ºè®®æ£€æŸ¥ä¸»è¦å¤„ç†æµç¨‹çš„é…ç½®å’Œä¾èµ–"
                )
            
            success_rate = self._processing_stats.get('successful_files', 0) / total_files
            if success_rate < 0.8:  # æˆåŠŸç‡ä½äº80%
                recommendations.append(
                    f"å¤„ç†æˆåŠŸç‡åä½ï¼ˆ{success_rate:.1%}ï¼‰ï¼Œå»ºè®®æ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡å’Œç³»ç»Ÿé…ç½®"
                )
        
        # å»é‡å’Œé™åˆ¶æ•°é‡
        recommendations = list(dict.fromkeys(recommendations))  # å»é‡
        return recommendations[:10]  # æœ€å¤šè¿”å›10ä¸ªå»ºè®®

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºæ¸…ç†"""
        self.cleanup() 