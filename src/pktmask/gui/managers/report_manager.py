#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æŠ¥å‘Šç®¡ç†å™¨ - è´Ÿè´£æŠ¥å‘Šç”Ÿæˆå’Œæ˜¾ç¤º
"""

import os
from typing import TYPE_CHECKING, Dict, Any, Optional, List
from datetime import datetime

if TYPE_CHECKING:
    from ..main_window import MainWindow

from pktmask.infrastructure.logging import get_logger

class ReportManager:
    """æŠ¥å‘Šç®¡ç†å™¨ - è´Ÿè´£æŠ¥å‘Šç”Ÿæˆå’Œæ˜¾ç¤º"""
    
    def __init__(self, main_window: 'MainWindow'):
        self.main_window = main_window
        self.config = main_window.config
        self._logger = get_logger(__name__)
    
    def update_log(self, message: str):
        """æ›´æ–°æ—¥å¿—æ˜¾ç¤º"""
        try:
            timestamp = datetime.now().strftime("%H:%M:%S")
            formatted_message = f"[{timestamp}] {message}"
            
            # æ·»åŠ åˆ°æ—¥å¿—æ–‡æœ¬åŒºåŸŸ
            self.main_window.log_text.append(formatted_message)
            
            # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
            cursor = self.main_window.log_text.textCursor()
            cursor.movePosition(cursor.MoveOperation.End)
            self.main_window.log_text.setTextCursor(cursor)
            
            self._logger.debug(f"UIæ—¥å¿—æ›´æ–°: {message}")
            
        except Exception as e:
            self._logger.error(f"æ›´æ–°æ—¥å¿—æ˜¾ç¤ºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def generate_partial_summary_on_stop(self):
        """ç”Ÿæˆç”¨æˆ·åœæ­¢æ—¶çš„éƒ¨åˆ†æ±‡æ€»ç»Ÿè®¡"""
        separator_length = 70
        
        # è®¡ç®—å½“å‰çš„æ—¶é—´
        if self.main_window.timer:
            self.main_window.timer.stop()
        
        # åœæ­¢ç»Ÿè®¡ç®¡ç†å™¨çš„è®¡æ—¶
        if hasattr(self.main_window, 'pipeline_manager') and hasattr(self.main_window.pipeline_manager, 'statistics'):
            self.main_window.pipeline_manager.statistics.stop_timing()
            
        self.main_window.update_time_elapsed()
        
        partial_time = self.main_window.time_elapsed_label.text()
        partial_files = self.main_window.files_processed_count
        partial_packets = self.main_window.packets_processed_count
        
        # ç”Ÿæˆåœæ­¢æ±‡æ€»æŠ¥å‘Š
        stop_report = f"\n{'='*separator_length}\nâ¹ï¸ PROCESSING STOPPED BY USER\n{'='*separator_length}\n"
        stop_report += f"ğŸ“Š Partial Statistics (Completed Portion):\n"
        stop_report += f"   â€¢ Files Processed: {partial_files}\n"
        stop_report += f"   â€¢ Packets Processed: {partial_packets:,}\n"
        stop_report += f"   â€¢ Processing Time: {partial_time}\n"
        
        # è®¡ç®—éƒ¨åˆ†å¤„ç†é€Ÿåº¦
        try:
            time_parts = partial_time.split(':')
            if len(time_parts) >= 2:
                minutes = int(time_parts[-2])
                seconds_with_ms = time_parts[-1].split('.')
                seconds = int(seconds_with_ms[0])
                total_seconds = minutes * 60 + seconds
                if total_seconds > 0 and partial_packets > 0:
                    speed = partial_packets / total_seconds
                    stop_report += f"   â€¢ Average Speed: {speed:,.0f} packets/second\n\n"
                else:
                    stop_report += f"   â€¢ Average Speed: N/A\n\n"
            else:
                stop_report += f"   â€¢ Average Speed: N/A\n\n"
        except:
            stop_report += f"   â€¢ Average Speed: N/A\n\n"
        
        # æ˜¾ç¤ºå·²å¯ç”¨çš„å¤„ç†æ­¥éª¤
        enabled_steps = []
        if self.main_window.mask_ip_cb.isChecked():
            enabled_steps.append("IP Anonymization")
        if self.main_window.dedup_packet_cb.isChecked():
            enabled_steps.append("Deduplication")
        if self.main_window.mask_payload_cb.isChecked():
            enabled_steps.append("Payload Masking")
        
        stop_report += f"ğŸ”§ Configured Processing Steps: {', '.join(enabled_steps)}\n"
        stop_report += f"ğŸ“ Working Directory: {os.path.basename(self.main_window.base_dir) if self.main_window.base_dir else 'N/A'}\n"
        stop_report += f"âš ï¸ Processing was interrupted. All intermediate files have been cleaned up.\n"
        stop_report += f"âŒ No completed output files were generated due to interruption.\n"
        stop_report += f"{'='*separator_length}\n"
        
        self.main_window.summary_text.append(stop_report)
        
        # æ£€æŸ¥å¹¶æ˜¾ç¤ºæ–‡ä»¶å¤„ç†çŠ¶æ€
        if self.main_window.file_processing_results:
            files_status_report = self._generate_files_status_report(separator_length)
            self.main_window.summary_text.append(files_status_report)
        
        # æ˜¾ç¤ºå…¨å±€IPæ˜ å°„æ±‡æ€»ï¼ˆä»…å½“æœ‰å®Œå…¨å®Œæˆçš„æ–‡ä»¶æ—¶ï¼‰
        if self.main_window.processed_files_count >= 1 and self.main_window.global_ip_mappings:
            global_partial_report = self._generate_global_ip_mappings_report(separator_length, True)
            if global_partial_report:
                self.main_window.summary_text.append(global_partial_report)
        
        # æ˜¾ç¤ºEnhanced Trimmeræ™ºèƒ½å¤„ç†ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        enhanced_partial_report = self._generate_enhanced_trimming_report(separator_length, is_partial=True)
        if enhanced_partial_report:
            self.main_window.summary_text.append(enhanced_partial_report)
        
        # ä¿®æ­£çš„é‡å¯æç¤º
        restart_hint = f"\nğŸ’¡ RESTART INFORMATION:\n"
        restart_hint += f"   â€¢ Clicking 'Start' will restart processing from the beginning\n"
        restart_hint += f"   â€¢ All files will be reprocessed (no partial resume capability)\n"
        restart_hint += f"   â€¢ Any existing output files will be skipped to avoid overwriting\n"
        restart_hint += f"   â€¢ Processing will be performed completely for each file\n"
        self.main_window.summary_text.append(restart_hint)
    
    def _generate_files_status_report(self, separator_length: int) -> str:
        """ç”Ÿæˆæ–‡ä»¶å¤„ç†çŠ¶æ€æŠ¥å‘Š"""
        files_status_report = f"\n{'='*separator_length}\nğŸ“‹ FILES PROCESSING STATUS (At Stop)\n{'='*separator_length}\n"
        
        completed_files = 0
        partial_files = 0
        
        for filename, file_result in self.main_window.file_processing_results.items():
            steps_data = file_result['steps']
            if not steps_data:
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´å¤„ç†å®Œæˆï¼ˆæ‰€æœ‰é…ç½®çš„æ­¥éª¤éƒ½å®Œæˆï¼‰
            expected_steps = set()
            if self.main_window.mask_ip_cb.isChecked():
                expected_steps.add("IP Anonymization")
            if self.main_window.dedup_packet_cb.isChecked():
                expected_steps.add("Deduplication")
            if self.main_window.mask_payload_cb.isChecked():
                expected_steps.add("Payload Masking")
            
            completed_steps = set(steps_data.keys())
            is_fully_completed = expected_steps.issubset(completed_steps)
            
            if is_fully_completed:
                completed_files += 1
                files_status_report += self._generate_completed_file_report(filename, steps_data)
            else:
                partial_files += 1
                files_status_report += self._generate_partial_file_report(filename, completed_steps, expected_steps)
        
        if completed_files == 0 and partial_files > 0:
            files_status_report += f"\nâš ï¸ All files were only partially processed.\n"
            files_status_report += f"   No final output files were created.\n"
        elif completed_files > 0:
            files_status_report += f"\nğŸ“ˆ Summary: {completed_files} completed, {partial_files} partial\n"
        
        files_status_report += f"{'='*separator_length}\n"
        return files_status_report
    
    def _generate_completed_file_report(self, filename: str, steps_data: Dict) -> str:
        """ç”Ÿæˆå·²å®Œæˆæ–‡ä»¶çš„æŠ¥å‘Š"""
        report = f"\nâœ… {filename}\n"
        report += f"   Status: FULLY COMPLETED\n"
        
        # è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶å
        step_order = ['Deduplication', 'IP Anonymization', 'Payload Masking']
        final_output = None
        for step_name in reversed(step_order):
            if step_name in steps_data:
                output_file = steps_data[step_name]['data'].get('output_filename')
                if output_file and not output_file.startswith('tmp'):
                    final_output = output_file
                    break
        
        if final_output:
            report += f"   Output File: {final_output}\n"
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        original_packets = 0
        file_ip_mappings = {}
        
        for step_name in step_order:
            if step_name in steps_data:
                data = steps_data[step_name]['data']
                if data.get('total_packets'):
                    original_packets = data.get('total_packets', 0)
                
                if step_name == 'IP Anonymization':
                    # æ”¯æŒæ–°çš„AnonStageå­—æ®µåç§°ï¼ˆä»extra_metricsä¸­è·å–ï¼‰
                    extra_metrics = data.get('extra_metrics', {})
                    original_ips = data.get('original_ips', extra_metrics.get('original_ips', 0))
                    masked_ips = data.get('anonymized_ips', extra_metrics.get('anonymized_ips', 0))
                    rate = (masked_ips / original_ips * 100) if original_ips > 0 else 0
                    report += f"   ğŸ›¡ï¸  IP Anonymization: {original_ips} â†’ {masked_ips} IPs ({rate:.1f}%)\n"
                    file_ip_mappings = data.get('file_ip_mappings', extra_metrics.get('file_ip_mappings', {}))
                    
                elif step_name == 'Deduplication':
                    unique = data.get('unique_packets', 0)
                    removed = data.get('removed_count', 0)
                    rate = (removed / original_packets * 100) if original_packets > 0 else 0
                    report += f"   ğŸ”„ Deduplication: {removed} removed ({rate:.1f}%)\n"
                
                elif step_name == 'Payload Masking':
                    # æ”¯æŒæ–°çš„MaskPayloadStageå­—æ®µåç§°
                    masked = data.get('packets_modified', data.get('trimmed_packets', 0))
                    rate = (masked / original_packets * 100) if original_packets > 0 else 0
                    report += f"   âœ‚ï¸  Payload Masking: {masked} masked ({rate:.1f}%)\n"
        
        # æ˜¾ç¤ºIPæ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰
        if file_ip_mappings:
            report += f"   ğŸ”— IP Mappings ({len(file_ip_mappings)}):\n"
            for i, (orig_ip, new_ip) in enumerate(sorted(file_ip_mappings.items()), 1):
                if i <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    report += f"      {i}. {orig_ip} â†’ {new_ip}\n"
                elif i == 6:
                    report += f"      ... and {len(file_ip_mappings) - 5} more\n"
                    break
        
        return report
    
    def _generate_partial_file_report(self, filename: str, completed_steps: set, expected_steps: set) -> str:
        """ç”Ÿæˆéƒ¨åˆ†å®Œæˆæ–‡ä»¶çš„æŠ¥å‘Š"""
        report = f"\nğŸ”„ {filename}\n"
        report += f"   Status: PARTIALLY PROCESSED (Interrupted)\n"
        report += f"   Completed Steps: {', '.join(completed_steps)}\n"
        report += f"   Missing Steps: {', '.join(expected_steps - completed_steps)}\n"
        report += f"   âŒ No final output file generated\n"
        report += f"   ğŸ—‘ï¸ Temporary files cleaned up automatically\n"
        return report
    
    def _generate_global_ip_mappings_report(self, separator_length: int, is_partial: bool = False) -> Optional[str]:
        """ç”Ÿæˆå…¨å±€IPæ˜ å°„æŠ¥å‘Š"""
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰IPåŒ¿ååŒ–å¤„ç†
        if not self.main_window.mask_ip_cb.isChecked():
            return None
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¨å±€IPæ˜ å°„æ•°æ®
        if not self.main_window.global_ip_mappings:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨å®Œæˆçš„æ–‡ä»¶
        has_completed_files = False
        for filename, file_result in self.main_window.file_processing_results.items():
            expected_steps = set()
            if self.main_window.mask_ip_cb.isChecked():
                expected_steps.add("IP Anonymization")
            if self.main_window.dedup_packet_cb.isChecked():
                expected_steps.add("Deduplication")
            if self.main_window.mask_payload_cb.isChecked():
                expected_steps.add("Payload Masking")
            
            completed_steps = set(file_result['steps'].keys())
            if expected_steps.issubset(completed_steps):
                has_completed_files = True
                break
        
        if not has_completed_files:
            return None
        
        if is_partial:
            title = "ğŸŒ IP MAPPINGS FROM COMPLETED FILES"
            subtitle = "ğŸ“ IP Mapping Table - From Successfully Completed Files Only:"
        else:
            title = "ğŸŒ GLOBAL IP MAPPINGS (All Files Combined)"
            subtitle = "ğŸ“ Complete IP Mapping Table - Unique Entries Across All Files:"
        
        global_partial_report = f"\n{'='*separator_length}\n{title}\n{'='*separator_length}\n"
        global_partial_report += f"{subtitle}\n"
        global_partial_report += f"   â€¢ Total Unique IPs Mapped: {len(self.main_window.global_ip_mappings)}\n\n"
        
        sorted_global_mappings = sorted(self.main_window.global_ip_mappings.items())
        for i, (orig_ip, new_ip) in enumerate(sorted_global_mappings, 1):
            global_partial_report += f"   {i:2d}. {orig_ip:<16} â†’ {new_ip}\n"
        
        if is_partial:
            global_partial_report += f"\nâœ… All unique IP addresses across files have been\n"
            global_partial_report += f"   successfully anonymized with consistent mappings.\n"
        else:
            global_partial_report += f"\nâœ… All unique IP addresses across {self.main_window.processed_files_count} files have been\n"
            global_partial_report += f"   successfully anonymized with consistent mappings.\n"
        
        global_partial_report += f"{'='*separator_length}\n"
        return global_partial_report
    
    def generate_file_complete_report(self, original_filename: str):
        """ä¸ºå•ä¸ªæ–‡ä»¶ç”Ÿæˆå®Œæ•´çš„å¤„ç†æŠ¥å‘Š"""
        if original_filename not in self.main_window.file_processing_results:
            return
            
        file_results = self.main_window.file_processing_results[original_filename]
        steps_data = file_results['steps']
        
        if not steps_data:
            return
        
        # **ä¿®å¤**: ç§»é™¤é‡å¤çš„æ–‡ä»¶è®¡æ•°é€’å¢ï¼ˆå·²åœ¨main_window.pyçš„FILE_ENDäº‹ä»¶ä¸­è®¡æ•°ï¼‰
        # self.main_window.processed_files_count += 1  # ç§»é™¤è¿™è¡Œï¼Œé¿å…åŒé‡è®¡æ•°
        
        separator_length = 70
        filename_display = original_filename
        
        # æ–‡ä»¶å¤„ç†æ ‡é¢˜
        header = f"\n{'='*separator_length}\nğŸ“„ FILE PROCESSING RESULTS: {filename_display}\n{'='*separator_length}"
        self.main_window.summary_text.append(header)
        
        # è·å–åŸå§‹åŒ…æ•°ï¼ˆä»ç¬¬ä¸€ä¸ªå¤„ç†æ­¥éª¤è·å–ï¼‰
        original_packets = 0
        output_filename = None
        if 'IP Anonymization' in steps_data:
            original_packets = steps_data['IP Anonymization']['data'].get('total_packets', 0)
            output_filename = steps_data['IP Anonymization']['data'].get('output_filename')
        elif 'Deduplication' in steps_data:
            original_packets = steps_data['Deduplication']['data'].get('total_packets', 0)
            output_filename = steps_data['Deduplication']['data'].get('output_filename')
        elif 'Payload Masking' in steps_data:
            original_packets = steps_data['Payload Masking']['data'].get('total_packets', 0)
            output_filename = steps_data['Payload Masking']['data'].get('output_filename')
        
        # ä»æœ€åä¸€ä¸ªå¤„ç†æ­¥éª¤è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶å
        step_order = ['Deduplication', 'IP Anonymization', 'Payload Masking']
        for step_name in reversed(step_order):
            if step_name in steps_data:
                final_output = steps_data[step_name]['data'].get('output_filename')
                if final_output:
                    output_filename = final_output
                    break
        
        # æ˜¾ç¤ºåŸå§‹åŒ…æ•°å’Œè¾“å‡ºæ–‡ä»¶å
        self.main_window.summary_text.append(f"ğŸ“¦ Original Packets: {original_packets:,}")
        if output_filename:
            self.main_window.summary_text.append(f"ğŸ“„ Output File: {output_filename}")
        self.main_window.summary_text.append("")
        
        # æŒ‰å¤„ç†é¡ºåºæ˜¾ç¤ºå„æ­¥éª¤ç»“æœ
        file_ip_mappings = {}  # å­˜å‚¨å½“å‰æ–‡ä»¶çš„IPæ˜ å°„
        
        # **è°ƒè¯•æ—¥å¿—**: æ˜¾ç¤ºæ”¶é›†åˆ°çš„æ­¥éª¤æ•°æ®
        self._logger.info(f"ğŸ” ç”Ÿæˆæ–‡ä»¶æŠ¥å‘Š: {original_filename}")
        self._logger.info(f"ğŸ” æ”¶é›†åˆ°çš„æ­¥éª¤: {list(steps_data.keys())}")
        for step_name, step_info in steps_data.items():
            self._logger.info(f"ğŸ”   {step_name}: ç±»å‹={step_info.get('type')}, æ•°æ®å­—æ®µ={list(step_info.get('data', {}).keys())}")
        
        # ä¿®å¤ï¼šä»æ–‡ä»¶çº§IPæ˜ å°„ç¼“å­˜ä¸­è·å–IPæ˜ å°„ä¿¡æ¯
        if hasattr(self.main_window, '_current_file_ips') and original_filename in self.main_window._current_file_ips:
            file_ip_mappings = self.main_window._current_file_ips[original_filename]
        
        for step_name in step_order:
            if step_name in steps_data:
                step_result = steps_data[step_name]
                step_type = step_result['type']
                data = step_result['data']
                
                self._logger.info(f"ğŸ” å¤„ç†æ­¥éª¤ {step_name}: ç±»å‹={step_type}")
                
                # å¯¹äºPayload Maskingï¼Œè®°å½•è¯¦ç»†çš„æ•°æ®å­—æ®µ
                if step_name == 'Payload Masking':
                    self._logger.info(f"ğŸ” Payload Maskingæ•°æ®: packets_processed={data.get('packets_processed')}, packets_modified={data.get('packets_modified')}")
                    self._logger.info(f"ğŸ” Payload Maskingæ•°æ®: total_packets={data.get('total_packets')}, trimmed_packets={data.get('trimmed_packets')}")
                
                if step_type in ['mask_ip', 'mask_ips']:  # ä¿®å¤ï¼šæ”¯æŒä¸¤ç§å‘½åæ ¼å¼
                    # ä½¿ç”¨æ–°çš„IPç»Ÿè®¡æ•°æ®
                    original_ips = data.get('original_ips', 0)
                    masked_ips = data.get('anonymized_ips', 0)
                    rate = (masked_ips / original_ips * 100) if original_ips > 0 else 0
                    line = f"  ğŸ›¡ï¸  {step_name:<18} | Original IPs: {original_ips:>3} | Anonymized IPs: {masked_ips:>3} | Rate: {rate:5.1f}%"
                    
                    # IPæ˜ å°„å·²åœ¨ä¸Šé¢ä»ç¼“å­˜ä¸­è·å–
                    
                elif step_type == 'remove_dupes':
                    unique = data.get('unique_packets', 0)
                    removed = data.get('removed_count', 0)
                    total_before = data.get('total_packets', 0)
                    rate = (removed / total_before * 100) if total_before > 0 else 0
                    line = f"  ğŸ”„ {step_name:<18} | Unique Pkts: {unique:>4} | Removed Pkts: {removed:>4} | Rate: {rate:5.1f}%"
                
                elif step_type in ['intelligent_trim', 'trim_payloads']:  # ä¿®å¤ï¼šæ”¯æŒä¸¤ç§å‘½åæ ¼å¼
                    # ä¿®å¤ï¼šMaskStageè¿”å›çš„å­—æ®µåç§°ä¸åŒ
                    total = data.get('total_packets', data.get('packets_processed', 0))
                    masked = data.get('trimmed_packets', data.get('packets_modified', 0))
                    rate = (masked / total * 100) if total > 0 else 0
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯Enhanced Trimmerçš„æ™ºèƒ½å¤„ç†ç»“æœ
                    if self._is_enhanced_trimming(data):
                        line = self._generate_enhanced_trimming_report_line(step_name, data)
                    else:
                        line = f"  âœ‚ï¸  {step_name:<18} | Total Pkts: {total:>5} | Masked Pkts: {masked:>4} | Rate: {rate:5.1f}%"
                else:
                    continue
                    
                self.main_window.summary_text.append(line)
        
        # å¦‚æœæœ‰IPæ˜ å°„ï¼Œæ˜¾ç¤ºæ–‡ä»¶çº§åˆ«çš„IPæ˜ å°„
        if file_ip_mappings:
            self.main_window.summary_text.append("")
            self.main_window.summary_text.append("ğŸ”— IP Mappings for this file:")
            sorted_mappings = sorted(file_ip_mappings.items())
            for i, (orig_ip, new_ip) in enumerate(sorted_mappings, 1):
                self.main_window.summary_text.append(f"   {i:2d}. {orig_ip:<16} â†’ {new_ip}")
        
        # å¦‚æœä½¿ç”¨äº†Enhanced Trimmerï¼Œæ˜¾ç¤ºæ™ºèƒ½å¤„ç†è¯¦ç»†ä¿¡æ¯
        enhanced_report = self._generate_enhanced_trimming_report_for_file(original_filename, separator_length)
        if enhanced_report:
            self.main_window.summary_text.append(enhanced_report)
        
        self.main_window.summary_text.append(f"{'='*separator_length}")
    
    def generate_processing_finished_report(self):
        """ç”Ÿæˆå¤„ç†å®Œæˆæ—¶çš„æŠ¥å‘Š"""
        separator_length = 70  # ä¿æŒä¸€è‡´çš„åˆ†éš”çº¿é•¿åº¦
        
        # åœæ­¢è®¡æ—¶å™¨
        if self.main_window.timer and self.main_window.timer.isActive():
            self.main_window.timer.stop()
        
        # åœæ­¢ç»Ÿè®¡ç®¡ç†å™¨çš„è®¡æ—¶
        if hasattr(self.main_window, 'pipeline_manager') and hasattr(self.main_window.pipeline_manager, 'statistics'):
            self.main_window.pipeline_manager.statistics.stop_timing()
            
        self.main_window.update_time_elapsed()
        
        enabled_steps = []
        if self.main_window.dedup_packet_cb.isChecked():
            enabled_steps.append("Deduplication")
        if self.main_window.mask_ip_cb.isChecked():
            enabled_steps.append("IP Anonymization")
        if self.main_window.mask_payload_cb.isChecked():
            enabled_steps.append("Payload Masking")
            
        completion_report = f"\n{'='*separator_length}\nğŸ‰ PROCESSING COMPLETED!\n{'='*separator_length}\n"
        completion_report += f"ğŸ¯ All {self.main_window.processed_files_count} files have been successfully processed.\n"
        completion_report += f"ğŸ“ˆ Files Processed: {self.main_window.processed_files_count}\n"
        completion_report += f"ğŸ“Š Total Packets Processed: {self.main_window.packets_processed_count}\n"
        completion_report += f"â±ï¸ Time Elapsed: {self.main_window.time_elapsed_label.text()}\n"
        completion_report += f"ğŸ”§ Applied Processing Steps: {', '.join(enabled_steps)}\n"
        
        # å®‰å…¨å¤„ç†è¾“å‡ºç›®å½•æ˜¾ç¤º
        if self.main_window.current_output_dir:
            completion_report += f"ğŸ“ Output Location: {os.path.basename(self.main_window.current_output_dir)}\n"
        else:
            completion_report += f"ğŸ“ Output Location: Not specified\n"
            
        completion_report += f"ğŸ“ All processed files saved to output directory.\n"
        completion_report += f"{'='*separator_length}\n"
        
        self.main_window.summary_text.append(completion_report)
        
        # ä¿®å¤ï¼šæ·»åŠ å…¨å±€IPæ˜ å°„æ±‡æ€»æŠ¥å‘Šï¼ˆå¤šæ–‡ä»¶å¤„ç†æ—¶æ˜¾ç¤ºå»é‡çš„å…¨å±€IPæ˜ å°„ï¼‰
        global_ip_report = self._generate_global_ip_mappings_report(separator_length, is_partial=False)
        if global_ip_report:
            self.main_window.summary_text.append(global_ip_report)
        
        # æ·»åŠ Enhanced Trimmeræ™ºèƒ½å¤„ç†æ€»æŠ¥å‘Š
        enhanced_trimming_report = self._generate_enhanced_trimming_report(separator_length, is_partial=False)
        if enhanced_trimming_report:
            self.main_window.summary_text.append(enhanced_trimming_report)
        
        # ä¿®å¤ï¼šå¤„ç†å®Œæˆåè‡ªåŠ¨ä¿å­˜Summary Reportåˆ°è¾“å‡ºç›®å½•
        self._save_summary_report_to_output()

    def set_final_summary_report(self, report: dict):
        """è®¾ç½®æœ€ç»ˆçš„æ±‡æ€»æŠ¥å‘Šï¼ŒåŒ…æ‹¬è¯¦ç»†çš„IPæ˜ å°„ä¿¡æ¯ã€‚"""
        subdir = report.get('path', 'N/A')
        stats = report.get('stats', {})
        total_mapping = report.get('data', {}).get('total_mapping', {})
        
        separator_length = 70  # ä¿æŒä¸€è‡´çš„åˆ†éš”çº¿é•¿åº¦
        
        # æ·»åŠ IPæ˜ å°„çš„æ±‡æ€»ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¯¦ç»†æ˜ å°„è¡¨
        text = f"\n{'='*separator_length}\nğŸ“‹ DIRECTORY PROCESSING SUMMARY\n{'='*separator_length}\n"
        text += f"ğŸ“‚ Directory: {subdir}\n\n"
        text += f"ğŸ”’ IP Anonymization Summary:\n"
        text += f"   â€¢ Total Unique IPs Discovered: {stats.get('total_unique_ips', 'N/A')}\n"
        text += f"   â€¢ Total IPs Anonymized: {stats.get('total_mapped_ips', 'N/A')}\n\n"
        
        if total_mapping:
            text += f"ğŸ“ Complete IP Mapping Table (All Files):\n"
            # æŒ‰åŸå§‹IPæ’åºæ˜¾ç¤ºæ˜ å°„
            sorted_mappings = sorted(total_mapping.items())
            for i, (orig_ip, new_ip) in enumerate(sorted_mappings, 1):
                text += f"   {i:2d}. {orig_ip:<16} â†’ {new_ip}\n"
            text += "\n"
        
        text += f"âœ… All IP addresses have been successfully anonymized while\n"
        text += f"   preserving network structure and subnet relationships.\n"
        text += f"{'='*separator_length}\n"
        
        self.main_window.summary_text.append(text)

    def update_summary_report(self, data: Dict[str, Any]):
        """æ›´æ–°æ‘˜è¦æŠ¥å‘Šæ˜¾ç¤º"""
        try:
            # æ ¹æ®æ•°æ®ç±»å‹ç”Ÿæˆä¸åŒçš„æŠ¥å‘Š
            if 'filename' in data:
                # å•æ–‡ä»¶å¤„ç†æŠ¥å‘Š
                self._update_file_summary(data)
            elif 'step_results' in data:
                # æ•´ä½“å¤„ç†æ‘˜è¦
                self._update_overall_summary(data)
            else:
                step_type = data.get('type')
                if step_type and step_type.endswith('_final'):
                    report_data = data.get('report')
                    if report_data and 'mask_ip' in step_type:
                        self.set_final_summary_report(report_data)
                else:
                    self._logger.warning(f"æœªçŸ¥çš„æ‘˜è¦æŠ¥å‘Šæ•°æ®æ ¼å¼: {data.keys()}")
                
        except Exception as e:
            self._logger.error(f"æ›´æ–°æ‘˜è¦æŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def _update_file_summary(self, data: Dict[str, Any]):
        """æ›´æ–°å•æ–‡ä»¶å¤„ç†æ‘˜è¦"""
        filename = data.get('filename', 'Unknown file')
        
        # è·å–å½“å‰æ‘˜è¦æ–‡æœ¬
        current_text = self.main_window.summary_text.toPlainText()
        
        # ç”Ÿæˆæ–‡ä»¶æ‘˜è¦
        file_summary = self._generate_file_summary_text(data)
        
        # è¿½åŠ åˆ°ç°æœ‰æ–‡æœ¬
        if current_text.strip():
            updated_text = current_text + "\n\n" + file_summary
        else:
            updated_text = file_summary
        
        self.main_window.summary_text.setPlainText(updated_text)
        
        # æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.main_window.summary_text.textCursor()
        cursor.movePosition(cursor.MoveOperation.End)
        self.main_window.summary_text.setTextCursor(cursor)
    
    def _update_overall_summary(self, data: Dict[str, Any]):
        """æ›´æ–°æ•´ä½“å¤„ç†æ‘˜è¦"""
        summary_text = self._generate_overall_summary_text(data)
        self.main_window.summary_text.setPlainText(summary_text)
    
    def _generate_file_summary_text(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå•æ–‡ä»¶æ‘˜è¦æ–‡æœ¬"""
        filename = data.get('filename', 'Unknown file')
        summary_parts = [f"ğŸ“„ {filename}"]
        
        # å¤„ç†ç»“æœç»Ÿè®¡
        results = data.get('results', {})
        for step_name, result in results.items():
            if isinstance(result, dict):
                if 'summary' in result:
                    summary_parts.append(f"  â€¢ {step_name}: {result['summary']}")
                elif 'packets_processed' in result:
                    summary_parts.append(f"  â€¢ {step_name}: {result['packets_processed']} packets")
                elif 'ips_anonymized' in result:
                    summary_parts.append(f"  â€¢ {step_name}: {result['ips_anonymized']} IPs anonymized")
        
        return '\n'.join(summary_parts)
    
    def _generate_overall_summary_text(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•´ä½“æ‘˜è¦æ–‡æœ¬"""
        summary_parts = ["ğŸ“Š Processing Summary", "=" * 50]
        
        # åŸºæœ¬ç»Ÿè®¡
        files_processed = data.get('files_processed', 0)
        total_files = data.get('total_files', 0)
        status = data.get('status', 'unknown')
        
        summary_parts.append(f"Status: {status.title().replace('_', ' ')}")
        summary_parts.append(f"Files Processed: {files_processed}/{total_files}")
        
        if files_processed > 0 and total_files > 0:
            percentage = (files_processed / total_files) * 100
            summary_parts.append(f"Completion: {percentage:.1f}%")
        
        summary_parts.append("")
        
        # æ­¥éª¤ç»Ÿè®¡
        step_results = data.get('step_results', {})
        if step_results:
            summary_parts.append("ğŸ“ˆ Step Statistics:")
            
            # èšåˆå„æ­¥éª¤çš„ç»Ÿè®¡
            step_stats = self._aggregate_step_statistics(step_results)
            
            for step_name, stats in step_stats.items():
                summary_parts.append(f"\nğŸ”§ {step_name}:")
                for key, value in stats.items():
                    summary_parts.append(f"  â€¢ {key}: {value}")
        
        # è¾“å‡ºç›®å½•ä¿¡æ¯
        output_dir = data.get('output_directory')
        if output_dir:
            summary_parts.append(f"\nğŸ“ Output Directory:")
            summary_parts.append(f"  {output_dir}")
        
        # æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        summary_parts.append(f"\nâ° Generated: {timestamp}")
        
        return '\n'.join(summary_parts)
    
    def _generate_final_summary_text(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæœ€ç»ˆæ‘˜è¦æ–‡æœ¬"""
        summary_parts = ["ğŸ¯ Final Processing Report", "=" * 60]
        
        # å¤„ç†çŠ¶æ€
        status = data.get('status', 'unknown')
        files_processed = data.get('files_processed', 0)
        total_files = data.get('total_files', 0)
        
        if status == 'completed':
            summary_parts.append("âœ… Status: Successfully Completed")
        elif status == 'stopped_by_user':
            summary_parts.append("â¹ï¸ Status: Stopped by User")
        else:
            summary_parts.append(f"â“ Status: {status.title()}")
        
        summary_parts.append(f"ğŸ“Š Files Processed: {files_processed} of {total_files}")
        
        if files_processed > 0 and total_files > 0:
            percentage = (files_processed / total_files) * 100
            summary_parts.append(f"ğŸ“ˆ Completion Rate: {percentage:.1f}%")
        
        summary_parts.append("")
        
        # è¯¦ç»†ç»Ÿè®¡
        step_results = data.get('step_results', {})
        if step_results:
            summary_parts.append("ğŸ“‹ Detailed Statistics:")
            summary_parts.append("-" * 40)
            
            # èšåˆç»Ÿè®¡
            aggregated_stats = self._aggregate_step_statistics(step_results)
            
            for step_name, stats in aggregated_stats.items():
                summary_parts.append(f"\nğŸ”§ {step_name}:")
                for stat_name, stat_value in stats.items():
                    summary_parts.append(f"  â€¢ {stat_name}: {stat_value}")
        
        # æ–‡ä»¶è¯¦æƒ…
        if step_results:
            summary_parts.append("\nğŸ“„ File Details:")
            summary_parts.append("-" * 30)
            
            for filename, file_results in step_results.items():
                summary_parts.append(f"\nğŸ“ {filename}:")
                for step_name, result in file_results.items():
                    if isinstance(result, dict):
                        if 'summary' in result:
                            summary_parts.append(f"  â€¢ {step_name}: {result['summary']}")
                        else:
                            summary_parts.append(f"  â€¢ {step_name}: Processed")
        
        # è¾“å‡ºä¿¡æ¯
        output_dir = data.get('output_directory')
        if output_dir:
            summary_parts.append(f"\nğŸ“‚ Output Location:")
            summary_parts.append(f"  {output_dir}")
        
        # ç”Ÿæˆæ—¶é—´
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        summary_parts.append(f"\nğŸ•’ Report Generated: {timestamp}")
        
        # å·¥å…·ä¿¡æ¯
        summary_parts.append("\n" + "=" * 60)
        summary_parts.append("ğŸ› ï¸ Generated by PktMask - Network Packet Processing Tool")
        
        return '\n'.join(summary_parts)
    
    def _aggregate_step_statistics(self, step_results: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """èšåˆæ­¥éª¤ç»Ÿè®¡ä¿¡æ¯"""
        aggregated = {}
        
        for filename, file_results in step_results.items():
            for step_name, result in file_results.items():
                if step_name not in aggregated:
                    aggregated[step_name] = {}
                
                if isinstance(result, dict):
                    for key, value in result.items():
                        if isinstance(value, (int, float)):
                            # æ•°å€¼ç±»å‹è¿›è¡Œç´¯åŠ 
                            if key in aggregated[step_name]:
                                aggregated[step_name][key] += value
                            else:
                                aggregated[step_name][key] = value
                        elif key == 'summary' and isinstance(value, str):
                            # æ‘˜è¦ä¿¡æ¯æ”¶é›†åˆ°åˆ—è¡¨
                            summary_key = 'summaries'
                            if summary_key not in aggregated[step_name]:
                                aggregated[step_name][summary_key] = []
                            aggregated[step_name][summary_key].append(f"{filename}: {value}")
        
        # åå¤„ç†ï¼šè®¡ç®—å¹³å‡å€¼ã€æ ¼å¼åŒ–æ˜¾ç¤ºç­‰
        for step_name, stats in aggregated.items():
            if 'summaries' in stats:
                # å°†æ‘˜è¦åˆ—è¡¨è½¬æ¢ä¸ºè®¡æ•°
                summaries = stats.pop('summaries')
                stats['files_processed'] = len(summaries)
        
        return aggregated
    
    def clear_displays(self):
        """æ¸…ç©ºæ˜¾ç¤ºåŒºåŸŸ"""
        try:
            self.main_window.log_text.clear()
            self.main_window.summary_text.clear()
            self._logger.debug("æ¸…ç©ºæ—¥å¿—å’Œæ‘˜è¦æ˜¾ç¤º")
            
        except Exception as e:
            self._logger.error(f"æ¸…ç©ºæ˜¾ç¤ºåŒºåŸŸæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def export_summary_report(self, filepath: str) -> bool:
        """å¯¼å‡ºæ‘˜è¦æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            content = self.main_window.summary_text.toPlainText()
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._logger.info(f"æ‘˜è¦æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filepath}")
            return True
            
        except Exception as e:
            self._logger.error(f"å¯¼å‡ºæ‘˜è¦æŠ¥å‘Šå¤±è´¥: {e}")
            return False
    
    def _save_summary_report_to_output(self):
        """ç§æœ‰æ–¹æ³•ï¼šä¿å­˜æ‘˜è¦æŠ¥å‘Šåˆ°è¾“å‡ºç›®å½•"""
        try:
            # å§”æ‰˜ç»™FileManageræˆ–ä½¿ç”¨MainWindowçš„ç°æœ‰æ–¹æ³•
            if hasattr(self.main_window, 'save_summary_report_to_output_dir'):
                self.main_window.save_summary_report_to_output_dir()
            elif hasattr(self.main_window, 'file_manager'):
                self.main_window.file_manager.save_summary_report_to_output_dir()
            else:
                self._logger.warning("æ— æ³•æ‰¾åˆ°ä¿å­˜Summary Reportçš„æ–¹æ³•")
        except Exception as e:
            self._logger.error(f"ä¿å­˜Summary Reportåˆ°è¾“å‡ºç›®å½•å¤±è´¥: {e}")

    def collect_step_result(self, data: dict):
        """æ”¶é›†æ¯ä¸ªæ­¥éª¤çš„å¤„ç†ç»“æœï¼Œä½†ä¸ç«‹å³æ˜¾ç¤º"""
        if not self.main_window.current_processing_file:
            return
            
        step_type = data.get('type')
        step_name_raw = data.get('step_name', '')
        
        # **è°ƒè¯•æ—¥å¿—**: è®°å½•æ”¶é›†çš„æ­¥éª¤ç»“æœ
        self._logger.info(f"ğŸ” æ”¶é›†æ­¥éª¤ç»“æœ: æ–‡ä»¶={self.main_window.current_processing_file}, æ­¥éª¤={step_name_raw}, ç±»å‹={step_type}")
        self._logger.info(f"ğŸ” æ•°æ®å­—æ®µ: {list(data.keys())}")
        
        # **ä¿®å¤**: æ”¯æŒæ–°Pipelineç³»ç»Ÿçš„æ­¥éª¤åç§°
        # ä»step_nameæ¨æ–­æ­¥éª¤ç±»å‹ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–typeå­—æ®µ
        if not step_type:
            # æ–°Pipelineç³»ç»Ÿæ²¡æœ‰typeå­—æ®µï¼Œä»step_nameæ¨æ–­
            if step_name_raw == 'AnonStage':
                step_type = 'mask_ip'  # ç»Ÿä¸€ä½¿ç”¨mask_ipä½œä¸ºIPåŒ¿ååŒ–çš„ç±»å‹
            elif step_name_raw in ['DedupStage', 'DeduplicationStage']:
                step_type = 'remove_dupes'
            elif step_name_raw in ['MaskStage', 'MaskPayloadStage', 'NewMaskPayloadStage']:
                step_type = 'trim_payloads'
            else:
                step_type = step_name_raw.lower()
        
        self._logger.info(f"ğŸ” æ¨æ–­æ­¥éª¤ç±»å‹: {step_type}")
        
        if not step_type or step_type.endswith('_final'):
            if step_type and step_type.endswith('_final'):
                # å¤„ç†æœ€ç»ˆæŠ¥å‘Šï¼Œæå–IPæ˜ å°„ä¿¡æ¯
                report_data = data.get('report')
                if report_data and 'mask_ip' in step_type:
                    self.set_final_summary_report(report_data)
            return
        
        # æ ‡å‡†åŒ–æ­¥éª¤åç§° - ä¿®å¤Pipelineå’ŒReportManagerä¹‹é—´çš„æ˜ å°„ä¸åŒ¹é…
        step_display_names = {
            'mask_ip': 'IP Anonymization',
            'mask_ips': 'IP Anonymization',  # ä¿®å¤ï¼šPipelineå‘é€çš„æ˜¯å¤æ•°å½¢å¼
            'remove_dupes': 'Deduplication',
            'intelligent_trim': 'Payload Masking',
            'trim_payloads': 'Payload Masking',  # ä¿®å¤ï¼šPipelineå‘é€çš„æ˜¯trim_payloads
        }
        
        step_name = step_display_names.get(step_type, step_type)
        
        # å­˜å‚¨æ­¥éª¤ç»“æœ
        self.main_window.file_processing_results[self.main_window.current_processing_file]['steps'][step_name] = {
            'type': step_type,
            'data': data
        }
        
        # **å…³é”®ä¿®å¤**: å¦‚æœæ˜¯IPåŒ¿ååŒ–æ­¥éª¤ï¼Œæå–å¹¶ç´¯ç§¯IPæ˜ å°„åˆ°å…¨å±€æ˜ å°„
        is_ip_anonymization = (
            step_type in ['mask_ip', 'mask_ips'] or 
            step_name_raw == 'AnonStage' or
            'ip_mappings' in data or 
            'file_ip_mappings' in data
        )
        
        if is_ip_anonymization:
            # ä»stepæ•°æ®ä¸­æå–IPæ˜ å°„
            ip_mappings = None
            if 'file_ip_mappings' in data:
                ip_mappings = data['file_ip_mappings']
            elif 'ip_mappings' in data:
                ip_mappings = data['ip_mappings']
            elif 'extra_metrics' in data:
                # æ£€æŸ¥extra_metricsä¸­çš„IPæ˜ å°„ï¼ˆæ–°Pipelineç³»ç»Ÿï¼‰
                extra_metrics = data['extra_metrics']
                if 'file_ip_mappings' in extra_metrics:
                    ip_mappings = extra_metrics['file_ip_mappings']
                elif 'ip_mappings' in extra_metrics:
                    ip_mappings = extra_metrics['ip_mappings']
            
            if ip_mappings and isinstance(ip_mappings, dict):
                # ä¿å­˜æ–‡ä»¶çº§IPæ˜ å°„
                if not hasattr(self.main_window, '_current_file_ips'):
                    self.main_window._current_file_ips = {}
                self.main_window._current_file_ips[self.main_window.current_processing_file] = ip_mappings
                
                # **å…³é”®ä¿®å¤**: å°†å½“å‰æ–‡ä»¶çš„IPæ˜ å°„ç´¯ç§¯åˆ°å…¨å±€æ˜ å°„ä¸­ï¼ˆä¸è¦†ç›–ï¼‰
                if not hasattr(self.main_window, 'global_ip_mappings') or self.main_window.global_ip_mappings is None:
                    self.main_window.global_ip_mappings = {}
                
                # ç´¯ç§¯æ˜ å°„è€Œä¸æ˜¯è¦†ç›–
                self.main_window.global_ip_mappings.update(ip_mappings)
                
                self._logger.info(f"âœ… æ”¶é›†IPæ˜ å°„: æ–‡ä»¶={self.main_window.current_processing_file}, æ–°æ˜ å°„={len(ip_mappings)}ä¸ª, å…¨å±€æ˜ å°„æ€»æ•°={len(self.main_window.global_ip_mappings)}ä¸ª")
            else:
                self._logger.warning(f"IPåŒ¿ååŒ–æ­¥éª¤å®Œæˆï¼Œä½†æœªæ‰¾åˆ°æœ‰æ•ˆçš„IPæ˜ å°„æ•°æ®: {list(data.keys())}")
        else:
            self._logger.debug(f"éIPåŒ¿ååŒ–æ­¥éª¤: {step_name_raw}")

    def _is_enhanced_trimming(self, data: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å¢å¼ºæ©ç å¤„ç†ç»“æœ - åŸºäºåŒæ¨¡å—æ¶æ„"""
        step_name = data.get('step_name', '')
        
        # æ£€æŸ¥Enhanced Trimmerç‰¹æœ‰çš„å­—æ®µç»„åˆ - å¿…é¡»æ˜¯çœŸæ­£çš„Enhanced Intelligent Mode
        enhanced_indicators = [
            'processing_mode' in data and data.get('processing_mode') == 'Enhanced Intelligent Mode',
            'protocol_stats' in data,
            'strategies_applied' in data,
            'enhancement_level' in data,
        ]
        
        # åè®®é€‚é…æ¨¡å¼æœ‰ä¸åŒçš„å¤„ç†æ¨¡å¼æ ‡è¯†ï¼Œä¸ä¼šæ˜¯ 'Enhanced Intelligent Mode'
        # å¦‚æœæœ‰çœŸæ­£çš„Enhanced Trimmerç‰¹æœ‰å­—æ®µç»„åˆï¼Œè®¤ä¸ºæ˜¯æ™ºèƒ½å¤„ç†
        return all(enhanced_indicators[:3])  # å‰3ä¸ªå­—æ®µå¿…é¡»éƒ½å­˜åœ¨

    def _generate_enhanced_trimming_report_line(self, step_name: str, data: Dict[str, Any]) -> str:
        """ç”ŸæˆEnhanced Trimmerçš„å¤„ç†ç»“æœæŠ¥å‘Šè¡Œï¼ˆç§»é™¤HTTPç»Ÿè®¡ï¼‰"""
        total = data.get('total_packets', 0)
        masked = data.get('trimmed_packets', 0)
        
        # è·å–åè®®ç»Ÿè®¡ï¼ˆç§»é™¤HTTPï¼‰
        protocol_stats = data.get('protocol_stats', {})
        tls_packets = protocol_stats.get('tls_packets', 0)
        other_packets = protocol_stats.get('other_packets', 0)
        
        # åŸºç¡€æŠ¥å‘Šè¡Œï¼ˆå¢å¼ºæ¨¡å¼æ ‡è¯†ï¼‰
        rate = (masked / total * 100) if total > 0 else 0
        line = f"  âœ‚ï¸  {step_name:<18} | Enhanced Mode | Total: {total:>4} | Masked: {masked:>4} | Rate: {rate:5.1f}%"
        
        return line

    def _generate_enhanced_trimming_report(self, separator_length: int, is_partial: bool = False) -> Optional[str]:
        """ç”ŸæˆEnhanced Trimmerçš„æ™ºèƒ½å¤„ç†ç»Ÿè®¡æ€»æŠ¥å‘Šï¼ˆç§»é™¤HTTPæ”¯æŒï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰Enhanced Trimmerå¤„ç†çš„æ–‡ä»¶
        enhanced_files = []
        total_enhanced_stats = {
            'total_packets': 0,
            'tls_packets': 0,
            'other_packets': 0,
            'strategies_applied': set(),
            'files_processed': 0
        }
        
        # éå†æ‰€æœ‰å¤„ç†è¿‡çš„æ–‡ä»¶ï¼Œæ‰¾å‡ºä½¿ç”¨Enhanced Trimmerçš„æ–‡ä»¶
        for filename, file_result in self.main_window.file_processing_results.items():
            steps_data = file_result.get('steps', {})
            payload_step = steps_data.get('Payload Masking')
            
            if payload_step and self._is_enhanced_trimming(payload_step.get('data', {})):
                enhanced_files.append(filename)
                data = payload_step['data']
                
                # æ±‡æ€»ç»Ÿè®¡ï¼ˆç§»é™¤HTTPï¼‰
                total_enhanced_stats['files_processed'] += 1
                total_enhanced_stats['total_packets'] += data.get('total_packets', 0)
                
                protocol_stats = data.get('protocol_stats', {})
                total_enhanced_stats['tls_packets'] += protocol_stats.get('tls_packets', 0)
                total_enhanced_stats['other_packets'] += protocol_stats.get('other_packets', 0)
                
                strategies = data.get('strategies_applied', [])
                total_enhanced_stats['strategies_applied'].update(strategies)
        
        # å¦‚æœæ²¡æœ‰Enhanced Trimmerå¤„ç†ï¼Œè¿”å›None
        if not enhanced_files:
            return None
        
        # ç”Ÿæˆæ™ºèƒ½å¤„ç†æ€»æŠ¥å‘Š
        title = "ğŸ§  ENHANCED TRIMMING INTELLIGENCE REPORT"
        if is_partial:
            title += " (Partial)"
        
        report = f"\n{'='*separator_length}\n{title}\n{'='*separator_length}\n"
        
        # å¤„ç†æ¨¡å¼å’Œå¢å¼ºä¿¡æ¯
        report += f"ğŸ¯ Processing Mode: Intelligent Auto-Detection\n"
        report += f"âš¡ Enhancement Level: 4x accuracy improvement over simple trimming\n"
        report += f"ğŸ“ Enhanced Files: {total_enhanced_stats['files_processed']}/{len(self.main_window.file_processing_results)}\n\n"
        
        # åè®®æ£€æµ‹ç»Ÿè®¡ï¼ˆç§»é™¤HTTPï¼‰
        total_packets = total_enhanced_stats['total_packets']
        if total_packets > 0:
            tls_rate = (total_enhanced_stats['tls_packets'] / total_packets) * 100
            other_rate = (total_enhanced_stats['other_packets'] / total_packets) * 100
            
            report += f"ğŸ“Š Protocol Detection Results:\n"
            report += f"   â€¢ TLS packets: {total_enhanced_stats['tls_packets']:,} ({tls_rate:.1f}%) - æ™ºèƒ½TLSç­–ç•¥\n"
            report += f"   â€¢ Other packets: {total_enhanced_stats['other_packets']:,} ({other_rate:.1f}%) - é€šç”¨ç­–ç•¥\n"
            report += f"   â€¢ Total processed: {total_packets:,} packets in 4 stages\n\n"
        
        # ç­–ç•¥åº”ç”¨ç»Ÿè®¡
        strategies_list = list(total_enhanced_stats['strategies_applied'])
        if strategies_list:
            report += f"ğŸ”§ Applied Strategies:\n"
            for strategy in sorted(strategies_list):
                report += f"   â€¢ {strategy}\n"
            report += "\n"
        
        # æ™ºèƒ½å¤„ç†ä¼˜åŠ¿è¯´æ˜ï¼ˆç§»é™¤HTTPï¼‰
        report += f"ğŸš€ Enhanced Processing Benefits:\n"
        report += f"   â€¢ Automatic protocol detection and strategy selection\n"
        report += f"   â€¢ TLS handshake preserved, ApplicationData masked\n"
        report += f"   â€¢ Improved accuracy while maintaining network analysis capability\n"
        
        report += f"{'='*separator_length}\n"
        
        return report

    def _generate_enhanced_trimming_report_for_file(self, filename: str, separator_length: int) -> Optional[str]:
        """ä¸ºå•ä¸ªæ–‡ä»¶ç”ŸæˆEnhanced Trimmerçš„å¤„ç†ç»“æœæŠ¥å‘Šï¼ˆç§»é™¤HTTPç»Ÿè®¡ï¼‰"""
        if filename not in self.main_window.file_processing_results:
            return None
        
        file_result = self.main_window.file_processing_results[filename]
        steps_data = file_result.get('steps', {})
        payload_step = steps_data.get('Payload Masking')
        
        if not payload_step or not self._is_enhanced_trimming(payload_step.get('data', {})):
            return None
        
        data = payload_step['data']
        protocol_stats = data.get('protocol_stats', {})
        
        report = f"\nğŸ§  Enhanced Trimming Details for {filename}:\n"
        report += f"   ğŸ“Š Protocol Analysis:\n"
        
        total_packets = data.get('total_packets', 0)
        if total_packets > 0:
            tls_packets = protocol_stats.get('tls_packets', 0)
            other_packets = protocol_stats.get('other_packets', 0)
            
            if tls_packets > 0:
                tls_rate = (tls_packets / total_packets) * 100
                report += f"      â€¢ TLS: {tls_packets} packets ({tls_rate:.1f}%) - Handshake preserved\n"
            
            if other_packets > 0:
                other_rate = (other_packets / total_packets) * 100
                report += f"      â€¢ Other: {other_packets} packets ({other_rate:.1f}%) - Generic strategy\n"
        
        # ç­–ç•¥åº”ç”¨ä¿¡æ¯
        strategies = data.get('strategies_applied', [])
        if strategies:
            report += f"   ğŸ”§ Applied Strategies: {', '.join(strategies)}\n"
        
        # å¤„ç†æ•ˆç‡
        enhancement_level = data.get('enhancement_level', 'Not specified')
        report += f"   âš¡ Enhancement: {enhancement_level}\n"
        
        return report

    def _generate_enhanced_trimming_report_for_directory(self, separator_length: int) -> Optional[str]:
        """ç”Ÿæˆæ•´ä¸ªç›®å½•çš„Enhanced Trimmerçš„å¤„ç†ç»“æœæŠ¥å‘Š"""
        # è¿™ä¸ªæ–¹æ³•åœ¨ç›®å½•çº§åˆ«å¤„ç†å®Œæˆæ—¶è°ƒç”¨
        # ç›®å‰å…ˆè¿”å›é€šç”¨çš„EnhancedæŠ¥å‘Š
        return self._generate_enhanced_trimming_report(separator_length, is_partial=False) 