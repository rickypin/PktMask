#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆçœŸå®æ•°æ®æµ‹è¯•è¿è¡Œå™¨
æ‰§è¡Œå®Œæ•´çš„IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•
"""

import sys
import time
import argparse
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from tests.integration.test_enhanced_real_data_validation import (
    EnhancedRealDataValidator, 
    EnhancedTestResult
)


class EnhancedTestRunner:
    """å¢å¼ºç‰ˆæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.validator = EnhancedRealDataValidator()
        self.test_samples = [
            # åŸºç¡€å°è£…ç±»å‹
            ("tests/data/samples/TLS/tls_sample.pcap", "plain_ip", "Plain IP æ ·æœ¬"),
            ("tests/data/samples/singlevlan/10.200.33.61(10ç¬”).pcap", "single_vlan", "Single VLAN æ ·æœ¬"),
            ("tests/data/samples/doublevlan/172.24.0.51.pcap", "double_vlan", "Double VLAN æ ·æœ¬"),
            ("tests/data/samples/mpls/mpls.pcap", "mpls", "MPLS æ ·æœ¬"),
            ("tests/data/samples/vxlan/vxlan.pcap", "vxlan", "VXLAN æ ·æœ¬"),
            
            # æ‰©å±•å°è£…ç±»å‹
            ("tests/data/samples/gre/20160406152100.pcap", "gre", "GRE æ ·æœ¬"),
            ("tests/data/samples/vlan_gre/case17-parts.pcap", "vlan_gre", "VLAN+GRE å¤åˆæ ·æœ¬"),
            ("tests/data/samples/vxlan_vlan/vxlan_servicetag_1001.pcap", "vxlan_vlan", "VXLAN+VLAN å¤åˆæ ·æœ¬"),
            ("tests/data/samples/TLS70/sslerr1-70.pcap", "tls70", "TLS70 æ ·æœ¬"),
            ("tests/data/samples/doublevlan_tls/TC-007-3-20230829-01.pcap", "doublevlan_tls", "Double VLAN + TLS æ ·æœ¬"),
            
            # å‰©ä½™æ¡ˆä¾‹è¦†ç›–
            ("tests/data/samples/IPTCP-200ips/TC-002-6-20200927-S-A-Replaced.pcapng", "large_dataset", "200 IPå¤§æ•°æ®é›†æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-001-1-20160407/TC-001-1-20160407-A.pcap", "test_case_001", "æµ‹è¯•ç”¨ä¾‹001æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-002-5-20220215/TC-002-5-20220215-FW-in.pcap", "test_case_002_5", "æµ‹è¯•ç”¨ä¾‹002-5æ ·æœ¬"),
            ("tests/data/samples/IPTCP-TC-002-8-20210817/TC-002-8-20210817.pcapng", "test_case_002_8", "æµ‹è¯•ç”¨ä¾‹002-8æ ·æœ¬"),
            ("tests/data/samples/vxlan4787/vxlan-double-http.pcap", "vxlan4787", "VXLAN4787å˜ç§æ ·æœ¬"),
        ]
    
    def run_enhanced_validation(self, mode: str = "standard") -> Dict[str, Any]:
        """è¿è¡Œå¢å¼ºç‰ˆéªŒè¯æµ‹è¯•"""
        print("ğŸš€ å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•")
        print("=" * 60)
        print("ğŸ“‹ æµ‹è¯•å†…å®¹:")
        print("   âœ“ å°è£…æ£€æµ‹éªŒè¯")
        print("   âœ“ IPåœ°å€æå–éªŒè¯")  
        print("   âœ“ IPåŒ¿ååŒ–å¤„ç†éªŒè¯")
        print("   âœ“ æ˜ å°„ä¸€è‡´æ€§éªŒè¯")
        print("   âœ“ æ•°é‡ä¿æŒéªŒè¯")
        print("   âœ“ åŒ¿åIPæœ‰æ•ˆæ€§éªŒè¯")
        print("   âœ“ è¦†ç›–ç‡éªŒè¯ (â‰¥95%)")
        print("=" * 60)
        
        start_time = time.time()
        results = []
        
        # è¿è¡Œæµ‹è¯•
        for sample_file, category, description in self.test_samples:
            sample_path = Path(sample_file)
            
            if not sample_path.exists():
                print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„æ ·æœ¬: {sample_file}")
                continue
            
            print(f"\nğŸ§ª æµ‹è¯•: {description}")
            print(f"   ğŸ“ æ–‡ä»¶: {sample_path.name}")
            print(f"   ğŸ·ï¸  ç±»åˆ«: {category}")
            
            result = self.validator.validate_sample_file_with_anonymization(
                sample_path, category, max_test_packets=50 if mode == "quick" else 100
            )
            
            results.append(result)
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            if result.success:
                print(f"   âœ… æˆåŠŸ")
                print(f"   ğŸ“Š ç»Ÿè®¡: {result.tested_packets}åŒ…, {len(result.original_ips)}IP, {len(result.ip_mappings)}æ˜ å°„")
                print(f"   ğŸ¯ æŒ‡æ ‡: è¦†ç›–{result.anonymization_coverage:.1%}, å”¯ä¸€{result.unique_mapping_ratio:.1%}")
                print(f"   â±ï¸  è€—æ—¶: {result.processing_time:.3f}s")
            else:
                print(f"   âŒ å¤±è´¥")
                for error in result.errors[:2]:
                    print(f"      â€¢ {error}")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_summary_report(results, time.time() - start_time)
        
        return {
            "total_tests": len(results),
            "successful_tests": len([r for r in results if r.success]),
            "results": results
        }
    
    def run_consistency_test(self) -> bool:
        """è¿è¡Œä¸€è‡´æ€§æµ‹è¯•"""
        print("\nğŸ”„ æ˜ å°„ä¸€è‡´æ€§æµ‹è¯•")
        print("-" * 40)
        
        sample_file = Path("tests/data/samples/TLS/tls_sample.pcap")
        if not sample_file.exists():
            print("âš ï¸  æµ‹è¯•æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶: {sample_file.name}")
        print("ğŸ” æ‰§è¡Œä¸¤æ¬¡åŒ¿ååŒ–å¹¶æ¯”è¾ƒæ˜ å°„...")
        
        # æ‰§è¡Œä¸¤æ¬¡æµ‹è¯•
        result1 = self.validator.validate_sample_file_with_anonymization(sample_file, "plain_ip")
        result2 = self.validator.validate_sample_file_with_anonymization(sample_file, "plain_ip")
        
        if not (result1.success and result2.success):
            print("âŒ åŸºç¡€æµ‹è¯•å¤±è´¥")
            return False
        
        # æ£€æŸ¥æ˜ å°„ä¸€è‡´æ€§
        common_ips = result1.original_ips & result2.original_ips
        inconsistent_count = 0
        
        for ip in common_ips:
            if ip in result1.ip_mappings and ip in result2.ip_mappings:
                if result1.ip_mappings[ip] != result2.ip_mappings[ip]:
                    inconsistent_count += 1
                    if inconsistent_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"âŒ ä¸ä¸€è‡´: {ip} -> {result1.ip_mappings[ip]} vs {result2.ip_mappings[ip]}")
        
        if inconsistent_count == 0:
            print(f"âœ… ä¸€è‡´æ€§éªŒè¯é€šè¿‡: {len(common_ips)} ä¸ªIPæ˜ å°„å®Œå…¨ä¸€è‡´")
            return True
        else:
            print(f"âŒ ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {inconsistent_count} ä¸ªIPæ˜ å°„ä¸ä¸€è‡´")
            return False
    
    def _generate_summary_report(self, results: List[EnhancedTestResult], total_time: float):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å¢å¼ºéªŒè¯æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        
        # åŸºç¡€ç»Ÿè®¡
        total_tests = len(results)
        successful_tests = len([r for r in results if r.success])
        success_rate = successful_tests / total_tests if total_tests > 0 else 0
        
        print(f"ğŸ¯ æ€»ä½“ç»“æœ:")
        print(f"   æµ‹è¯•æ€»æ•°: {total_tests}")
        print(f"   æˆåŠŸæ•°é‡: {successful_tests}")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   æ€»è€—æ—¶: {total_time:.3f}s")
        
        # è¯¦ç»†éªŒè¯æŒ‡æ ‡
        if results:
            avg_coverage = sum(r.anonymization_coverage for r in results) / len(results)
            avg_uniqueness = sum(r.unique_mapping_ratio for r in results) / len(results)
            total_ips = sum(len(r.original_ips) for r in results)
            total_mappings = sum(len(r.ip_mappings) for r in results)
            
            print(f"\nğŸ“ˆ éªŒè¯æŒ‡æ ‡:")
            print(f"   å¹³å‡è¦†ç›–ç‡: {avg_coverage:.1%}")
            print(f"   å¹³å‡å”¯ä¸€æ€§: {avg_uniqueness:.1%}")
            print(f"   æ€»IPæ•°é‡: {total_ips}")
            print(f"   æ€»æ˜ å°„æ•°: {total_mappings}")
        
        # éªŒè¯ç»´åº¦ç»Ÿè®¡
        validation_stats = {
            "mapping_consistency": 0,
            "ip_count_preserved": 0,
            "anonymized_ip_validity": 0,
            "high_coverage": 0
        }
        
        for result in results:
            if result.mapping_consistency:
                validation_stats["mapping_consistency"] += 1
            if result.ip_count_preserved:
                validation_stats["ip_count_preserved"] += 1
            if result.anonymized_ip_validity:
                validation_stats["anonymized_ip_validity"] += 1
            if result.anonymization_coverage >= 0.95:
                validation_stats["high_coverage"] += 1
        
        print(f"\nğŸ” éªŒè¯ç»´åº¦é€šè¿‡ç‡:")
        for metric, count in validation_stats.items():
            rate = count / total_tests if total_tests > 0 else 0
            status = "âœ…" if rate >= 0.8 else "âŒ"
            print(f"   {status} {metric}: {rate:.1%} ({count}/{total_tests})")
        
        # å¤±è´¥è¯¦æƒ…
        failed_results = [r for r in results if not r.success]
        if failed_results:
            print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
            for result in failed_results:
                print(f"   â€¢ {Path(result.file_path).name} ({result.category})")
                for error in result.errors[:2]:
                    print(f"     - {error}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        self._save_json_report(results, total_time)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: reports/enhanced_validation_report.json")
    
    def _save_json_report(self, results: List[EnhancedTestResult], total_time: float):
        """ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        import json
        
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        report_data = {
            "test_summary": {
                "total_tests": len(results),
                "successful_tests": len([r for r in results if r.success]),
                "success_rate": len([r for r in results if r.success]) / len(results) if results else 0,
                "total_time": total_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "validation_metrics": {
                "average_coverage": sum(r.anonymization_coverage for r in results) / len(results) if results else 0,
                "average_uniqueness": sum(r.unique_mapping_ratio for r in results) / len(results) if results else 0,
                "total_original_ips": sum(len(r.original_ips) for r in results),
                "total_mappings": sum(len(r.ip_mappings) for r in results)
            },
            "test_results": [
                {
                    "file_path": result.file_path,
                    "category": result.category,
                    "success": result.success,
                    "processing_time": result.processing_time,
                    "original_ip_count": len(result.original_ips),
                    "anonymized_ip_count": len(result.anonymized_ips),
                    "mapping_count": len(result.ip_mappings),
                    "mapping_consistency": result.mapping_consistency,
                    "ip_count_preserved": result.ip_count_preserved,
                    "anonymized_ip_validity": result.anonymized_ip_validity,
                    "anonymization_coverage": result.anonymization_coverage,
                    "unique_mapping_ratio": result.unique_mapping_ratio,
                    "encapsulation_stats": result.encapsulation_stats,
                    "errors": result.errors,
                    "validation_details": result.validation_details
                }
                for result in results
            ]
        }
        
        with open(reports_dir / "enhanced_validation_report.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)


def run_payload_trimming_tests():
    """è¿è¡Œè½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸ¯ è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•")
    print("="*60)
    
    try:
        import subprocess
        
        # è¿è¡Œè½½è·è£åˆ‡éªŒè¯æµ‹è¯•
        cmd = [
            'python', '-m', 'pytest', 
            'tests/integration/test_enhanced_real_data_validation.py::TestPayloadTrimmingValidation',
            '-v', '--tb=short', '-x'
        ]
        
        print(f"ğŸ“‹ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
            print("\nğŸ“Š æµ‹è¯•è¾“å‡º:")
            print(result.stdout)
        else:
            print("âŒ è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•å¤±è´¥")
            print("\né”™è¯¯è¾“å‡º:")
            print(result.stderr)
            print("\næ ‡å‡†è¾“å‡º:")
            print(result.stdout)
            return False
            
    except Exception as e:
        print(f"âŒ è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        return False
    
    return True


def run_all_enhanced_tests():
    """è¿è¡Œæ‰€æœ‰å¢å¼ºéªŒè¯æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸ¯ å®Œæ•´å¢å¼ºéªŒè¯æµ‹è¯•å¥—ä»¶")
    print("="*60)
    
    all_success = True
    
    # 1. IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•
    print("\n1ï¸âƒ£ IPåŒ¿ååŒ–åŠŸèƒ½éªŒè¯...")
    runner = EnhancedTestRunner()
    try:
        test_summary = runner.run_enhanced_validation("standard")
        success_rate = test_summary["successful_tests"] / test_summary["total_tests"]
        if success_rate < 0.8:
            all_success = False
            print("âŒ IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•å¤±è´¥")
        else:
            print("âœ… IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ IPåŒ¿ååŒ–éªŒè¯æµ‹è¯•å¼‚å¸¸: {e}")
        all_success = False
    
    # 2. è½½è·è£åˆ‡éªŒè¯æµ‹è¯•
    print("\n2ï¸âƒ£ è½½è·è£åˆ‡åŠŸèƒ½éªŒè¯...")
    if not run_payload_trimming_tests():
        all_success = False
        print("âŒ è½½è·è£åˆ‡éªŒè¯æµ‹è¯•å¤±è´¥")
    else:
        print("âœ… è½½è·è£åˆ‡éªŒè¯æµ‹è¯•é€šè¿‡")
    
    print("\n" + "="*60)
    if all_success:
        print("ğŸ‰ æ‰€æœ‰å¢å¼ºéªŒè¯æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        print("âœ… IPåŒ¿ååŒ–åŠŸèƒ½: 100%éªŒè¯é€šè¿‡")
        print("âœ… è½½è·è£åˆ‡åŠŸèƒ½: 100%éªŒè¯é€šè¿‡")
        print("âœ… å¤šå±‚å°è£…æ”¯æŒ: å®Œæ•´è¦†ç›–")
        print("ğŸ† PktMaskå¢å¼ºåŠŸèƒ½éªŒè¯å®Œæˆ!")
    else:
        print("âŒ éƒ¨åˆ†å¢å¼ºéªŒè¯æµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤ç›¸å…³é—®é¢˜")
    
    return all_success


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆçœŸå®æ•°æ®éªŒè¯æµ‹è¯•")
    parser.add_argument("--mode", choices=["quick", "standard", "full"], default="standard",
                       help="æµ‹è¯•æ¨¡å¼: quick(å¿«é€Ÿ), standard(æ ‡å‡†), full(å®Œæ•´)")
    parser.add_argument("--consistency", action="store_true",
                       help="æ‰§è¡Œå¤šæ¬¡è¿è¡Œçš„æ˜ å°„ä¸€è‡´æ€§éªŒè¯")
    parser.add_argument('--payload-trimming', action='store_true',
                        help='æ‰§è¡Œè½½è·è£åˆ‡åŠŸèƒ½éªŒè¯æµ‹è¯•')
    parser.add_argument('--all', action='store_true',
                        help='æ‰§è¡Œæ‰€æœ‰å¢å¼ºéªŒè¯æµ‹è¯•ï¼ˆIPåŒ¿ååŒ– + è½½è·è£åˆ‡ï¼‰')
    
    args = parser.parse_args()
    
    try:
        if args.payload_trimming:
            print(f"âœ‚ï¸ è½½è·è£åˆ‡éªŒè¯æ¨¡å¼ï¼šæµ‹è¯•æ‰€æœ‰15ä¸ªæ ·æœ¬çš„è½½è·è£åˆ‡åŠŸèƒ½")
            success = run_payload_trimming_tests()
        elif args.all:
            print(f"ğŸ¯ å®Œæ•´å¢å¼ºéªŒè¯æ¨¡å¼ï¼šIPåŒ¿ååŒ– + è½½è·è£åˆ‡åŠŸèƒ½")
            success = run_all_enhanced_tests()
        else:
            # é»˜è®¤è¿è¡ŒIPåŒ¿ååŒ–éªŒè¯
            print(f"ğŸ”’ IPåŒ¿ååŒ–éªŒè¯æ¨¡å¼ï¼šæµ‹è¯•æ‰€æœ‰15ä¸ªæ ·æœ¬çš„IPåŒ¿ååŒ–åŠŸèƒ½")
            runner = EnhancedTestRunner()
            
            # è¿è¡Œä¸»è¦éªŒè¯æµ‹è¯•
            test_summary = runner.run_enhanced_validation(args.mode)
            
            # è¿è¡Œä¸€è‡´æ€§æµ‹è¯•ï¼ˆå¦‚æœè¯·æ±‚ï¼‰
            consistency_passed = True
            if args.consistency:
                consistency_passed = runner.run_consistency_test()
            
            # åˆ¤æ–­æ€»ä½“ç»“æœ
            success_rate = test_summary["successful_tests"] / test_summary["total_tests"]
            success = success_rate >= 0.8 and consistency_passed
        
        print(f"\nğŸ¯ æœ€ç»ˆç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if success else 'âŒ å­˜åœ¨å¤±è´¥'}")
        return 0 if success else 1
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {str(e)}")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 