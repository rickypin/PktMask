#!/usr/bin/env python3
"""
æ™ºèƒ½å¯¼å…¥è¯­å¥æ›´æ–°å·¥å…·
ä¿æŒå‘åå…¼å®¹ï¼Œé¿å…ç ´åæ€§å˜æ›´
"""

import re
import os
from pathlib import Path
from typing import Dict, List, Set, Tuple

class SmartImportUpdater:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)

        # ä¿å®ˆçš„å¯¼å…¥æ˜ å°„ - åªæ›´æ–°æ˜ç¡®éœ€è¦çš„
        self.import_mappings = {
            # åŸºç±»å¯¼å…¥æ›´æ–°
            'from pktmask.core.base_step import ProcessingStep':
                'from pktmask.core.unified_stage import StageBase',
            'from ..core.base_step import ProcessingStep':
                'from ..core.unified_stage import StageBase',
            'from ...core.base_step import ProcessingStep':
                'from ...core.unified_stage import StageBase',
            
            # é€‚é…å™¨å¯¼å…¥æ›´æ–°
            'from pktmask.adapters.processor_adapter import PipelineProcessorAdapter':
                'from pktmask.core.unified_stage import StageBase',
            'from ..adapters.processor_adapter import PipelineProcessorAdapter':
                'from ..core.unified_stage import StageBase',
        }

        # ç±»ç»§æ‰¿æ˜ å°„ - æ›´ä¿å®ˆ
        self.class_mappings = {
            'ProcessingStep': 'StageBase',
            'PipelineProcessorAdapter': 'StageBase'
        }

        # éœ€è¦è·³è¿‡çš„æ–‡ä»¶ - é¿å…ç ´åå…¼å®¹å±‚
        self.skip_patterns = {
            '__pycache__',
            '.git',
            'backup',
            'migration_backups',
            'tools/',
            'reports/',
            'src/pktmask/core/base_step.py',  # ä¿ç•™å…¼å®¹å±‚
            'src/pktmask/adapters/compatibility/',  # ä¿ç•™å…¼å®¹é€‚é…å™¨
            'src/pktmask/core/unified_stage.py',  # è·³è¿‡æ–°çš„åŸºç±»æ–‡ä»¶
        }

    def update_all_files(self) -> Dict[str, int]:
        """æ›´æ–°æ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥è¯­å¥"""
        results = {'files_updated': 0, 'imports_updated': 0, 'classes_updated': 0}

        print("ğŸ”„ å¼€å§‹æ™ºèƒ½å¯¼å…¥æ›´æ–°...")

        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue

            updates = self._update_file(py_file)
            if updates['total'] > 0:
                results['files_updated'] += 1
                results['imports_updated'] += updates['imports']
                results['classes_updated'] += updates['classes']

        return results

    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        file_str = str(file_path)
        return any(pattern in file_str for pattern in self.skip_patterns)

    def _update_file(self, file_path: Path) -> Dict[str, int]:
        """æ›´æ–°å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content
            import_updates = 0
            class_updates = 0

            # æ›´æ–°å¯¼å…¥è¯­å¥
            for old_import, new_import in self.import_mappings.items():
                if old_import in content:
                    content = content.replace(old_import, new_import)
                    import_updates += 1
                    print(f"  ğŸ“¦ æ›´æ–°å¯¼å…¥: {file_path.relative_to(self.project_root)}")

            # æ›´æ–°ç±»ç»§æ‰¿
            for old_class, new_class in self.class_mappings.items():
                # åŒ¹é…ç±»ç»§æ‰¿æ¨¡å¼
                pattern = rf'class\s+(\w+)\s*\(\s*{re.escape(old_class)}\s*\)'
                replacement = rf'class \1({new_class})'

                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content)
                    class_updates += 1
                    print(f"  ğŸ—ï¸  æ›´æ–°ç±»ç»§æ‰¿: {file_path.relative_to(self.project_root)}")

            # å¦‚æœæœ‰æ›´æ–°ï¼Œå†™å›æ–‡ä»¶
            total_updates = import_updates + class_updates
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)

            return {
                'imports': import_updates,
                'classes': class_updates,
                'total': total_updates
            }

        except Exception as e:
            print(f"âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {'imports': 0, 'classes': 0, 'total': 0}

    def update_gui_pipeline_manager(self) -> List[str]:
        """ä¸“é—¨æ›´æ–°GUI Pipeline Manager"""
        changes = []
        
        pipeline_manager_path = self.project_root / "src/pktmask/gui/managers/pipeline_manager.py"
        if not pipeline_manager_path.exists():
            return ["Pipeline Manageræ–‡ä»¶ä¸å­˜åœ¨"]

        try:
            with open(pipeline_manager_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content

            # æ›´æ–°å¯¼å…¥è¯­å¥ - ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¶æ„
            import_updates = [
                ('from pktmask.core.pipeline.executor import PipelineExecutor',
                 'from pktmask.core.unified_stage import ModernPipelineExecutor'),
                ('from pktmask.core.pipeline.models import PipelineConfig',
                 'from pktmask.core.unified_stage import PipelineConfig'),
            ]

            for old_import, new_import in import_updates:
                if old_import in content:
                    content = content.replace(old_import, new_import)
                    changes.append(f"æ›´æ–°å¯¼å…¥: {old_import} -> {new_import}")

            # æ›´æ–°ç±»åå¼•ç”¨
            class_updates = [
                ('PipelineExecutor', 'ModernPipelineExecutor'),
            ]

            for old_class, new_class in class_updates:
                # åªæ›¿æ¢ç±»å®ä¾‹åŒ–å’Œç±»å‹æ³¨è§£
                patterns = [
                    (rf'\b{old_class}\s*\(', f'{new_class}('),
                    (rf':\s*{old_class}\b', f': {new_class}'),
                    (rf'=\s*{old_class}\s*\(', f'= {new_class}('),
                ]

                for pattern, replacement in patterns:
                    if re.search(pattern, content):
                        content = re.sub(pattern, replacement, content)
                        changes.append(f"æ›´æ–°ç±»å¼•ç”¨: {old_class} -> {new_class}")

            # å¦‚æœæœ‰æ›´æ–°ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(pipeline_manager_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                changes.append("Pipeline Manageræ›´æ–°å®Œæˆ")
            else:
                changes.append("Pipeline Manageræ— éœ€æ›´æ–°")

        except Exception as e:
            changes.append(f"Pipeline Manageræ›´æ–°å¤±è´¥: {e}")

        return changes

    def create_compatibility_wrapper(self) -> List[str]:
        """åˆ›å»ºå…¼å®¹æ€§åŒ…è£…å™¨"""
        changes = []

        # æ›´æ–° base_step.py ä»¥æä¾›æ›´å¥½çš„å…¼å®¹æ€§
        base_step_path = self.project_root / "src/pktmask/core/base_step.py"
        if base_step_path.exists():
            try:
                compatibility_content = '''import abc
import warnings
from pathlib import Path
from typing import Optional, Dict, List, Union

from .unified_stage import StageBase, StageStats


class ProcessingStep(StageBase):
    """
    ProcessingStep å…¼å®¹æ€§åŒ…è£…
    
    ï¼ï¼ï¼è¿ç§»æç¤ºï¼ï¼ï¼
    è¿™ä¸ªç±»æ˜¯ä¸ºäº†å…¼å®¹æ—§çš„ ProcessingStep æ¥å£è€Œä¿ç•™çš„ã€‚
    æ¨èæ–°ä»£ç ç›´æ¥ç»§æ‰¿ StageBaseã€‚
    
    ç°æœ‰çš„ ProcessingStep å­ç±»å¯ä»¥ï¼š
    1. æš‚æ—¶ç»§ç»­ä½¿ç”¨è¿™ä¸ªå…¼å®¹å±‚
    2. å°† process_file æ–¹æ³•é‡å‘½åä¸º process_file_legacy
    3. æœ€ç»ˆè¿ç§»åˆ°ç›´æ¥ç»§æ‰¿ StageBase
    """
    
    # ä¿æŒæ—§çš„ suffix å±æ€§ä»¥å…¼å®¹
    suffix: str = ""
    
    def __init__(self, config: Optional[Dict] = None):
        super().__init__(config)
        # å‘å‡ºè¿ç§»æç¤ºï¼ˆä»…åœ¨ç¬¬ä¸€æ¬¡åˆ›å»ºå®ä¾‹æ—¶ï¼‰
        if not hasattr(self.__class__, '_migration_warning_shown'):
            warnings.warn(
                f"{self.__class__.__name__} ç»§æ‰¿è‡ª ProcessingStepï¼ˆå…¼å®¹å±‚ï¼‰ã€‚"
                "æ¨èè¿ç§»åˆ°ç›´æ¥ç»§æ‰¿ StageBase ä»¥è·å¾—æ›´å¥½çš„åŠŸèƒ½ã€‚",
                FutureWarning,
                stacklevel=2
            )
            self.__class__._migration_warning_shown = True
    
    def process_file(self, input_path: Union[str, Path], output_path: Union[str, Path]) -> Union[StageStats, Dict, None]:
        """ç»Ÿä¸€çš„å¤„ç†æ–¹æ³• - å…¼å®¹æ–°æ—§æ¥å£"""
        
        # å°è¯•è°ƒç”¨æ–°çš„æ–¹æ³•ï¼ˆå¦‚æœå­ç±»å·²ç»è¿ç§»ï¼‰
        if hasattr(self, 'process_file_legacy'):
            # å­ç±»æä¾›äº† legacy æ–¹æ³•ï¼Œä½¿ç”¨å®ƒ
            result = self.process_file_legacy(str(input_path), str(output_path))
            return self._convert_legacy_result_to_stage_stats(result)
        
        # å¦‚æœå­ç±»é‡å†™äº† process_fileï¼Œç›´æ¥è°ƒç”¨
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªæŠ€å·§æ¥æ£€æµ‹å­ç±»æ˜¯å¦é‡å†™äº† process_file
        child_method = getattr(type(self), 'process_file', None)
        if child_method and child_method is not ProcessingStep.process_file:
            # å­ç±»é‡å†™äº† process_fileï¼Œä½†æˆ‘ä»¬éœ€è¦é¿å…æ— é™é€’å½’
            # è¿™ç§æƒ…å†µä¸‹ï¼Œå‡è®¾å­ç±»æœŸæœ›æ—§çš„æ¥å£
            result = self._call_legacy_process_file(str(input_path), str(output_path))
            return self._convert_legacy_result_to_stage_stats(result)
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼ŒæŠ›å‡ºé”™è¯¯
        raise NotImplementedError(
            f"{self.__class__.__name__} å¿…é¡»å®ç° process_file_legacy æ–¹æ³•ï¼Œ"
            "æˆ–è€…ç›´æ¥ç»§æ‰¿ StageBase å¹¶å®ç°æ–°çš„ process_file æ–¹æ³•ã€‚"
        )
    
    def _call_legacy_process_file(self, input_path: str, output_path: str) -> Optional[Dict]:
        """è°ƒç”¨å­ç±»çš„æ—§ç‰ˆ process_file æ–¹æ³•"""
        # è¿™é‡Œéœ€è¦ä¸€ä¸ªå·§å¦™çš„æ–¹æ³•æ¥è°ƒç”¨å­ç±»çš„åŸå§‹ process_file
        # æˆ‘ä»¬ç›´æ¥æŸ¥æ‰¾å­ç±»çš„æ–¹æ³•å¹¶è°ƒç”¨
        for cls in type(self).__mro__[1:]:  # è·³è¿‡è‡ªå·±ï¼Œä»çˆ¶ç±»å¼€å§‹
            if hasattr(cls, 'process_file') and cls is not ProcessingStep:
                method = getattr(cls, 'process_file')
                if callable(method):
                    return method(self, input_path, output_path)
        return None
    
    def _convert_legacy_result_to_stage_stats(self, result: Optional[Dict]) -> Optional[StageStats]:
        """å°†æ—§æ ¼å¼ç»“æœè½¬æ¢ä¸ºæ–°çš„ StageStats"""
        if result is None:
            return None
        
        if isinstance(result, dict):
            return StageStats(
                stage_name=self.name,
                packets_processed=result.get('total_packets', 0),
                packets_modified=result.get('modified_packets', 0),
                duration_ms=result.get('duration_ms', 0.0),
                extra_metrics=result
            )
        
        return result
'''

                with open(base_step_path, 'w', encoding='utf-8') as f:
                    f.write(compatibility_content)
                
                changes.append("æ›´æ–°base_step.pyå…¼å®¹æ€§åŒ…è£…å™¨")

            except Exception as e:
                changes.append(f"æ›´æ–°base_step.pyå¤±è´¥: {e}")

        return changes

    def generate_update_report(self, results: Dict[str, int], gui_changes: List[str], 
                             compat_changes: List[str]) -> Dict[str, any]:
        """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
        return {
            "import_updates": {
                "files_updated": results['files_updated'],
                "imports_updated": results['imports_updated'],
                "classes_updated": results['classes_updated']
            },
            "gui_updates": gui_changes,
            "compatibility_updates": compat_changes,
            "recommendations": [
                "âœ… å¯¼å…¥è¯­å¥å·²æ›´æ–°åˆ°ç»Ÿä¸€æ¶æ„",
                "ğŸ”„ GUIç»„ä»¶å·²å‡†å¤‡å¥½ä½¿ç”¨æ–°æ¶æ„",
                "ğŸ›¡ï¸ å…¼å®¹æ€§åŒ…è£…å™¨å·²æ›´æ–°",
                "ğŸ“ å»ºè®®è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½å®Œæ•´æ€§"
            ]
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import sys
    import json
    
    project_root = sys.argv[1] if len(sys.argv) > 1 else "."
    updater = SmartImportUpdater(project_root)
    
    # æ‰§è¡Œå¯¼å…¥æ›´æ–°
    results = updater.update_all_files()
    
    # æ›´æ–°GUI Pipeline Manager
    gui_changes = updater.update_gui_pipeline_manager()
    
    # åˆ›å»ºå…¼å®¹æ€§åŒ…è£…å™¨
    compat_changes = updater.create_compatibility_wrapper()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = updater.generate_update_report(results, gui_changes, compat_changes)
    
    print(f"\nğŸ“Š å¯¼å…¥æ›´æ–°å®Œæˆ:")
    print(f"   - æ›´æ–°æ–‡ä»¶æ•°: {results['files_updated']}")
    print(f"   - æ›´æ–°å¯¼å…¥æ•°: {results['imports_updated']}")
    print(f"   - æ›´æ–°ç±»æ•°: {results['classes_updated']}")
    
    print(f"\nğŸ–¥ï¸  GUIæ›´æ–°:")
    for change in gui_changes:
        print(f"   - {change}")
    
    print(f"\nğŸ›¡ï¸ å…¼å®¹æ€§æ›´æ–°:")
    for change in compat_changes:
        print(f"   - {change}")
    
    # ä¿å­˜æŠ¥å‘Š
    output_file = "reports/import_update_report.json"
    os.makedirs("reports", exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
