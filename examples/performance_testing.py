#!/usr/bin/env python3
"""
ç‹¬ç«‹PCAPæ©ç å¤„ç†å™¨ - æ€§èƒ½æµ‹è¯•ç¤ºä¾‹

æœ¬ç¤ºä¾‹æä¾›äº†å®Œæ•´çš„æ€§èƒ½æµ‹è¯•æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼š
- æ€§èƒ½ç›‘æ§å™¨
- åŸºå‡†æµ‹è¯•å¥—ä»¶
- å†…å­˜ä½¿ç”¨åˆ†æ
- æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
- æ€§èƒ½å›å½’æµ‹è¯•

ä½œè€…: PktMaskå¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-06-22
"""

import os
import sys
import time
import json
import platform
import statistics
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple
from contextlib import contextmanager

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.pathä»¥ä¾¿å¯¼å…¥æ¨¡å—
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from pktmask.core.independent_pcap_masker import (
    IndependentPcapMasker,
    SequenceMaskTable, 
    MaskEntry, 
    MaskingResult
)


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    test_name: str
    file_name: str
    file_size: int
    total_packets: int
    modified_packets: int
    bytes_masked: int
    processing_time: float
    memory_before: float
    memory_after: float
    memory_peak: float
    cpu_usage: float
    success: bool
    error_message: Optional[str] = None
    
    @property
    def processing_speed_pps(self) -> float:
        """å¤„ç†é€Ÿåº¦ï¼ˆåŒ…/ç§’ï¼‰"""
        return self.total_packets / self.processing_time if self.processing_time > 0 else 0
    
    @property
    def memory_delta(self) -> float:
        """å†…å­˜å¢é•¿ï¼ˆMBï¼‰"""
        return self.memory_after - self.memory_before
    
    @property
    def bytes_per_second(self) -> float:
        """å­—èŠ‚å¤„ç†é€Ÿåº¦ï¼ˆB/sï¼‰"""
        return self.file_size / self.processing_time if self.processing_time > 0 else 0
    
    @property
    def modification_rate(self) -> float:
        """ä¿®æ”¹ç‡ï¼ˆ%ï¼‰"""
        return (self.modified_packets / self.total_packets * 100) if self.total_packets > 0 else 0


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics: List[PerformanceMetrics] = []
        self._psutil_available = self._check_psutil()
    
    def _check_psutil(self) -> bool:
        """æ£€æŸ¥psutilæ˜¯å¦å¯ç”¨"""
        try:
            import psutil
            return True
        except ImportError:
            print("âš ï¸  psutilæœªå®‰è£…ï¼Œå†…å­˜å’ŒCPUç›‘æ§åŠŸèƒ½å—é™")
            return False
    
    def get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        if self._psutil_available:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        return 0.0
    
    def get_cpu_usage(self) -> float:
        """è·å–CPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰"""
        if self._psutil_available:
            import psutil
            return psutil.cpu_percent(interval=0.1)
        return 0.0
    
    @contextmanager
    def monitor_test(self, test_name: str, file_path: str):
        """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
        
        # å¼€å§‹ç›‘æ§
        memory_before = self.get_memory_usage()
        cpu_before = self.get_cpu_usage()
        start_time = time.time()
        
        print(f"ğŸ å¼€å§‹æ€§èƒ½æµ‹è¯•: {test_name}")
        print(f"   æ–‡ä»¶: {os.path.basename(file_path)} ({file_size:,} bytes)")
        
        test_result = {
            "test_name": test_name,
            "file_name": os.path.basename(file_path),
            "file_size": file_size,
            "memory_before": memory_before,
            "start_time": start_time,
            "success": True,
            "error_message": None
        }
        
        try:
            yield test_result
        except Exception as e:
            test_result["success"] = False
            test_result["error_message"] = str(e)
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")
        finally:
            # ç»“æŸç›‘æ§
            end_time = time.time()
            memory_after = self.get_memory_usage()
            cpu_after = self.get_cpu_usage()
            
            processing_time = end_time - start_time
            memory_delta = memory_after - memory_before
            avg_cpu = (cpu_before + cpu_after) / 2
            
            print(f"â±ï¸  æµ‹è¯•å®Œæˆ: {test_name}")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.3f} ç§’")
            print(f"   å†…å­˜å¢é•¿: {memory_delta:+.2f} MB")
            print(f"   CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
            
            # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
            metrics = PerformanceMetrics(
                test_name=test_name,
                file_name=test_result["file_name"],
                file_size=file_size,
                total_packets=test_result.get("total_packets", 0),
                modified_packets=test_result.get("modified_packets", 0),
                bytes_masked=test_result.get("bytes_masked", 0),
                processing_time=processing_time,
                memory_before=memory_before,
                memory_after=memory_after,
                memory_peak=max(memory_before, memory_after),
                cpu_usage=avg_cpu,
                success=test_result["success"],
                error_message=test_result.get("error_message")
            )
            
            self.metrics.append(metrics)
            
            if metrics.success and metrics.total_packets > 0:
                print(f"   å¤„ç†é€Ÿåº¦: {metrics.processing_speed_pps:.1f} pps")
                print(f"   ä¿®æ”¹ç‡: {metrics.modification_rate:.1f}%")
    
    def get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            "platform": platform.platform(),
            "python_version": platform.python_version(),
            "cpu_count": os.cpu_count(),
            "architecture": platform.architecture()[0]
        }
        
        if self._psutil_available:
            import psutil
            info.update({
                "total_memory": psutil.virtual_memory().total / 1024 / 1024 / 1024,  # GB
                "available_memory": psutil.virtual_memory().available / 1024 / 1024 / 1024,  # GB
                "cpu_freq": psutil.cpu_freq().current if psutil.cpu_freq() else "Unknown"
            })
        
        return info
    
    def generate_report(self, output_file: Path):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "system_info": self.get_system_info(),
            "test_summary": self._generate_summary(),
            "detailed_metrics": [asdict(m) for m in self.metrics]
        }
        
        # å†™å…¥JSONæŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        
        # æ˜¾ç¤ºæ‘˜è¦
        self._print_summary()
    
    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        if not self.metrics:
            return {}
        
        successful_tests = [m for m in self.metrics if m.success]
        
        if not successful_tests:
            return {"total_tests": len(self.metrics), "successful_tests": 0}
        
        processing_times = [m.processing_time for m in successful_tests]
        speeds = [m.processing_speed_pps for m in successful_tests]
        memory_deltas = [m.memory_delta for m in successful_tests]
        
        return {
            "total_tests": len(self.metrics),
            "successful_tests": len(successful_tests),
            "failed_tests": len(self.metrics) - len(successful_tests),
            "avg_processing_time": statistics.mean(processing_times),
            "min_processing_time": min(processing_times),
            "max_processing_time": max(processing_times),
            "avg_processing_speed": statistics.mean(speeds),
            "max_processing_speed": max(speeds),
            "min_processing_speed": min(speeds),
            "avg_memory_delta": statistics.mean(memory_deltas),
            "max_memory_delta": max(memory_deltas),
            "total_packets_processed": sum(m.total_packets for m in successful_tests),
            "total_bytes_masked": sum(m.bytes_masked for m in successful_tests)
        }
    
    def _print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        summary = self._generate_summary()
        
        if not summary:
            print("âš ï¸  æ— æ€§èƒ½æ•°æ®å¯æ˜¾ç¤º")
            return
        
        print("\n" + "=" * 60)
        print("æ€§èƒ½æµ‹è¯•æ‘˜è¦")
        print("=" * 60)
        
        print(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        print(f"å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        
        if summary['successful_tests'] > 0:
            print(f"\nå¤„ç†æ—¶é—´ç»Ÿè®¡:")
            print(f"   å¹³å‡: {summary['avg_processing_time']:.3f} ç§’")
            print(f"   æœ€å¿«: {summary['min_processing_time']:.3f} ç§’")
            print(f"   æœ€æ…¢: {summary['max_processing_time']:.3f} ç§’")
            
            print(f"\nå¤„ç†é€Ÿåº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡: {summary['avg_processing_speed']:.1f} pps")
            print(f"   æœ€å¿«: {summary['max_processing_speed']:.1f} pps")
            print(f"   æœ€æ…¢: {summary['min_processing_speed']:.1f} pps")
            
            print(f"\nå†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
            print(f"   å¹³å‡å¢é•¿: {summary['avg_memory_delta']:.2f} MB")
            print(f"   æœ€å¤§å¢é•¿: {summary['max_memory_delta']:.2f} MB")
            
            print(f"\næ€»ä½“ç»Ÿè®¡:")
            print(f"   å¤„ç†æ•°æ®åŒ…: {summary['total_packets_processed']:,}")
            print(f"   æ©ç å­—èŠ‚æ•°: {summary['total_bytes_masked']:,}")


class BenchmarkSuite:
    """åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
    
    def run_initialization_benchmark(self):
        """åˆå§‹åŒ–æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 60)
        print("åŸºå‡†æµ‹è¯•1: åˆå§‹åŒ–æ€§èƒ½")
        print("=" * 60)
        
        configs = [
            ("é»˜è®¤é…ç½®", {}),
            ("æœ€å°é…ç½®", {
                'log_level': 'ERROR',
                'recalculate_checksums': False,
                'strict_consistency_mode': False
            }),
            ("å®Œæ•´é…ç½®", {
                'log_level': 'DEBUG',
                'recalculate_checksums': True,
                'strict_consistency_mode': True,
                'processing_batch_size': 500,
                'memory_limit_mb': 256
            })
        ]
        
        for config_name, config in configs:
            with self.monitor.monitor_test(f"åˆå§‹åŒ–-{config_name}", "dummy_file") as test_result:
                start_time = time.time()
                masker = IndependentPcapMasker(config)
                end_time = time.time()
                
                initialization_time = end_time - start_time
                print(f"   {config_name} åˆå§‹åŒ–æ—¶é—´: {initialization_time:.4f} ç§’")
                
                test_result.update({
                    "total_packets": 0,
                    "modified_packets": 0,
                    "bytes_masked": 0
                })
    
    def run_mask_table_benchmark(self):
        """æ©ç è¡¨æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 60)
        print("åŸºå‡†æµ‹è¯•2: æ©ç è¡¨æ€§èƒ½")
        print("=" * 60)
        
        table_sizes = [10, 100, 1000, 5000]
        
        for size in table_sizes:
            with self.monitor.monitor_test(f"æ©ç è¡¨-{size}æ¡ç›®", "dummy_file") as test_result:
                # åˆ›å»ºæŒ‡å®šå¤§å°çš„æ©ç è¡¨
                mask_table = SequenceMaskTable()
                
                start_time = time.time()
                
                for i in range(size):
                    mask_table.add_entry(MaskEntry(
                        stream_id=f"TCP_192.168.1.{i%255}:443_10.0.0.{i%255}:54321_forward",
                        sequence_start=i * 1000,
                        sequence_end=(i + 1) * 1000,
                        mask_type="mask_after",
                        mask_params={"keep_bytes": 5}
                    ))
                
                creation_time = time.time() - start_time
                
                # æµ‹è¯•æŸ¥æ‰¾æ€§èƒ½
                search_start = time.time()
                for i in range(1000):
                    stream_id = f"TCP_192.168.1.{i%255}:443_10.0.0.{i%255}:54321_forward"
                    sequence = (i % size) * 1000 + 500
                    matches = mask_table.find_matches(stream_id, sequence)
                
                search_time = time.time() - search_start
                
                print(f"   {size} æ¡ç›®è¡¨:")
                print(f"     åˆ›å»ºæ—¶é—´: {creation_time:.4f} ç§’")
                print(f"     1000æ¬¡æŸ¥æ‰¾: {search_time:.4f} ç§’")
                print(f"     å¹³å‡æŸ¥æ‰¾: {search_time/1000*1000:.4f} ms")
                
                test_result.update({
                    "total_packets": size,
                    "modified_packets": 0,
                    "bytes_masked": 0
                })
    
    def run_file_processing_benchmark(self, test_files: List[Tuple[str, str]]):
        """æ–‡ä»¶å¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 60)
        print("åŸºå‡†æµ‹è¯•3: æ–‡ä»¶å¤„ç†æ€§èƒ½")
        print("=" * 60)
        
        # åˆ›å»ºæ ‡å‡†æ©ç è¡¨
        mask_table = SequenceMaskTable()
        mask_table.add_entry(MaskEntry(
            stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
            sequence_start=1000,
            sequence_end=5000,
            mask_type="mask_after",
            mask_params={"keep_bytes": 5}
        ))
        
        # æµ‹è¯•ä¸åŒçš„é…ç½®
        configs = [
            ("å¿«é€Ÿæ¨¡å¼", {
                'recalculate_checksums': False,
                'strict_consistency_mode': False,
                'log_level': 'ERROR',
                'processing_batch_size': 2000
            }),
            ("æ ‡å‡†æ¨¡å¼", {}),
            ("é«˜è´¨é‡æ¨¡å¼", {
                'recalculate_checksums': True,
                'strict_consistency_mode': True,
                'log_level': 'INFO',
                'processing_batch_size': 500
            })
        ]
        
        for file_name, file_path in test_files:
            if not os.path.exists(file_path):
                print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
            
            print(f"\næµ‹è¯•æ–‡ä»¶: {file_name}")
            
            for config_name, config in configs:
                test_name = f"æ–‡ä»¶å¤„ç†-{file_name}-{config_name}"
                output_file = f"examples/output/processed/benchmark_{file_name}_{config_name.replace(' ', '_')}.pcap"
                
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(output_file), exist_ok=True)
                
                with self.monitor.monitor_test(test_name, file_path) as test_result:
                    masker = IndependentPcapMasker(config)
                    
                    result = masker.mask_pcap_with_sequences(
                        file_path, mask_table, output_file
                    )
                    
                    if result.success:
                        test_result.update({
                            "total_packets": result.total_packets,
                            "modified_packets": result.modified_packets,
                            "bytes_masked": result.bytes_masked
                        })
                        
                        print(f"     {config_name}: {result.modified_packets}/{result.total_packets} åŒ…è¢«ä¿®æ”¹")
                    else:
                        test_result["success"] = False
                        test_result["error_message"] = result.error_message
                        print(f"     {config_name}: å¤„ç†å¤±è´¥ - {result.error_message}")
    
    def run_stress_test(self, test_file: str, iterations: int = 10):
        """å‹åŠ›æµ‹è¯•"""
        print("\n" + "=" * 60)
        print(f"åŸºå‡†æµ‹è¯•4: å‹åŠ›æµ‹è¯• ({iterations} æ¬¡è¿­ä»£)")
        print("=" * 60)
        
        if not os.path.exists(test_file):
            print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return
        
        mask_table = SequenceMaskTable()
        mask_table.add_entry(MaskEntry(
            stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
            sequence_start=1000,
            sequence_end=3000,
            mask_type="mask_after",
            mask_params={"keep_bytes": 8}
        ))
        
        masker = IndependentPcapMasker({
            'log_level': 'ERROR'  # å‡å°‘æ—¥å¿—è¾“å‡º
        })
        
        with self.monitor.monitor_test(f"å‹åŠ›æµ‹è¯•-{iterations}æ¬¡", test_file) as test_result:
            times = []
            total_packets = 0
            total_modified = 0
            total_bytes_masked = 0
            
            for i in range(iterations):
                output_file = f"examples/output/processed/stress_test_{i}.pcap"
                
                iteration_start = time.time()
                result = masker.mask_pcap_with_sequences(test_file, mask_table, output_file)
                iteration_end = time.time()
                
                if result.success:
                    times.append(iteration_end - iteration_start)
                    total_packets = result.total_packets  # åº”è¯¥æ¯æ¬¡éƒ½ç›¸åŒ
                    total_modified += result.modified_packets
                    total_bytes_masked += result.bytes_masked
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(output_file):
                        os.remove(output_file)
                else:
                    print(f"   è¿­ä»£ {i+1} å¤±è´¥: {result.error_message}")
            
            if times:
                avg_time = statistics.mean(times)
                min_time = min(times)
                max_time = max(times)
                std_dev = statistics.stdev(times) if len(times) > 1 else 0
                
                print(f"   æˆåŠŸå®Œæˆ {len(times)}/{iterations} æ¬¡è¿­ä»£")
                print(f"   å¹³å‡æ—¶é—´: {avg_time:.3f} ç§’")
                print(f"   æœ€å¿«æ—¶é—´: {min_time:.3f} ç§’")
                print(f"   æœ€æ…¢æ—¶é—´: {max_time:.3f} ç§’")
                print(f"   æ ‡å‡†å·®: {std_dev:.3f} ç§’")
                print(f"   å˜å¼‚ç³»æ•°: {std_dev/avg_time*100:.1f}%" if avg_time > 0 else "")
                
                test_result.update({
                    "total_packets": total_packets,
                    "modified_packets": total_modified // len(times),  # å¹³å‡å€¼
                    "bytes_masked": total_bytes_masked // len(times)   # å¹³å‡å€¼
                })
            else:
                test_result["success"] = False
                test_result["error_message"] = "æ‰€æœ‰è¿­ä»£éƒ½å¤±è´¥"


def find_test_files() -> List[Tuple[str, str]]:
    """æŸ¥æ‰¾å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶"""
    test_files = []
    
    # é¢„å®šä¹‰çš„æµ‹è¯•æ–‡ä»¶ä½ç½®
    candidate_files = [
        ("tls-single", "tests/samples/tls-single/tls_sample.pcap"),
        ("http-sample", "tests/samples/http/http_sample.pcap"),
        ("small-pcap", "tests/samples/small.pcap"),
        ("mixed-traffic", "tests/samples/mixed_traffic.pcap")
    ]
    
    # æŸ¥æ‰¾å®é™…å­˜åœ¨çš„æ–‡ä»¶
    for name, path in candidate_files:
        if os.path.exists(path):
            test_files.append((name, path))
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„å®šä¹‰æ–‡ä»¶ï¼Œæœç´¢samplesç›®å½•
    if not test_files:
        samples_dir = Path("tests/samples")
        if samples_dir.exists():
            for pcap_file in samples_dir.rglob("*.pcap"):
                if pcap_file.stat().st_size > 0:  # ç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º
                    relative_name = str(pcap_file.relative_to(samples_dir)).replace("/", "-")
                    test_files.append((relative_name, str(pcap_file)))
                    if len(test_files) >= 3:  # é™åˆ¶æµ‹è¯•æ–‡ä»¶æ•°é‡
                        break
    
    return test_files


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    print("ç‹¬ç«‹PCAPæ©ç å¤„ç†å™¨ - æ€§èƒ½æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print("æœ¬æµ‹è¯•å¥—ä»¶å°†å…¨é¢è¯„ä¼°æ©ç å¤„ç†å™¨çš„æ€§èƒ½ç‰¹å¾")
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("examples/output")
    output_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
    monitor = PerformanceMonitor()
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    system_info = monitor.get_system_info()
    print("ç³»ç»Ÿä¿¡æ¯:")
    for key, value in system_info.items():
        print(f"   {key}: {value}")
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å¥—ä»¶
    benchmark_suite = BenchmarkSuite(monitor)
    
    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    test_files = find_test_files()
    
    if test_files:
        print(f"\nå‘ç° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
        for name, path in test_files:
            size = os.path.getsize(path)
            print(f"   {name}: {size:,} bytes")
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ï¼Œéƒ¨åˆ†åŸºå‡†æµ‹è¯•å°†è¢«è·³è¿‡")
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•å¥—ä»¶
    try:
        # 1. åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•
        benchmark_suite.run_initialization_benchmark()
        
        # 2. æ©ç è¡¨æ€§èƒ½æµ‹è¯•
        benchmark_suite.run_mask_table_benchmark()
        
        # 3. æ–‡ä»¶å¤„ç†æ€§èƒ½æµ‹è¯•
        if test_files:
            benchmark_suite.run_file_processing_benchmark(test_files)
        
        # 4. å‹åŠ›æµ‹è¯•ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ–‡ä»¶ï¼‰
        if test_files:
            stress_test_file = test_files[0][1]
            benchmark_suite.run_stress_test(stress_test_file, iterations=5)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¥—ä»¶æ‰§è¡Œå¼‚å¸¸: {str(e)}")
    
    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    report_file = output_dir / "performance_test_report.json"
    monitor.generate_report(report_file)
    
    print("\næ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    print("\nğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    temp_files = list(output_dir.glob("benchmark_*.pcap")) + list(output_dir.glob("stress_test_*.pcap"))
    
    for temp_file in temp_files:
        try:
            temp_file.unlink()
            print(f"   æ¸…ç†: {temp_file.name}")
        except Exception as e:
            print(f"   æ¸…ç†å¤±è´¥: {temp_file.name} - {e}")
    
    print("æ€§èƒ½æµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæˆï¼")


if __name__ == "__main__":
    main() 