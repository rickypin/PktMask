#!/usr/bin/env python3
"""
ç‹¬ç«‹PCAPæ©ç å¤„ç†å™¨ - é«˜çº§ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºäº†IndependentPcapMaskerçš„é«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¤æ‚æ©ç è¡¨åˆ›å»ºå’Œç®¡ç†
- æ‰¹é‡æ–‡ä»¶å¤„ç†
- æ€§èƒ½ä¼˜åŒ–é…ç½®
- å¹¶è¡Œå¤„ç†
- åè®®è§£ææ§åˆ¶
- ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨

ä½œè€…: PktMaskå¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-06-22
"""

import os
import sys
import time
import json
import logging
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from contextlib import contextmanager
from typing import List, Dict, Tuple, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.pathä»¥ä¾¿å¯¼å…¥æ¨¡å—
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from pktmask.core.independent_pcap_masker import (
    IndependentPcapMasker,
    SequenceMaskTable, 
    MaskEntry, 
    MaskingResult
)


class AdvancedMaskTableBuilder:
    """é«˜çº§æ©ç è¡¨æ„å»ºå™¨"""
    
    def __init__(self):
        self.mask_table = SequenceMaskTable()
        self._stream_counter = {}
    
    def add_tls_stream_masks(self, src_ip: str, src_port: int, dst_ip: str, dst_port: int, 
                           app_data_ranges: List[Tuple[int, int]]) -> 'AdvancedMaskTableBuilder':
        """æ·»åŠ TLSæµçš„å®Œæ•´æ©ç è§„åˆ™"""
        
        # æ­£å‘æµï¼ˆå®¢æˆ·ç«¯åˆ°æœåŠ¡å™¨ï¼‰
        forward_stream_id = f"TCP_{src_ip}:{src_port}_{dst_ip}:{dst_port}_forward"
        
        for start_seq, end_seq in app_data_ranges:
            self.mask_table.add_entry(MaskEntry(
                stream_id=forward_stream_id,
                sequence_start=start_seq,
                sequence_end=end_seq,
                mask_type="mask_after",
                mask_params={"keep_bytes": 5}  # TLSå¤´éƒ¨
            ))
        
        # åå‘æµï¼ˆæœåŠ¡å™¨åˆ°å®¢æˆ·ç«¯ï¼‰
        reverse_stream_id = f"TCP_{dst_ip}:{dst_port}_{src_ip}:{src_port}_reverse"
        
        for start_seq, end_seq in app_data_ranges:
            # æœåŠ¡å™¨å“åº”é€šå¸¸åºåˆ—å·ä¸åŒï¼Œè¿™é‡Œä½¿ç”¨åç§»
            self.mask_table.add_entry(MaskEntry(
                stream_id=reverse_stream_id,
                sequence_start=start_seq + 1000,  # å‡è®¾çš„åç§»
                sequence_end=end_seq + 1000,
                mask_type="mask_after",
                mask_params={"keep_bytes": 5}
            ))
        
        return self
    
    def add_http_api_masks(self, src_ip: str, src_port: int, dst_ip: str, dst_port: int,
                          request_body_ranges: List[Tuple[int, int]],
                          response_body_ranges: List[Tuple[int, int]]) -> 'AdvancedMaskTableBuilder':
        """æ·»åŠ HTTP APIçš„æ•æ„Ÿæ•°æ®æ©ç è§„åˆ™"""
        
        forward_stream_id = f"TCP_{src_ip}:{src_port}_{dst_ip}:{dst_port}_forward"
        reverse_stream_id = f"TCP_{dst_ip}:{dst_port}_{src_ip}:{src_port}_reverse"
        
        # æ©ç è¯·æ±‚ä½“ä¸­çš„æ•æ„Ÿæ•°æ®
        for start_seq, end_seq in request_body_ranges:
            self.mask_table.add_entry(MaskEntry(
                stream_id=forward_stream_id,
                sequence_start=start_seq,
                sequence_end=end_seq,
                mask_type="mask_range",
                mask_params={
                    "ranges": [
                        (50, 150),   # ç”¨æˆ·å/å¯†ç å­—æ®µ
                        (200, 300),  # APIå¯†é’¥
                        (400, 600)   # å…¶ä»–æ•æ„Ÿæ•°æ®
                    ]
                }
            ))
        
        # æ©ç å“åº”ä½“ä¸­çš„æ•æ„Ÿæ•°æ®
        for start_seq, end_seq in response_body_ranges:
            self.mask_table.add_entry(MaskEntry(
                stream_id=reverse_stream_id,
                sequence_start=start_seq,
                sequence_end=end_seq,
                mask_type="mask_after",
                mask_params={"keep_bytes": 100}  # ä¿ç•™å“åº”å¤´éƒ¨
            ))
        
        return self
    
    def add_debug_stream(self, stream_id: str, seq_ranges: List[Tuple[int, int]]) -> 'AdvancedMaskTableBuilder':
        """æ·»åŠ è°ƒè¯•æµï¼ˆä¿ç•™æ‰€æœ‰æ•°æ®ï¼‰"""
        
        for start_seq, end_seq in seq_ranges:
            self.mask_table.add_entry(MaskEntry(
                stream_id=stream_id,
                sequence_start=start_seq,
                sequence_end=end_seq,
                mask_type="keep_all",
                mask_params={}
            ))
        
        return self
    
    def build(self) -> SequenceMaskTable:
        """æ„å»ºæœ€ç»ˆçš„æ©ç è¡¨"""
        return self.mask_table
    
    def get_statistics(self) -> Dict[str, int]:
        """è·å–æ„å»ºç»Ÿè®¡ä¿¡æ¯"""
        try:
            # å°è¯•ä½¿ç”¨å†…ç½®ç»Ÿè®¡æ–¹æ³•
            stats = self.mask_table.get_statistics()
            return {
                "total_entries": stats.get("total_entries", 0),
                "unique_streams": stats.get("streams_count", 0),
                "mask_after_count": 0,  # æš‚æ—¶ä¸å¯ç”¨
                "mask_range_count": 0,  # æš‚æ—¶ä¸å¯ç”¨
                "keep_all_count": 0     # æš‚æ—¶ä¸å¯ç”¨
            }
        except AttributeError:
            # é™çº§åˆ°åŸºæœ¬ç»Ÿè®¡
            return {
                "total_entries": self.mask_table.get_total_entries(),
                "unique_streams": 0,  # ä¸å¯ç”¨
                "mask_after_count": 0,  # ä¸å¯ç”¨
                "mask_range_count": 0,  # ä¸å¯ç”¨
                "keep_all_count": 0     # ä¸å¯ç”¨
            }


class BatchProcessor:
    """æ‰¹é‡æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.results = []
        self.lock = threading.Lock()
    
    def process_file(self, input_file: Path, output_file: Path, mask_table: SequenceMaskTable) -> Tuple[str, MaskingResult]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        masker = IndependentPcapMasker(self.config)
        
        try:
            start_time = time.time()
            result = masker.mask_pcap_with_sequences(
                str(input_file),
                mask_table,
                str(output_file)
            )
            end_time = time.time()
            
            # æ·»åŠ é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
            if result.statistics is None:
                result.statistics = {}
            
            result.statistics.update({
                "file_name": input_file.name,
                "file_size": input_file.stat().st_size,
                "total_time": end_time - start_time,
                "processing_speed_pps": result.total_packets / result.processing_time if result.processing_time > 0 else 0
            })
            
            return input_file.name, result
            
        except Exception as e:
            # åˆ›å»ºå¤±è´¥ç»“æœ
            error_result = MaskingResult(
                success=False,
                total_packets=0,
                modified_packets=0,
                bytes_masked=0,
                processing_time=0.0,
                streams_processed=0,
                error_message=str(e)
            )
            return input_file.name, error_result
    
    def process_directory(self, input_dir: Path, output_dir: Path, mask_table: SequenceMaskTable, 
                         max_workers: int = 4) -> List[Tuple[str, MaskingResult]]:
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰PCAPæ–‡ä»¶"""
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æŸ¥æ‰¾æ‰€æœ‰PCAPæ–‡ä»¶
        pcap_files = list(input_dir.glob("*.pcap")) + list(input_dir.glob("*.pcapng"))
        
        if not pcap_files:
            print(f"âš ï¸  åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°PCAPæ–‡ä»¶")
            return []
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(pcap_files)} ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹")
        
        # å¹¶è¡Œå¤„ç†æ–‡ä»¶
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {}
            for pcap_file in pcap_files:
                output_file = output_dir / f"masked_{pcap_file.name}"
                future = executor.submit(self.process_file, pcap_file, output_file, mask_table)
                future_to_file[future] = pcap_file
            
            # æ”¶é›†ç»“æœ
            results = []
            completed = 0
            
            for future in as_completed(future_to_file):
                completed += 1
                try:
                    file_name, result = future.result()
                    results.append((file_name, result))
                    
                    status = "âœ…" if result.success else "âŒ"
                    print(f"   [{completed}/{len(pcap_files)}] {status} {file_name}")
                    
                except Exception as e:
                    file_name = future_to_file[future].name
                    print(f"   [{completed}/{len(pcap_files)}] âŒ {file_name}: {str(e)}")
                    
                    error_result = MaskingResult(
                        success=False,
                        total_packets=0,
                        modified_packets=0,
                        bytes_masked=0,
                        processing_time=0.0,
                        streams_processed=0,
                        error_message=str(e)
                    )
                    results.append((file_name, error_result))
        
        return results
    
    def generate_batch_report(self, results: List[Tuple[str, MaskingResult]], output_file: Path):
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        
        report = {
            "summary": {
                "total_files": len(results),
                "successful_files": len([r for _, r in results if r.success]),
                "failed_files": len([r for _, r in results if not r.success]),
                "total_packets": sum(r.total_packets for _, r in results),
                "total_modified_packets": sum(r.modified_packets for _, r in results),
                "total_bytes_masked": sum(r.bytes_masked for _, r in results),
                "total_processing_time": sum(r.processing_time for _, r in results)
            },
            "file_details": []
        }
        
        for file_name, result in results:
            detail = {
                "file_name": file_name,
                "success": result.success,
                "total_packets": result.total_packets,
                "modified_packets": result.modified_packets,
                "bytes_masked": result.bytes_masked,
                "processing_time": result.processing_time,
                "streams_processed": result.streams_processed
            }
            
            if result.error_message:
                detail["error_message"] = result.error_message
            
            if result.statistics:
                detail["statistics"] = result.statistics
            
            report["file_details"].append(detail)
        
        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š æ‰¹é‡å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        
        # æ˜¾ç¤ºæ‘˜è¦
        summary = report["summary"]
        print(f"\næ‰¹é‡å¤„ç†æ‘˜è¦:")
        print(f"   æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"   æˆåŠŸæ–‡ä»¶: {summary['successful_files']}")
        print(f"   å¤±è´¥æ–‡ä»¶: {summary['failed_files']}")
        print(f"   æ€»æ•°æ®åŒ…: {summary['total_packets']:,}")
        print(f"   ä¿®æ”¹æ•°æ®åŒ…: {summary['total_modified_packets']:,}")
        print(f"   æ©ç å­—èŠ‚æ•°: {summary['total_bytes_masked']:,}")
        print(f"   æ€»å¤„ç†æ—¶é—´: {summary['total_processing_time']:.2f} ç§’")
        
        if summary['total_processing_time'] > 0:
            avg_pps = summary['total_packets'] / summary['total_processing_time']
            print(f"   å¹³å‡å¤„ç†é€Ÿåº¦: {avg_pps:.1f} pps")


@contextmanager
def performance_monitor(operation_name: str):
    """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.time()
    start_memory = get_memory_usage()
    
    print(f"ğŸ å¼€å§‹æ“ä½œ: {operation_name}")
    
    try:
        yield
    finally:
        end_time = time.time()
        end_memory = get_memory_usage()
        
        elapsed_time = end_time - start_time
        memory_delta = end_memory - start_memory
        
        print(f"â±ï¸  æ“ä½œå®Œæˆ: {operation_name}")
        print(f"   è€—æ—¶: {elapsed_time:.3f} ç§’")
        print(f"   å†…å­˜å˜åŒ–: {memory_delta:+.2f} MB")


def get_memory_usage() -> float:
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
    try:
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024
    except ImportError:
        return 0.0


def example_1_complex_mask_table_creation():
    """
    ç¤ºä¾‹1: å¤æ‚æ©ç è¡¨åˆ›å»º
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨AdvancedMaskTableBuilderåˆ›å»ºå¤æ‚çš„å¤šåè®®æ©ç è¡¨
    """
    print("=" * 60)
    print("ç¤ºä¾‹1: å¤æ‚æ©ç è¡¨åˆ›å»º")
    print("=" * 60)
    
    with performance_monitor("å¤æ‚æ©ç è¡¨åˆ›å»º"):
        builder = AdvancedMaskTableBuilder()
        
        # æ·»åŠ å¤šä¸ªTLSæµçš„æ©ç è§„åˆ™
        print("æ·»åŠ TLSæµæ©ç è§„åˆ™...")
        builder.add_tls_stream_masks(
            src_ip="192.168.1.100", src_port=54321,
            dst_ip="10.0.0.1", dst_port=443,
            app_data_ranges=[(1000, 5000), (10000, 15000), (20000, 25000)]
        )
        
        builder.add_tls_stream_masks(
            src_ip="192.168.1.101", src_port=54322,
            dst_ip="10.0.0.2", dst_port=443,
            app_data_ranges=[(2000, 8000), (12000, 18000)]
        )
        
        # æ·»åŠ HTTP APIæµçš„æ©ç è§„åˆ™
        print("æ·»åŠ HTTP APIæµæ©ç è§„åˆ™...")
        builder.add_http_api_masks(
            src_ip="192.168.1.100", src_port=54323,
            dst_ip="10.0.0.3", dst_port=80,
            request_body_ranges=[(500, 2000), (3000, 4000)],
            response_body_ranges=[(1000, 3000), (5000, 7000)]
        )
        
        # æ·»åŠ è°ƒè¯•æµ
        print("æ·»åŠ è°ƒè¯•æµ...")
        builder.add_debug_stream(
            stream_id="TCP_192.168.1.100:22_10.0.0.4:54324_forward",
            seq_ranges=[(0, 10000)]
        )
        
        # æ„å»ºæ©ç è¡¨
        mask_table = builder.build()
        stats = builder.get_statistics()
        
        print("âœ… å¤æ‚æ©ç è¡¨åˆ›å»ºå®Œæˆ")
        print(f"   æ€»æ¡ç›®æ•°: {stats['total_entries']}")
        print(f"   å”¯ä¸€æµæ•°: {stats['unique_streams']}")
        print(f"   MaskAfteræ¡ç›®: {stats['mask_after_count']}")
        print(f"   MaskRangeæ¡ç›®: {stats['mask_range_count']}")
        print(f"   KeepAllæ¡ç›®: {stats['keep_all_count']}")
        
        return mask_table


def example_2_performance_optimization():
    """
    ç¤ºä¾‹2: æ€§èƒ½ä¼˜åŒ–é…ç½®
    
    æ¼”ç¤ºä¸åŒé…ç½®å¯¹æ€§èƒ½çš„å½±å“
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: æ€§èƒ½ä¼˜åŒ–é…ç½®")
    print("=" * 60)
    
    # æµ‹è¯•ä¸åŒçš„é…ç½®
    configs = {
        "é»˜è®¤é…ç½®": {},
        "é«˜æ€§èƒ½é…ç½®": {
            'recalculate_checksums': False,
            'strict_consistency_mode': False,
            'log_level': 'ERROR',
            'processing_batch_size': 3000,
            'memory_limit_mb': 2048
        },
        "é«˜è´¨é‡é…ç½®": {
            'recalculate_checksums': True,
            'strict_consistency_mode': True,
            'log_level': 'DEBUG',
            'processing_batch_size': 500,
            'memory_limit_mb': 512
        }
    }
    
    # åˆ›å»ºæµ‹è¯•æ©ç è¡¨
    mask_table = SequenceMaskTable()
    mask_table.add_entry(MaskEntry(
        stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
        sequence_start=1000,
        sequence_end=3000,
        mask_type="mask_after",
        mask_params={"keep_bytes": 8}
    ))
    
    # æµ‹è¯•æ–‡ä»¶
    test_file = "tests/samples/tls-single/tls_sample.pcap"
    
    if not os.path.exists(test_file):
        print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        print("è·³è¿‡æ€§èƒ½æµ‹è¯•")
        return None
    
    results = {}
    
    for config_name, config in configs.items():
        print(f"\næµ‹è¯•é…ç½®: {config_name}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_file = f"examples/output/processed/perf_test_{config_name.replace(' ', '_').lower()}.pcap"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        try:
            with performance_monitor(f"é…ç½®æµ‹è¯•: {config_name}"):
                masker = IndependentPcapMasker(config)
                
                # è¿è¡Œå¤šæ¬¡å–å¹³å‡å€¼
                times = []
                for i in range(3):
                    start_time = time.time()
                    result = masker.mask_pcap_with_sequences(test_file, mask_table, output_file)
                    end_time = time.time()
                    
                    if result.success:
                        times.append(end_time - start_time)
                    else:
                        print(f"   âŒ ç¬¬{i+1}æ¬¡è¿è¡Œå¤±è´¥: {result.error_message}")
                        break
                
                if times:
                    avg_time = sum(times) / len(times)
                    min_time = min(times)
                    max_time = max(times)
                    
                    results[config_name] = {
                        "avg_time": avg_time,
                        "min_time": min_time,
                        "max_time": max_time,
                        "total_packets": result.total_packets,
                        "modified_packets": result.modified_packets,
                        "processing_speed": result.total_packets / avg_time if avg_time > 0 else 0
                    }
                    
                    print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f} ç§’")
                    print(f"   å¤„ç†é€Ÿåº¦: {results[config_name]['processing_speed']:.1f} pps")
                
        except Exception as e:
            print(f"   âŒ é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
    if results:
        print("\næ€§èƒ½å¯¹æ¯”æ‘˜è¦:")
        print("-" * 60)
        
        baseline = None
        for config_name, data in results.items():
            speed = data['processing_speed']
            
            if baseline is None:
                baseline = speed
                improvement = "åŸºå‡†"
            else:
                improvement = f"{speed/baseline:.1f}x"
            
            print(f"{config_name:12s}: {speed:7.1f} pps ({improvement})")
    
    return results


def example_3_batch_processing():
    """
    ç¤ºä¾‹3: æ‰¹é‡æ–‡ä»¶å¤„ç†
    
    æ¼”ç¤ºå¦‚ä½•æ‰¹é‡å¤„ç†å¤šä¸ªPCAPæ–‡ä»¶
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: æ‰¹é‡æ–‡ä»¶å¤„ç†")
    print("=" * 60)
    
    # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
    batch_config = {
        'log_level': 'WARNING',  # å‡å°‘æ—¥å¿—è¾“å‡º
        'processing_batch_size': 2000,
        'memory_limit_mb': 1024
    }
    
    processor = BatchProcessor(batch_config)
    
    # åˆ›å»ºæ©ç è¡¨
    mask_table = SequenceMaskTable()
    
    # æ·»åŠ é€šç”¨çš„æ©ç è§„åˆ™
    common_streams = [
        ("TCP_192.168.1.100:443_10.0.0.1:54321_forward", [(1000, 5000)]),
        ("TCP_192.168.1.100:80_10.0.0.1:54322_forward", [(500, 2000)]),
        ("TCP_192.168.1.101:443_10.0.0.2:54323_forward", [(2000, 8000)])
    ]
    
    for stream_id, ranges in common_streams:
        for start_seq, end_seq in ranges:
            mask_table.add_entry(MaskEntry(
                stream_id=stream_id,
                sequence_start=start_seq,
                sequence_end=end_seq,
                mask_type="mask_after",
                mask_params={"keep_bytes": 5}
            ))
    
    print(f"åˆ›å»ºæ©ç è¡¨ï¼ŒåŒ…å« {mask_table.get_total_entries()} ä¸ªæ¡ç›®")
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºç›®å½•
    input_dir = Path("tests/samples")
    output_dir = Path("examples/output/processed/batch_results")
    
    if not input_dir.exists():
        print(f"âš ï¸  è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        print("è·³è¿‡æ‰¹é‡å¤„ç†æ¼”ç¤º")
        return None
    
    with performance_monitor("æ‰¹é‡æ–‡ä»¶å¤„ç†"):
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        results = processor.process_directory(input_dir, output_dir, mask_table, max_workers=4)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = output_dir / "batch_processing_report.json"
        processor.generate_batch_report(results, report_file)
        
        return results


def example_4_parallel_batch_processing():
    """
    ç¤ºä¾‹4: å¹¶è¡Œæ‰¹é‡å¤„ç†
    
    æ¼”ç¤ºé«˜çº§å¹¶è¡Œå¤„ç†æ¨¡å¼
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: å¹¶è¡Œæ‰¹é‡å¤„ç†")
    print("=" * 60)
    
    def process_file_group(group_name: str, file_list: List[Path], mask_table: SequenceMaskTable) -> Dict:
        """å¤„ç†ä¸€ç»„æ–‡ä»¶"""
        print(f"   å¼€å§‹å¤„ç†ç»„: {group_name} ({len(file_list)} ä¸ªæ–‡ä»¶)")
        
        group_config = {
            'log_level': 'ERROR',
            'processing_batch_size': 1500,
            'memory_limit_mb': 512
        }
        
        masker = IndependentPcapMasker(group_config)
        group_results = []
        
        for file_path in file_list:
            output_file = Path(f"examples/output/processed/parallel/{group_name}_{file_path.name}")
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                result = masker.mask_pcap_with_sequences(
                    str(file_path), mask_table, str(output_file)
                )
                group_results.append((file_path.name, result))
            except Exception as e:
                error_result = MaskingResult(
                    success=False, total_packets=0, modified_packets=0,
                    bytes_masked=0, processing_time=0.0, streams_processed=0,
                    error_message=str(e)
                )
                group_results.append((file_path.name, error_result))
        
        successful = len([r for _, r in group_results if r.success])
        print(f"   å®Œæˆå¤„ç†ç»„: {group_name} ({successful}/{len(group_results)} æˆåŠŸ)")
        
        return {
            "group_name": group_name,
            "total_files": len(group_results),
            "successful_files": successful,
            "results": group_results
        }
    
    # æŸ¥æ‰¾æ‰€æœ‰PCAPæ–‡ä»¶å¹¶åˆ†ç»„
    input_dir = Path("tests/samples")
    
    if not input_dir.exists():
        print(f"âš ï¸  è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        print("è·³è¿‡å¹¶è¡Œæ‰¹é‡å¤„ç†æ¼”ç¤º")
        return None
    
    pcap_files = list(input_dir.rglob("*.pcap")) + list(input_dir.rglob("*.pcapng"))
    
    if not pcap_files:
        print("âš ï¸  æœªæ‰¾åˆ°PCAPæ–‡ä»¶")
        return None
    
    # æŒ‰ç›®å½•åˆ†ç»„
    file_groups = {}
    for file_path in pcap_files:
        group_name = file_path.parent.name
        if group_name not in file_groups:
            file_groups[group_name] = []
        file_groups[group_name].append(file_path)
    
    print(f"å‘ç° {len(file_groups)} ä¸ªæ–‡ä»¶ç»„ï¼Œæ€»å…± {len(pcap_files)} ä¸ªæ–‡ä»¶")
    
    # åˆ›å»ºæ©ç è¡¨
    mask_table = SequenceMaskTable()
    mask_table.add_entry(MaskEntry(
        stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
        sequence_start=1000,
        sequence_end=5000,
        mask_type="mask_after",
        mask_params={"keep_bytes": 8}
    ))
    
    with performance_monitor("å¹¶è¡Œæ‰¹é‡å¤„ç†"):
        # å¹¶è¡Œå¤„ç†å„ç»„
        with ThreadPoolExecutor(max_workers=min(4, len(file_groups))) as executor:
            futures = []
            
            for group_name, files in file_groups.items():
                future = executor.submit(process_file_group, group_name, files, mask_table)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            all_results = []
            for future in as_completed(futures):
                try:
                    group_result = future.result()
                    all_results.append(group_result)
                except Exception as e:
                    print(f"âŒ ç»„å¤„ç†å¤±è´¥: {str(e)}")
        
        # æ±‡æ€»ç»“æœ
        total_files = sum(r["total_files"] for r in all_results)
        total_successful = sum(r["successful_files"] for r in all_results)
        
        print(f"\nå¹¶è¡Œå¤„ç†å®Œæˆ:")
        print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"   æˆåŠŸå¤„ç†: {total_successful}")
        print(f"   æˆåŠŸç‡: {total_successful/total_files*100:.1f}%" if total_files > 0 else "   æˆåŠŸç‡: 0%")
        
        for group_result in all_results:
            group_name = group_result["group_name"]
            success_rate = group_result["successful_files"] / group_result["total_files"] * 100
            print(f"   ç»„ {group_name}: {group_result['successful_files']}/{group_result['total_files']} ({success_rate:.1f}%)")
        
        return all_results


def example_5_protocol_parsing_control():
    """
    ç¤ºä¾‹5: åè®®è§£ææ§åˆ¶æ¼”ç¤º
    
    æ¼”ç¤ºåè®®è§£æç¦ç”¨æœºåˆ¶çš„æ•ˆæœ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: åè®®è§£ææ§åˆ¶æ¼”ç¤º")
    print("=" * 60)
    
    # æµ‹è¯•ä¸åŒçš„åè®®è§£æè®¾ç½®
    test_configs = [
        ("åè®®è§£æå¯ç”¨", {'disable_protocol_parsing': False}),
        ("åè®®è§£æç¦ç”¨", {'disable_protocol_parsing': True})
    ]
    
    mask_table = SequenceMaskTable()
    mask_table.add_entry(MaskEntry(
        stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
        sequence_start=1000,
        sequence_end=3000,
        mask_type="mask_after",
        mask_params={"keep_bytes": 5}
    ))
    
    test_file = "tests/samples/tls-single/tls_sample.pcap"
    
    if not os.path.exists(test_file):
        print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        print("è·³è¿‡åè®®è§£ææ§åˆ¶æ¼”ç¤º")
        return None
    
    results = {}
    
    for config_name, config in test_configs:
        print(f"\næµ‹è¯•: {config_name}")
        
        try:
            masker = IndependentPcapMasker(config)
            
            output_file = f"examples/output/processed/protocol_test_{config_name.replace(' ', '_')}.pcap"
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            start_time = time.time()
            result = masker.mask_pcap_with_sequences(test_file, mask_table, output_file)
            end_time = time.time()
            
            if result.success:
                results[config_name] = {
                    "total_packets": result.total_packets,
                    "modified_packets": result.modified_packets,
                    "bytes_masked": result.bytes_masked,
                    "processing_time": end_time - start_time,
                    "success": True
                }
                
                print(f"   âœ… å¤„ç†æˆåŠŸ")
                print(f"   ä¿®æ”¹æ•°æ®åŒ…: {result.modified_packets}/{result.total_packets}")
                print(f"   æ©ç å­—èŠ‚æ•°: {result.bytes_masked}")
                print(f"   å¤„ç†æ—¶é—´: {end_time - start_time:.3f} ç§’")
            else:
                print(f"   âŒ å¤„ç†å¤±è´¥: {result.error_message}")
                results[config_name] = {"success": False, "error": result.error_message}
        
        except Exception as e:
            print(f"   âŒ é…ç½®æµ‹è¯•å¼‚å¸¸: {str(e)}")
            results[config_name] = {"success": False, "error": str(e)}
    
    # æ¯”è¾ƒç»“æœ
    if len([r for r in results.values() if r.get("success")]) >= 2:
        print("\nåè®®è§£ææ§åˆ¶æ•ˆæœå¯¹æ¯”:")
        print("-" * 40)
        
        for config_name, data in results.items():
            if data.get("success"):
                modified_rate = data["modified_packets"] / data["total_packets"] * 100 if data["total_packets"] > 0 else 0
                print(f"{config_name}:")
                print(f"   ä¿®æ”¹ç‡: {modified_rate:.1f}%")
                print(f"   æ©ç å­—èŠ‚: {data['bytes_masked']}")
                print(f"   å¤„ç†æ—¶é—´: {data['processing_time']:.3f}s")
    
    return results


def example_6_context_manager_usage():
    """
    ç¤ºä¾‹6: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨
    
    æ¼”ç¤ºèµ„æºç®¡ç†å’Œè‡ªåŠ¨æ¸…ç†
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹6: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨")
    print("=" * 60)
    
    class MaskingSession:
        """æ©ç å¤„ç†ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        
        def __init__(self, config: Optional[Dict] = None):
            self.config = config or {}
            self.masker = None
            self.temp_files = []
            self.start_time = None
        
        def __enter__(self):
            self.start_time = time.time()
            self.masker = IndependentPcapMasker(self.config)
            print("ğŸš€ å¼€å§‹æ©ç å¤„ç†ä¼šè¯")
            return self
        
        def __exit__(self, exc_type, exc_val, exc_tb):
            end_time = time.time()
            session_time = end_time - self.start_time
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in self.temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                        print(f"   ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                except Exception as e:
                    print(f"   âš ï¸  æ¸…ç†æ–‡ä»¶å¤±è´¥: {temp_file} - {e}")
            
            if exc_type is None:
                print(f"âœ… æ©ç å¤„ç†ä¼šè¯å®Œæˆï¼Œè€—æ—¶ {session_time:.3f} ç§’")
            else:
                print(f"âŒ æ©ç å¤„ç†ä¼šè¯å¼‚å¸¸ç»“æŸ: {exc_val}")
                print(f"   ä¼šè¯è€—æ—¶: {session_time:.3f} ç§’")
            
            return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸
        
        def process_with_backup(self, input_file: str, mask_table: SequenceMaskTable, output_file: str) -> MaskingResult:
            """å¸¦å¤‡ä»½çš„å¤„ç†æ–¹æ³•"""
            # åˆ›å»ºå¤‡ä»½æ–‡ä»¶
            backup_file = f"{input_file}.backup"
            if not os.path.exists(backup_file):
                import shutil
                shutil.copy2(input_file, backup_file)
                self.temp_files.append(backup_file)
                print(f"   ğŸ“‹ åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
            
            # æ‰§è¡Œå¤„ç†
            result = self.masker.mask_pcap_with_sequences(input_file, mask_table, output_file)
            
            if result.success:
                print(f"   âœ… å¤„ç†æˆåŠŸï¼Œå¤‡ä»½å·²ä¿ç•™")
            else:
                print(f"   âŒ å¤„ç†å¤±è´¥ï¼Œå¯ä»å¤‡ä»½æ¢å¤")
            
            return result
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    session_config = {
        'log_level': 'INFO',
        'cleanup_temp_files': True
    }
    
    mask_table = SequenceMaskTable()
    mask_table.add_entry(MaskEntry(
        stream_id="TCP_192.168.1.100:443_10.0.0.1:54321_forward",
        sequence_start=1000,
        sequence_end=3000,
        mask_type="mask_after",
        mask_params={"keep_bytes": 8}
    ))
    
    test_file = "tests/samples/tls-single/tls_sample.pcap"
    output_file = "examples/output/processed/context_manager_test.pcap"
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    if os.path.exists(test_file):
        try:
            with MaskingSession(session_config) as session:
                result = session.process_with_backup(test_file, mask_table, output_file)
                
                if result.success:
                    print(f"   å¤„ç†ç»Ÿè®¡: {result.modified_packets}/{result.total_packets} åŒ…è¢«ä¿®æ”¹")
                
                return result
        
        except Exception as e:
            print(f"âŒ ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨å¼‚å¸¸: {str(e)}")
            return None
    else:
        print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        print("æ¼”ç¤ºä¸Šä¸‹æ–‡ç®¡ç†å™¨åŸºæœ¬ç”¨æ³•...")
        
        try:
            with MaskingSession(session_config) as session:
                print("   ä¼šè¯å·²å¯åŠ¨ï¼Œæ¨¡æ‹Ÿä¸€äº›æ“ä½œ...")
                time.sleep(0.1)
                print("   æ¨¡æ‹Ÿæ“ä½œå®Œæˆ")
        except Exception as e:
            print(f"âŒ ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¼”ç¤ºå¼‚å¸¸: {str(e)}")
        
        return None


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰é«˜çº§ç¤ºä¾‹"""
    print("ç‹¬ç«‹PCAPæ©ç å¤„ç†å™¨ - é«˜çº§ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºé«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¤æ‚æ©ç è¡¨ã€æ‰¹é‡å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰")
    print("æ³¨æ„: éƒ¨åˆ†ç¤ºä¾‹éœ€è¦å®é™…çš„PCAPæ–‡ä»¶æ‰èƒ½å®Œæ•´è¿è¡Œ")
    print()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dirs = [
        "examples/output",
        "examples/output/processed/batch_results",
        "examples/output/processed/parallel"
    ]
    
    for output_dir in output_dirs:
        Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # è¿è¡Œæ‰€æœ‰é«˜çº§ç¤ºä¾‹
    examples = [
        ("å¤æ‚æ©ç è¡¨åˆ›å»º", example_1_complex_mask_table_creation),
        ("æ€§èƒ½ä¼˜åŒ–é…ç½®", example_2_performance_optimization),
        ("æ‰¹é‡æ–‡ä»¶å¤„ç†", example_3_batch_processing),
        ("å¹¶è¡Œæ‰¹é‡å¤„ç†", example_4_parallel_batch_processing),
        ("åè®®è§£ææ§åˆ¶", example_5_protocol_parsing_control),
        ("ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨", example_6_context_manager_usage)
    ]
    
    results = {}
    successful_count = 0
    
    total_start_time = time.time()
    
    for example_name, example_func in examples:
        print(f"\n{'='*20} {example_name} {'='*20}")
        
        try:
            result = example_func()
            results[example_name] = result
            
            if result is not None:
                successful_count += 1
                status = "âœ… æˆåŠŸ"
            else:
                status = "âš ï¸  è·³è¿‡"
            
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            results[example_name] = None
            status = "âŒ å¤±è´¥"
        
        print(f"\n{example_name}: {status}")
    
    total_end_time = time.time()
    total_time = total_end_time - total_start_time
    
    # æ˜¾ç¤ºæ€»ç»“
    print("\n" + "=" * 60)
    print("é«˜çº§ç¤ºä¾‹æ‰§è¡Œæ€»ç»“")
    print("=" * 60)
    
    for example_name, result in results.items():
        if result is None:
            status = "âš ï¸  è·³è¿‡/å¤±è´¥"
        else:
            status = "âœ… æˆåŠŸ"
        
        print(f"   {example_name}: {status}")
    
    print(f"\næˆåŠŸè¿è¡Œ {successful_count}/{len(examples)} ä¸ªé«˜çº§ç¤ºä¾‹")
    print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
    print("\nç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶:")
    for output_dir in output_dirs:
        output_path = Path(output_dir)
        if output_path.exists():
            for file_path in output_path.rglob("*"):
                if file_path.is_file():
                    size = file_path.stat().st_size
                    relative_path = file_path.relative_to(Path("examples"))
                    print(f"   {relative_path}: {size:,} bytes")
    
    print("\né«˜çº§ä½¿ç”¨ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print("æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…APIæ–‡æ¡£å’ŒåŸºç¡€ä½¿ç”¨ç¤ºä¾‹")


if __name__ == "__main__":
    main() 