# HTTP Stream-Based Parsing and Masking Plan (Gemini v2.0)

## 1. 项目概述

### 1.1. 项目目标

本项目旨在彻底解决现有HTTP载荷掩码功能中头部保留不完整和消息体掩码不精确的问题。我们将用一种**基于流的解析（Stream-Based Parsing）**模型，取代当前基于独立数据包（Packet-Based）的启发式分析方法，以实现以下目标：

*   **HTTP头部保留率**: 100%
*   **HTTP消息体掩码率**: 100% (完全置零)
*   **多消息处理（Keep-Alive）**: 100% 支持
*   **关键协议机制支持**: 完整支持`Content-Length`和`Transfer-Encoding: chunked`

### 1.2. 核心思路转变：从"包"到"流"

*   **旧思路（当前）**: 逐个分析TCP数据包，猜测其是否包含HTTP头部，并估算头部大小。这种方法在HTTP头或消息边界被分割到多个TCP包时会彻底失败。
*   **新思路（本方案）**: 将属于同一个TCP会话方向的数据包载荷，按TCP序列号拼接成一个完整的、有序的字节流。所有HTTP协议的分析和边界检测都在这个重组后的"流"上进行，完美还原了HTTP协议的工作环境，从根本上消除了跨包边界问题。

## 2. 结合PktMask现有架构的方案设计

我们将充分利用现有的三阶段架构，仅对核心分析逻辑进行升级，保持系统其他部分的稳定。

```mermaid
graph TD
    subgraph A [现有流程]
        A1[原始PCAP] --> A2{TShark预处理器};
        A2 -->|重组后的PCAP| A3{PyShark分析器};
        A3 -->|掩码表 (MaskTable)| A4{Scapy回写器};
        A4 --> A5[处理后的PCAP];
    end

    subgraph B [本方案核心优化区域]
        B1(PyShark分析器内) --包含--> B2(HTTPTrimStrategy);
        B2 --将被重构为--> B3(HTTPStreamParser);
    end

    style B fill:#e6f3ff,stroke:#0066cc,stroke-width:2px
```

### 2.1. 关键组件和流程

#### **阶段一：方向性TCP流缓冲区 (在 `PySharkAnalyzer` 内)**

*   **目的**: 收集并按序重组TCP流。
*   **实现**:
    1.  `PySharkAnalyzer`在处理一个PCAP文件时，会按方向性的流ID（如 `TCP_IP1:Port1_IP2:Port2_forward`）将所有属于该流的数据包进行分组。
    2.  为每个流创建一个`DirectionalTCPStreamBuffer`对象。该对象的核心是一个有序字典或类似结构，以TCP序列号为键，存储数据包的载荷。
    3.  当一个流的所有包都收集完毕后，这个缓冲区能按顺序拼接所有载荷，生成一个完整的、单向的字节流（`byte stream`）。
    4.  **关键映射**: 在生成字节流的同时，必须创建一个**"流偏移量 -> (包序号, 包内偏移量)"**的映射表。这个映射表是后续将分析结果（Body在流中的位置）转换回具体掩码规范（MaskSpec）的唯一桥梁。

#### **阶段二：HTTP流解析器 (HTTPStreamParser)**

*   **目的**: 在重组后的字节流上，精确地识别所有HTTP消息的头部和消息体。它将取代现有`HTTPTrimStrategy`中的大部分逻辑。
*   **核心循环逻辑**:
    1.  **寻找头部边界**: 从流的当前位置开始，搜索第一个出现的 `\r\n\r\n`。如果找不到，则认为当前流中没有完整的HTTP头部，结束处理。
    2.  **解析头部**: 将`\r\n\r\n`之前的数据视为一个完整的HTTP头部。解析此头部，重点提取 `Content-Length` 和 `Transfer-Encoding` 两个关键字段。
    3.  **确定消息体范围**:
        *   **Case A: `Content-Length`**: 如果存在 `Content-Length: N`，则从 `\r\n\r\n` 之后算起，接下来的 `N` 个字节就是完整的消息体。
        *   **Case B: `Transfer-Encoding: chunked`**: （在进阶阶段实现）进入一个子循环，按照分块编码的规则（`chunk-size\r\nchunk-data\r\n`）进行解析，直到遇到表示结束的 `0\r\n\r\n`，从而确定整个消息体的范围。
        *   **Case C: 连接关闭**: （在进阶阶段实现）如果两者都没有，则认为消息体一直持续到流的末尾（或TCP FIN信号）。
    4.  **生成掩码指令**: 确定了消息体在**流中的起始和结束偏移量**后，使用第一阶段生成的**关键映射表**，将这个范围转换成一个或多个针对具体数据包的 `MaskRange(seq_start, seq_end)` 规范。
    5.  **推进与循环**: 将流的解析指针移动到当前消息体结束之后的位置，然后**返回步骤1**，继续在同一个流中寻找下一个HTTP消息（完美支持Keep-Alive）。

#### **阶段三：Scapy回写器 (`ScapyRewriter`)**

*   **职责**: **保持不变**。
*   **说明**: `ScapyRewriter`继续扮演"哑"执行者的角色。它不关心协议细节，只忠实地根据`PySharkAnalyzer`生成的掩码表（`StreamMaskTable`）对指定序列号范围的数据包载荷应用掩码。这种清晰的职责划分是健壮软件设计的体现。

## 3. 实施计划

### 阶段 1: 流重组与映射基础建设 (预计2天)

*   [ ] **任务1.1**: 在`PySharkAnalyzer`中实现按方向性流ID收集所有相关数据包的逻辑。
*   [ ] **任务1.2**: 创建`DirectionalTCPStreamBuffer`类，负责接收数据包列表，并能按序列号输出一个完整的、有序的字节流。
*   [ ] **任务1.3**: 在`DirectionalTCPStreamBuffer`中，实现"流偏移量 -> (包序号, 包内偏移量)"的映射表生成逻辑。
*   **验收标准**:
    *   能够将一个跨越多个TCP包的HTTP POST请求正确重组为一个连续的字节流。
    *   能够准确查询流中任意字节偏移量对应的是哪个数据包的哪个位置。

### 阶段 2: 核心HTTP流解析器实现 (预计3天)

*   [ ] **任务2.1**: 创建`HTTPStreamParser`类，其构造函数接收一个字节流和流偏移映射表。
*   [ ] **任务2.2**: 实现解析器的核心循环逻辑，支持`\r\n\r\n`边界查找和`Content-Length`头部的解析。
*   [ ] **任务2.3**: 实现根据`Content-Length`确定消息体范围，并利用映射表生成`MaskRange`掩码规范的逻辑。
*   [ ] **任务2.4**: 实现对HTTP Keep-Alive的支持，即在一个流中能够循环解析出多个HTTP消息。
*   **验收标准**:
    *   对于一个包含多个使用`Content-Length`的HTTP请求/响应的PCAP文件，能够为每一个消息体生成精确的掩码。
    *   单元测试覆盖率 > 90%。

### 阶段 3: 高级特性与集成 (预计2天)

*   [ ] **任务3.1**: (可选/进阶) 增强`HTTPStreamParser`以支持`Transfer-Encoding: chunked`。
*   [ ] **任务3.2**: 将新的`HTTPStreamParser`集成到`PySharkAnalyzer`中，完全替换掉`HTTPTrimStrategy`的旧有逻辑。
*   [ ] **任务3.3**: 创建完整的集成测试，使用包含复杂场景（如大头部跨包、小Body、连续POST请求）的真实PCAP文件进行端到端验证。
*   **验收标准**:
    *   通过所有集成测试，处理后的PCAP文件用Wireshark打开，能看到HTTP头部完整，而消息体被准确置零。
    *   系统性能无显著下降（与基线相比 < 10%）。

## 4. 预期成果与风险分析

### 4.1. 预期成果

1.  **精确性**: 从根本上解决边界检测问题，实现100%精确的头部保留和消息体掩码。
2.  **健壮性**: 能够正确处理Keep-Alive等真实世界的复杂HTTP场景。
3.  **可维护性**: 软件架构更加清晰，职责划分明确。`PySharkAnalyzer`负责"分析决策"，`ScapyRewriter`负责"掩码执行"，便于未来维护和扩展。
4.  **技术债务消除**: 彻底偿还在HTTP协议处理上因"逐包分析"而欠下的技术债务。

### 4.2. 风险分析

*   **内存消耗**: 对于包含极大流量（如几GB的文件下载）的TCP流，在内存中完整重组字节流可能会消耗大量内存。
    *   **缓解措施**: 可以为流缓冲区设置一个最大大小限制（如10MB），超过则放弃对该流的精确分析，回退到保守的`KeepAll`策略。
*   **映射表复杂性**: "流偏移->包"的映射逻辑是本方案的技术关键点，实现需要非常仔细，否则容易出错。
    *   **缓解措施**: 针对此模块编写详尽的单元测试，覆盖所有边界情况。 