#!/usr/bin/env python3
"""
TCPè½½è·æ©ç å™¨åœºæ™¯æµ‹è¯•éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯test_scenarios/ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶å’Œæ‰§è¡Œåœºæ™¯æµ‹è¯•
"""

import os
import sys
import yaml
import json
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional
import shutil

class TcpMaskerScenarioValidator:
    def __init__(self):
        self.scenarios_dir = Path("test_scenarios")
        self.sample_file = Path("tests/data/tls-single/tls_sample.pcap")
        self.analysis_file = Path("scripts/tls_sample_analysis.json")
        self.output_dir = Path("test_outputs")
        self.test_script = Path("run_tcp_masker_test.py")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½åˆ†æç»“æœ
        with open(self.analysis_file, 'r', encoding='utf-8') as f:
            self.analysis_data = json.load(f)
    
    def validate_scenario_configs(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰åœºæ™¯é…ç½®æ–‡ä»¶çš„æ­£ç¡®æ€§"""
        print("ğŸ” éªŒè¯æµ‹è¯•åœºæ™¯é…ç½®æ–‡ä»¶...")
        validation_results = {}
        
        scenario_files = list(self.scenarios_dir.glob("scenario_*.yaml"))
        if not scenario_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•åœºæ™¯é…ç½®æ–‡ä»¶")
            return {}
        
        for scenario_file in sorted(scenario_files):
            print(f"\nğŸ“„ éªŒè¯åœºæ™¯: {scenario_file.name}")
            result = self._validate_single_scenario(scenario_file)
            validation_results[scenario_file.name] = result
            
            # æ‰“å°éªŒè¯ç»“æœ
            if result['valid']:
                print(f"  âœ… é…ç½®æœ‰æ•ˆ: {result['metadata']['name']}")
                print(f"  ğŸ“Š é¢„æœŸä¿®æ”¹åŒ…æ•°: {result['metadata']['expected_modified_packets']}")
                print(f"  ğŸ“¦ æ©ç å­—èŠ‚æ•°: {result['metadata']['expected_masked_bytes']}")
            else:
                print(f"  âŒ é…ç½®æ— æ•ˆ: {', '.join(result['errors'])}")
        
        return validation_results
    
    def _validate_single_scenario(self, scenario_file: Path) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªåœºæ™¯é…ç½®æ–‡ä»¶"""
        result = {
            'valid': False,
            'errors': [],
            'metadata': {},
            'keep_range_rules': [],
            'verification': {}
        }
        
        try:
            with open(scenario_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_sections = ['metadata', 'keep_range_rules', 'verification']
            for section in required_sections:
                if section not in config:
                    result['errors'].append(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®æ®µ: {section}")
            
            if result['errors']:
                return result
            
            # éªŒè¯metadata
            metadata = config['metadata']
            required_metadata = ['name', 'description', 'expected_modified_packets', 'test_type']
            for field in required_metadata:
                if field not in metadata:
                    result['errors'].append(f"metadataç¼ºå°‘å­—æ®µ: {field}")
            
            # éªŒè¯keep_range_rules
            keep_rules = config['keep_range_rules']
            if not isinstance(keep_rules, list):
                result['errors'].append("keep_range_ruleså¿…é¡»æ˜¯åˆ—è¡¨")
            else:
                for i, rule in enumerate(keep_rules):
                    rule_errors = self._validate_keep_range_rule(rule, i)
                    result['errors'].extend(rule_errors)
            
            # éªŒè¯verification
            verification = config['verification']
            if 'target_packets' not in verification:
                result['errors'].append("verificationç¼ºå°‘target_packetså­—æ®µ")
            
            if not result['errors']:
                result['valid'] = True
                result['metadata'] = metadata
                result['keep_range_rules'] = keep_rules
                result['verification'] = verification
        
        except Exception as e:
            result['errors'].append(f"é…ç½®æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
        
        return result
    
    def _validate_keep_range_rule(self, rule: Dict, index: int) -> List[str]:
        """éªŒè¯å•ä¸ªä¿ç•™èŒƒå›´è§„åˆ™"""
        errors = []
        required_fields = ['stream_id', 'sequence_start', 'sequence_end']
        
        for field in required_fields:
            if field not in rule:
                errors.append(f"è§„åˆ™{index}ç¼ºå°‘å­—æ®µ: {field}")
        
        # éªŒè¯åºåˆ—å·èŒƒå›´
        if 'sequence_start' in rule and 'sequence_end' in rule:
            if rule['sequence_start'] >= rule['sequence_end']:
                errors.append(f"è§„åˆ™{index}åºåˆ—å·èŒƒå›´æ— æ•ˆ: start >= end")
        
        # éªŒè¯stream_idæ ¼å¼
        if 'stream_id' in rule:
            stream_id = rule['stream_id']
            if not stream_id.startswith('TCP_'):
                errors.append(f"è§„åˆ™{index}æµIDæ ¼å¼é”™è¯¯: {stream_id}")
            if not (stream_id.endswith('_forward') or stream_id.endswith('_reverse')):
                errors.append(f"è§„åˆ™{index}æµIDç¼ºå°‘æ–¹å‘åç¼€: {stream_id}")
        
        return errors
    
    def run_scenario_test(self, scenario_name: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªåœºæ™¯æµ‹è¯•"""
        scenario_file = self.scenarios_dir / f"{scenario_name}.yaml"
        if not scenario_file.exists():
            return {'success': False, 'error': f"åœºæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {scenario_file}"}
        
        print(f"\nğŸš€ æ‰§è¡Œåœºæ™¯æµ‹è¯•: {scenario_name}")
        
        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶
        output_file = self.output_dir / f"{scenario_name}_output.pcap"
        
        try:
            # æ‰§è¡Œæµ‹è¯•å‘½ä»¤
            cmd = [
                sys.executable, str(self.test_script),
                "--input-pcap", str(self.sample_file),
                "--config", str(scenario_file),
                "--output-pcap", str(output_file),
                "--log-level", "DEBUG"
            ]
            
            print(f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                print("âœ… æµ‹è¯•æ‰§è¡ŒæˆåŠŸ")
                # åˆ†æè¾“å‡ºç»“æœ
                analysis = self._analyze_test_output(scenario_name, output_file, result.stdout)
                return {'success': True, 'analysis': analysis, 'stdout': result.stdout}
            else:
                print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {result.stderr}")
                return {'success': False, 'error': result.stderr, 'stdout': result.stdout}
        
        except subprocess.TimeoutExpired:
            return {'success': False, 'error': "æµ‹è¯•æ‰§è¡Œè¶…æ—¶"}
        except Exception as e:
            return {'success': False, 'error': f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}"}
    
    def _analyze_test_output(self, scenario_name: str, output_file: Path, stdout: str) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•è¾“å‡ºç»“æœ"""
        analysis = {
            'file_exists': output_file.exists(),
            'file_size': 0,
            'modified_packets': 0,
            'stdout_analysis': {}
        }
        
        if output_file.exists():
            analysis['file_size'] = output_file.stat().st_size
        
        # åˆ†æstdoutä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        lines = stdout.split('\n')
        for line in lines:
            if 'ä¿®æ”¹äº†' in line and 'ä¸ªæ•°æ®åŒ…' in line:
                # æå–ä¿®æ”¹çš„åŒ…æ•°é‡
                try:
                    # æŸ¥æ‰¾å½¢å¦‚ "2/22 ä¸ªæ•°æ®åŒ…è¢«ä¿®æ”¹" çš„æ¨¡å¼
                    import re
                    match = re.search(r'(\d+)/\d+\s*ä¸ªæ•°æ®åŒ…è¢«ä¿®æ”¹', line)
                    if match:
                        analysis['modified_packets'] = int(match.group(1))
                except:
                    pass
            
            if 'æ©ç å­—èŠ‚:' in line:
                try:
                    # æå–æ©ç å­—èŠ‚æ•°ï¼Œæ ¼å¼: "æ©ç å­—èŠ‚: 306"
                    parts = line.split('æ©ç å­—èŠ‚:')[1].split(',')[0]
                    analysis['stdout_analysis']['masked_bytes'] = int(parts.strip())
                except:
                    pass
            
            if 'ä¿ç•™å­—èŠ‚:' in line:
                try:
                    # æå–ä¿ç•™å­—èŠ‚æ•°ï¼Œæ ¼å¼: "ä¿ç•™å­—èŠ‚: 10"
                    parts = line.split('ä¿ç•™å­—èŠ‚:')[1].split('(')[0]
                    analysis['stdout_analysis']['kept_bytes'] = int(parts.strip())
                except:
                    pass
        
        return analysis
    
    def run_all_scenarios(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰åœºæ™¯æµ‹è¯•"""
        print("ğŸ¯ å¼€å§‹æ‰§è¡Œæ‰€æœ‰åœºæ™¯æµ‹è¯•...")
        
        # é¦–å…ˆéªŒè¯é…ç½®
        validation_results = self.validate_scenario_configs()
        
        # æ‰§è¡Œæµ‹è¯•
        test_results = {}
        valid_scenarios = [name for name, result in validation_results.items() if result['valid']]
        
        for scenario_file in valid_scenarios:
            scenario_name = scenario_file.replace('.yaml', '')
            test_result = self.run_scenario_test(scenario_name)
            test_results[scenario_name] = test_result
        
        return {
            'validation': validation_results,
            'tests': test_results,
            'summary': self._generate_test_summary(validation_results, test_results)
        }
    
    def _generate_test_summary(self, validation_results: Dict, test_results: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        total_scenarios = len(validation_results)
        valid_scenarios = sum(1 for r in validation_results.values() if r['valid'])
        successful_tests = sum(1 for r in test_results.values() if r['success'])
        
        return {
            'total_scenarios': total_scenarios,
            'valid_scenarios': valid_scenarios,
            'successful_tests': successful_tests,
            'validation_rate': valid_scenarios / total_scenarios if total_scenarios > 0 else 0,
            'success_rate': successful_tests / valid_scenarios if valid_scenarios > 0 else 0
        }
    
    def generate_test_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
        report = []
        report.append("# TCPè½½è·æ©ç å™¨åœºæ™¯æµ‹è¯•æŠ¥å‘Š")
        report.append("")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {self._get_timestamp()}")
        report.append("")
        
        # æ€»ç»“ä¿¡æ¯
        summary = results['summary']
        report.append("## æµ‹è¯•æ€»ç»“")
        report.append(f"- **æ€»åœºæ™¯æ•°**: {summary['total_scenarios']}")
        report.append(f"- **æœ‰æ•ˆåœºæ™¯æ•°**: {summary['valid_scenarios']}")
        report.append(f"- **æˆåŠŸæµ‹è¯•æ•°**: {summary['successful_tests']}")
        report.append(f"- **é…ç½®éªŒè¯ç‡**: {summary['validation_rate']:.1%}")
        report.append(f"- **æµ‹è¯•æˆåŠŸç‡**: {summary['success_rate']:.1%}")
        report.append("")
        
        # åœºæ™¯è¯¦æƒ…
        report.append("## åœºæ™¯æµ‹è¯•è¯¦æƒ…")
        for scenario_name, test_result in results['tests'].items():
            report.append(f"### {scenario_name}")
            if test_result['success']:
                analysis = test_result['analysis']
                report.append(f"- âœ… **æµ‹è¯•çŠ¶æ€**: æˆåŠŸ")
                report.append(f"- **è¾“å‡ºæ–‡ä»¶**: å­˜åœ¨ ({analysis['file_size']} å­—èŠ‚)")
                report.append(f"- **ä¿®æ”¹åŒ…æ•°**: {analysis['modified_packets']}")
            else:
                report.append(f"- âŒ **æµ‹è¯•çŠ¶æ€**: å¤±è´¥")
                report.append(f"- **é”™è¯¯ä¿¡æ¯**: {test_result['error']}")
            report.append("")
        
        return "\n".join(report)
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def main():
    """ä¸»å‡½æ•°"""
    validator = TcpMaskerScenarioValidator()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "validate":
            # åªéªŒè¯é…ç½®
            results = validator.validate_scenario_configs()
            print(f"\nğŸ“Š éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆåœºæ™¯: {sum(1 for r in results.values() if r['valid'])}/{len(results)}")
        
        elif command == "test":
            if len(sys.argv) > 2:
                # æµ‹è¯•å•ä¸ªåœºæ™¯
                scenario_name = sys.argv[2]
                result = validator.run_scenario_test(scenario_name)
                if result['success']:
                    print(f"âœ… åœºæ™¯ {scenario_name} æµ‹è¯•æˆåŠŸ")
                else:
                    print(f"âŒ åœºæ™¯ {scenario_name} æµ‹è¯•å¤±è´¥: {result['error']}")
            else:
                print("âŒ è¯·æŒ‡å®šè¦æµ‹è¯•çš„åœºæ™¯åç§°")
        
        elif command == "all":
            # è¿è¡Œæ‰€æœ‰æµ‹è¯•
            results = validator.run_all_scenarios()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = validator.generate_test_report(results)
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = Path("test_outputs/scenario_test_report.md")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            print(f"âœ… æµ‹è¯•æˆåŠŸç‡: {results['summary']['success_rate']:.1%}")
        
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
    
    else:
        print("TCPè½½è·æ©ç å™¨åœºæ™¯æµ‹è¯•å·¥å…·")
        print("ç”¨æ³•:")
        print("  python test_tcp_masker_scenarios.py validate  # éªŒè¯é…ç½®æ–‡ä»¶")
        print("  python test_tcp_masker_scenarios.py test <scenario_name>  # æµ‹è¯•å•ä¸ªåœºæ™¯")
        print("  python test_tcp_masker_scenarios.py all       # è¿è¡Œæ‰€æœ‰æµ‹è¯•")

if __name__ == "__main__":
    main() 