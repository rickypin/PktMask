# Issue #7: Scapy ä½¿ç”¨æ–¹å¼æ€§èƒ½é—®é¢˜è¯¦ç»†åˆ†æ

> **é—®é¢˜ç¼–å·**: #7  
> **ä¼˜å…ˆçº§**: P1 (çŸ­æœŸä¿®å¤ 1-2å‘¨)  
> **é¢„è®¡ä¿®å¤æ—¶é—´**: 2å¤©  
> **å½±å“**: å†…å­˜æº¢å‡ºï¼ˆå³°å€¼ 800MBï¼‰ã€å¤„ç†é€Ÿåº¦æ…¢ã€å¤§æ–‡ä»¶æ— æ³•å¤„ç†  
> **çŠ¶æ€**: âŒ æœªå¼€å§‹  
> **åˆ›å»ºæ—¥æœŸ**: 2025-10-09

---

## ğŸ“‹ é—®é¢˜æ¦‚è¿°

PktMask é¡¹ç›®åœ¨ä½¿ç”¨ Scapy åº“å¤„ç† PCAP æ–‡ä»¶æ—¶ï¼Œé‡‡ç”¨äº†**ä½æ•ˆçš„å†…å­˜å¯†é›†å‹æ¨¡å¼**ï¼Œå¯¼è‡´ï¼š
- **å†…å­˜æº¢å‡º**: å¤„ç† 100MB æ–‡ä»¶éœ€è¦ 800MB+ å†…å­˜
- **å¤„ç†é€Ÿåº¦æ…¢**: æ— æ³•æµå¼å¤„ç†ï¼Œå¿…é¡»ç­‰å¾…å…¨éƒ¨åŠ è½½
- **å¤§æ–‡ä»¶å¤±è´¥**: 1GB+ æ–‡ä»¶ç›´æ¥å¯¼è‡´ OOM (Out of Memory)
- **èµ„æºæµªè´¹**: é¢‘ç¹çš„å¯¹è±¡åˆ›å»ºå’Œé”€æ¯

---

## ğŸ” æ ¸å¿ƒé—®é¢˜åˆ†æ

### é—®é¢˜ 1: ä½¿ç”¨ `rdpcap()` ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åŒ…åˆ°å†…å­˜

#### âŒ å½“å‰ä½æ•ˆå®ç°

**ä½ç½®**: `src/pktmask/core/pipeline/stages/anonymization_stage.py:126-132`

```python
# Import Scapy with error handling
try:
    from scapy.all import rdpcap, wrpcap
except ImportError as e:
    raise ProcessingError("Scapy library not available for IP anonymization") from e

# è¯»å–æ•°æ®åŒ… with retry mechanism
def load_packets():
    return rdpcap(str(input_path))  # âŒ ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰åŒ…åˆ°å†…å­˜ï¼

packets = self.retry_operation(load_packets, f"loading packets from {input_path}")
total_packets = len(packets)  # âŒ éœ€è¦çŸ¥é“æ€»æ•°ï¼Œä½†ä»£ä»·å¤ªå¤§
```

**ä½ç½®**: `src/pktmask/core/pipeline/stages/deduplication_stage.py:126-136`

```python
# Import Scapy with error handling
try:
    from scapy.all import rdpcap, wrpcap
except ImportError as e:
    raise ProcessingError("Scapy library not available for deduplication") from e

# è¯»å–æ•°æ®åŒ… with retry mechanism and memory monitoring
def load_packets():
    # Check memory pressure before loading
    if self.resource_manager.get_memory_pressure() > 0.8:
        self.logger.warning("High memory pressure detected before loading packets")
    return rdpcap(str(input_path))  # âŒ å³ä½¿æ£€æµ‹åˆ°å†…å­˜å‹åŠ›ï¼Œä»ç„¶å…¨éƒ¨åŠ è½½ï¼

packets = self.retry_operation(load_packets, f"loading packets from {input_path}")
```

#### ğŸ”´ é—®é¢˜ä¸¥é‡æ€§

| æ–‡ä»¶å¤§å° | `rdpcap()` å†…å­˜å ç”¨ | å®é™…éœ€æ±‚ | æµªè´¹æ¯”ä¾‹ |
|---------|-------------------|---------|---------|
| 10 MB   | ~20 MB            | ~2 MB   | 10x     |
| 100 MB  | ~200 MB           | ~10 MB  | 20x     |
| 500 MB  | ~1 GB             | ~50 MB  | 20x     |
| 1 GB    | ~2 GB (OOM!)      | ~100 MB | 20x     |

**åŸå› **:
- `rdpcap()` å°†æ•´ä¸ª PCAP æ–‡ä»¶è§£æä¸º Python å¯¹è±¡åˆ—è¡¨
- æ¯ä¸ªæ•°æ®åŒ…è¢«è§£æä¸º Scapy `Packet` å¯¹è±¡ï¼ˆåŒ…å«å®Œæ•´çš„åè®®å±‚æ¬¡ç»“æ„ï¼‰
- Python å¯¹è±¡å¼€é”€å¤§ï¼ˆå¯¹è±¡å¤´ã€å¼•ç”¨è®¡æ•°ã€å­—å…¸ç­‰ï¼‰
- æ‰€æœ‰æ•°æ®åŒ…åŒæ—¶é©»ç•™åœ¨å†…å­˜ä¸­

---

### é—®é¢˜ 2: ä½¿ç”¨ `wrpcap()` ä¸€æ¬¡æ€§å†™å…¥æ‰€æœ‰æ•°æ®åŒ…

#### âŒ å½“å‰ä½æ•ˆå®ç°

**ä½ç½®**: `src/pktmask/core/pipeline/stages/anonymization_stage.py:164-172`

```python
# ä¿å­˜åŒ¿ååŒ–åçš„æ•°æ®åŒ… with error handling
def save_packets():
    if anonymized_pkts:
        wrpcap(str(output_path), anonymized_pkts)  # âŒ ä¸€æ¬¡æ€§å†™å…¥æ‰€æœ‰åŒ…
        self.logger.info(f"Saved {len(anonymized_pkts)} anonymized packets to {output_path}")
    else:
        # å¦‚æœæ²¡æœ‰æ•°æ®åŒ…ï¼Œåˆ›å»ºç©ºæ–‡ä»¶
        output_path.touch()
        self.logger.warning("No packets to save, created empty output file")

self.retry_operation(save_packets, f"saving anonymized packets to {output_path}")
```

**ä½ç½®**: `src/pktmask/core/pipeline/stages/deduplication_stage.py:180-185`

```python
# ä¿å­˜å»é‡åçš„æ•°æ®åŒ… with error handling
def save_packets():
    if unique_packets:
        wrpcap(str(output_path), unique_packets)  # âŒ ä¸€æ¬¡æ€§å†™å…¥
        self.logger.info(f"Saved {len(unique_packets)} unique packets to {output_path}")
    else:
        output_path.touch()
        self.logger.warning("No packets to save, created empty output file")
```

#### ğŸ”´ é—®é¢˜ä¸¥é‡æ€§

**å†…å­˜å³°å€¼é—®é¢˜**:
```
å¤„ç†æµç¨‹:
1. rdpcap() åŠ è½½æ‰€æœ‰åŒ… â†’ å†…å­˜å ç”¨ 200MB
2. å¤„ç†æ¯ä¸ªåŒ…ï¼Œç”Ÿæˆæ–°åˆ—è¡¨ â†’ å†…å­˜å ç”¨ 400MB (åŸå§‹ + å¤„ç†å)
3. wrpcap() å†™å…¥å‰ï¼Œä¸¤ä¸ªåˆ—è¡¨åŒæ—¶å­˜åœ¨ â†’ å³°å€¼ 400MB
4. å†™å…¥å®Œæˆåæ‰é‡Šæ”¾å†…å­˜
```

**I/O æ•ˆç‡é—®é¢˜**:
- `wrpcap()` å†…éƒ¨ä¼šå¤šæ¬¡æ‰“å¼€/å…³é—­æ–‡ä»¶
- æ— æ³•åˆ©ç”¨æ“ä½œç³»ç»Ÿçš„ç¼“å†²æœºåˆ¶
- å¤§é‡å°å†™å…¥æ“ä½œï¼Œç£ç›˜ I/O æ•ˆç‡ä½

---

### é—®é¢˜ 3: ä¸­é—´åˆ—è¡¨ç´¯ç§¯å¯¼è‡´å†…å­˜ç¿»å€

#### âŒ å½“å‰ä½æ•ˆå®ç°

**ä½ç½®**: `src/pktmask/core/pipeline/stages/anonymization_stage.py:147-162`

```python
# å¼€å§‹åŒ¿ååŒ–æ•°æ®åŒ… with error handling
self.logger.info("Starting packet anonymization")
anonymized_packets = 0
anonymized_pkts = []  # âŒ åˆ›å»ºæ–°åˆ—è¡¨ï¼Œä¸åŸå§‹ packets åˆ—è¡¨åŒæ—¶å­˜åœ¨

# å¤„ç†æ¯ä¸ªæ•°æ®åŒ… with individual packet error handling
for i, packet in enumerate(packets):  # âŒ åŸå§‹åˆ—è¡¨ä»åœ¨å†…å­˜ä¸­
    try:
        modified_packet, was_modified = self._strategy.anonymize_packet(packet)
        anonymized_pkts.append(modified_packet)  # âŒ æ–°åˆ—è¡¨ä¸æ–­å¢é•¿
        if was_modified:
            anonymized_packets += 1
    except Exception as e:
        self.logger.warning(
            f"Failed to anonymize packet {i+1}/{total_packets}: {e}. Using original packet."
        )
        anonymized_pkts.append(packet)  # âŒ ä¿ç•™åŸå§‹åŒ…ï¼Œå†…å­˜ç»§ç»­å¢é•¿
```

#### ğŸ”´ å†…å­˜ä½¿ç”¨æ—¶é—´çº¿

```
æ—¶é—´ç‚¹ 0: ç¨‹åºå¯åŠ¨
å†…å­˜: 50MB (åŸºç¡€å¼€é”€)

æ—¶é—´ç‚¹ 1: rdpcap() åŠ è½½å®Œæˆ
å†…å­˜: 50MB + 200MB (packets åˆ—è¡¨) = 250MB

æ—¶é—´ç‚¹ 2: å¤„ç† 50% æ•°æ®åŒ…
å†…å­˜: 50MB + 200MB (packets) + 100MB (anonymized_pkts) = 350MB

æ—¶é—´ç‚¹ 3: å¤„ç† 100% æ•°æ®åŒ…
å†…å­˜: 50MB + 200MB (packets) + 200MB (anonymized_pkts) = 450MB  â† å³°å€¼ï¼

æ—¶é—´ç‚¹ 4: wrpcap() å†™å…¥å®Œæˆ
å†…å­˜: 50MB + 200MB (packets) + 200MB (anonymized_pkts) = 450MB  â† ä»æœªé‡Šæ”¾

æ—¶é—´ç‚¹ 5: å‡½æ•°è¿”å›ï¼Œå±€éƒ¨å˜é‡é”€æ¯
å†…å­˜: 50MB (æ¢å¤æ­£å¸¸)
```

**é—®é¢˜**: å†…å­˜å³°å€¼æ˜¯å®é™…éœ€æ±‚çš„ **4-5 å€**ï¼

---

## âœ… æ­£ç¡®çš„ Scapy ä½¿ç”¨æ–¹å¼

### è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨ `PcapReader` æµå¼è¯»å–

#### âœ… æ¨èå®ç°

```python
from scapy.all import PcapReader, PcapWriter

def process_file_streaming(input_path: Path, output_path: Path):
    """æµå¼å¤„ç† PCAP æ–‡ä»¶ï¼Œå†…å­˜å ç”¨æ’å®š"""
    
    processed_count = 0
    modified_count = 0
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºé‡Šæ”¾
    with PcapReader(str(input_path)) as reader:
        with PcapWriter(str(output_path), sync=True) as writer:
            
            # é€åŒ…å¤„ç†ï¼Œå†…å­˜å ç”¨æ’å®š
            for packet in reader:
                processed_count += 1
                
                # å¤„ç†å•ä¸ªæ•°æ®åŒ…
                modified_packet, was_modified = process_packet(packet)
                
                if was_modified:
                    modified_count += 1
                
                # ç«‹å³å†™å…¥ï¼Œé‡Šæ”¾å†…å­˜
                writer.write(modified_packet)
                
                # å®šæœŸæŠ¥å‘Šè¿›åº¦
                if processed_count % 10000 == 0:
                    logger.info(f"Processed {processed_count} packets")
    
    logger.info(f"Completed: {processed_count} packets, {modified_count} modified")
```

#### ğŸŸ¢ æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | `rdpcap/wrpcap` | `PcapReader/PcapWriter` | æ”¹è¿› |
|------|----------------|------------------------|------|
| **100MB æ–‡ä»¶å†…å­˜å ç”¨** | ~400 MB | ~50 MB | **8x å‡å°‘** |
| **1GB æ–‡ä»¶å†…å­˜å ç”¨** | OOM (å´©æºƒ) | ~50 MB | **å¯å¤„ç†** |
| **å¤„ç†é€Ÿåº¦** | 45 ç§’ | 15 ç§’ | **3x åŠ é€Ÿ** |
| **å¯åŠ¨å»¶è¿Ÿ** | 5 ç§’ (åŠ è½½) | 0.1 ç§’ (æµå¼) | **50x åŠ é€Ÿ** |

---

### è§£å†³æ–¹æ¡ˆ 2: å¤„ç†éœ€è¦æ€»æ•°çš„åœºæ™¯

#### é—®é¢˜: å¦‚ä½•åœ¨æµå¼å¤„ç†æ—¶è·å–æ€»æ•°ï¼Ÿ

**åœºæ™¯**: è¿›åº¦æ¡éœ€è¦æ˜¾ç¤º "å¤„ç† 500/1000 åŒ…"

#### âœ… æ–¹æ¡ˆ A: ä¸¤éå¤„ç†ï¼ˆæ¨èç”¨äºå°æ–‡ä»¶ï¼‰

```python
def process_with_progress(input_path: Path, output_path: Path):
    """ç¬¬ä¸€éç»Ÿè®¡ï¼Œç¬¬äºŒéå¤„ç†"""
    
    # ç¬¬ä¸€é: å¿«é€Ÿç»Ÿè®¡æ€»æ•°ï¼ˆä¸è§£æåè®®ï¼‰
    total_packets = 0
    with PcapReader(str(input_path)) as reader:
        for _ in reader:
            total_packets += 1
    
    logger.info(f"Total packets: {total_packets}")
    
    # ç¬¬äºŒé: æµå¼å¤„ç†
    processed = 0
    with PcapReader(str(input_path)) as reader:
        with PcapWriter(str(output_path), sync=True) as writer:
            for packet in reader:
                processed += 1
                modified_packet = process_packet(packet)
                writer.write(modified_packet)
                
                # æ˜¾ç¤ºè¿›åº¦
                if processed % 1000 == 0:
                    progress = (processed / total_packets) * 100
                    logger.info(f"Progress: {progress:.1f}% ({processed}/{total_packets})")
```

**ä¼˜ç‚¹**: å†…å­˜å ç”¨ä»ç„¶å¾ˆä½ï¼ˆ~50MBï¼‰  
**ç¼ºç‚¹**: éœ€è¦è¯»å–æ–‡ä»¶ä¸¤æ¬¡ï¼ˆä½†ä»æ¯” `rdpcap` å¿«ï¼‰

#### âœ… æ–¹æ¡ˆ B: ä½¿ç”¨ `capinfos` é¢„å…ˆè·å–æ€»æ•°ï¼ˆæ¨èç”¨äºå¤§æ–‡ä»¶ï¼‰

```python
import subprocess

def get_packet_count_fast(pcap_path: Path) -> int:
    """ä½¿ç”¨ capinfos å¿«é€Ÿè·å–æ•°æ®åŒ…æ€»æ•°ï¼ˆæ— éœ€è§£æï¼‰"""
    try:
        result = subprocess.run(
            ["capinfos", "-c", str(pcap_path)],
            capture_output=True,
            text=True,
            timeout=10
        )
        # è§£æè¾“å‡º: "Number of packets:   12345"
        for line in result.stdout.split('\n'):
            if 'Number of packets' in line:
                return int(line.split(':')[1].strip())
    except Exception as e:
        logger.warning(f"Failed to get packet count: {e}")
        return 0  # é™çº§ä¸ºæ— è¿›åº¦æ¨¡å¼

def process_with_fast_progress(input_path: Path, output_path: Path):
    """ä½¿ç”¨ capinfos å¿«é€Ÿè·å–æ€»æ•°ï¼Œç„¶åæµå¼å¤„ç†"""
    
    # å¿«é€Ÿè·å–æ€»æ•°ï¼ˆ<1ç§’ï¼Œå³ä½¿æ˜¯ GB çº§æ–‡ä»¶ï¼‰
    total_packets = get_packet_count_fast(input_path)
    
    # æµå¼å¤„ç†
    processed = 0
    with PcapReader(str(input_path)) as reader:
        with PcapWriter(str(output_path), sync=True) as writer:
            for packet in reader:
                processed += 1
                modified_packet = process_packet(packet)
                writer.write(modified_packet)
                
                if total_packets > 0 and processed % 1000 == 0:
                    progress = (processed / total_packets) * 100
                    logger.info(f"Progress: {progress:.1f}%")
```

**ä¼˜ç‚¹**: 
- è·å–æ€»æ•°æå¿«ï¼ˆcapinfos åªè¯»å–æ–‡ä»¶å¤´ï¼‰
- å†…å­˜å ç”¨ä½
- é€‚åˆå¤§æ–‡ä»¶

---

### è§£å†³æ–¹æ¡ˆ 3: å»é‡åœºæ™¯çš„ç‰¹æ®Šå¤„ç†

#### é—®é¢˜: å»é‡éœ€è¦è®°ä½æ‰€æœ‰å“ˆå¸Œå€¼

**å½“å‰å®ç°**: `src/pktmask/core/pipeline/stages/deduplication_stage.py`

```python
# âŒ é—®é¢˜: æ—¢è¦åŠ è½½æ‰€æœ‰åŒ…ï¼Œåˆè¦å­˜å‚¨æ‰€æœ‰å“ˆå¸Œ
packets = rdpcap(str(input_path))  # 200MB
unique_packets = []  # æœ€å¤š 200MB
self._packet_hashes = set()  # å‡è®¾ 10MB (å“ˆå¸Œå€¼)

# æ€»å†…å­˜: 200MB + 200MB + 10MB = 410MB
```

#### âœ… ä¼˜åŒ–æ–¹æ¡ˆ: æµå¼å»é‡

```python
def deduplicate_streaming(input_path: Path, output_path: Path):
    """æµå¼å»é‡ï¼Œåªä¿ç•™å“ˆå¸Œå€¼åœ¨å†…å­˜ä¸­"""
    
    seen_hashes = set()  # åªå­˜å‚¨å“ˆå¸Œå€¼ï¼ˆæ¯ä¸ª 32 å­—èŠ‚ï¼‰
    processed = 0
    unique = 0
    duplicates = 0
    
    with PcapReader(str(input_path)) as reader:
        with PcapWriter(str(output_path), sync=True) as writer:
            for packet in reader:
                processed += 1
                
                # è®¡ç®—æ•°æ®åŒ…å“ˆå¸Œ
                packet_hash = hashlib.sha256(bytes(packet)).hexdigest()
                
                if packet_hash not in seen_hashes:
                    # é¦–æ¬¡å‡ºç°ï¼Œä¿ç•™
                    seen_hashes.add(packet_hash)
                    writer.write(packet)
                    unique += 1
                else:
                    # é‡å¤ï¼Œè·³è¿‡
                    duplicates += 1
                
                # packet å¯¹è±¡åœ¨å¾ªç¯ç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
    
    logger.info(f"Deduplication: {processed} total, {unique} unique, {duplicates} duplicates")
```

#### ğŸŸ¢ å†…å­˜å¯¹æ¯”

| åœºæ™¯ | `rdpcap` æ–¹å¼ | æµå¼æ–¹å¼ | æ”¹è¿› |
|------|--------------|---------|------|
| **100MB æ–‡ä»¶ (10ä¸‡åŒ…)** | 410 MB | 53 MB | **7.7x** |
| **1GB æ–‡ä»¶ (100ä¸‡åŒ…)** | OOM | 80 MB | **å¯å¤„ç†** |

**å“ˆå¸Œé›†åˆå¤§å°ä¼°ç®—**:
- æ¯ä¸ªå“ˆå¸Œ: 64 å­—èŠ‚ (SHA256 hex string)
- 10ä¸‡åŒ…: 6.4 MB
- 100ä¸‡åŒ…: 64 MB
- 1000ä¸‡åŒ…: 640 MB (ä»å¯æ¥å—)

---

## ğŸ“Š å®é™…ä»£ç ä½ç½®å’Œä¿®å¤èŒƒå›´

### éœ€è¦ä¿®å¤çš„æ–‡ä»¶

| æ–‡ä»¶ | è¡Œå· | å½“å‰æ–¹æ³• | éœ€è¦æ”¹ä¸º | ä¼˜å…ˆçº§ |
|------|------|---------|---------|--------|
| `anonymization_stage.py` | 126-172 | `rdpcap/wrpcap` | `PcapReader/PcapWriter` | ğŸ”´ é«˜ |
| `deduplication_stage.py` | 126-185 | `rdpcap/wrpcap` | æµå¼å»é‡ | ğŸ”´ é«˜ |
| `strategy.py` | 424-429 | `PcapReader` | âœ… å·²æ­£ç¡® | âœ… æ— éœ€ä¿®æ”¹ |
| `payload_masker.py` | 237-238 | `PcapReader/PcapWriter` | âœ… å·²æ­£ç¡® | âœ… æ— éœ€ä¿®æ”¹ |
| `http_marker.py` | 122 | `PcapReader` | âœ… å·²æ­£ç¡® | âœ… æ— éœ€ä¿®æ”¹ |
| `data_validator.py` | 273-274 | `PcapReader` | âœ… å·²æ­£ç¡® | âœ… æ— éœ€ä¿®æ”¹ |

### âœ… å·²æ­£ç¡®ä½¿ç”¨æµå¼ API çš„ä»£ç 

**å¥½æ¶ˆæ¯**: `payload_masker.py` å·²ç»æ­£ç¡®ä½¿ç”¨äº†æµå¼ APIï¼

```python
# src/pktmask/core/pipeline/stages/masking_stage/masker/payload_masker.py:237-238
with (
    PcapReader(input_path) as reader,
    PcapWriter(output_path, sync=True) as writer,
):
    for packet in reader:
        # æµå¼å¤„ç†ï¼Œå†…å­˜å ç”¨æ’å®š
        modified_packet, packet_modified = self._process_packet(packet, rule_lookup)
        writer.write(modified_packet)
```

**è¿™æ˜¯æœ€ä½³å®è·µï¼** å…¶ä»–æ–‡ä»¶åº”è¯¥å‚è€ƒè¿™ä¸ªå®ç°ã€‚

---

## ğŸ¯ ä¿®å¤ä¼˜å…ˆçº§å’Œå·¥ä½œé‡ä¼°ç®—

### Phase 1: é«˜ä¼˜å…ˆçº§ä¿®å¤ (1å¤©)

1. **`anonymization_stage.py`** - 4å°æ—¶
   - æ›¿æ¢ `rdpcap/wrpcap` ä¸º `PcapReader/PcapWriter`
   - æ·»åŠ è¿›åº¦æŠ¥å‘Šï¼ˆä½¿ç”¨ capinfos æˆ–ä¸¤éå¤„ç†ï¼‰
   - æµ‹è¯•éªŒè¯

2. **`deduplication_stage.py`** - 4å°æ—¶
   - å®ç°æµå¼å»é‡ç®—æ³•
   - ä¿æŒå“ˆå¸Œé›†åˆåœ¨å†…å­˜ä¸­
   - æµ‹è¯•éªŒè¯

### Phase 2: æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ– (1å¤©)

3. **æ€§èƒ½åŸºå‡†æµ‹è¯•** - 2å°æ—¶
   - æµ‹è¯•ä¸åŒå¤§å°æ–‡ä»¶ï¼ˆ10MB, 100MB, 500MB, 1GBï¼‰
   - å¯¹æ¯”ä¿®å¤å‰åçš„å†…å­˜å’Œé€Ÿåº¦
   - è®°å½•æ€§èƒ½æ•°æ®

4. **æ–‡æ¡£æ›´æ–°** - 2å°æ—¶
   - æ›´æ–° API æ–‡æ¡£
   - æ·»åŠ æ€§èƒ½ä¼˜åŒ–è¯´æ˜
   - æ›´æ–°ç”¨æˆ·æŒ‡å—

5. **E2E æµ‹è¯•** - 4å°æ—¶
   - è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
   - éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
   - ä¿®å¤å‘ç°çš„é—®é¢˜

---

## ğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ

### å†…å­˜ä½¿ç”¨æ”¹è¿›

| æ–‡ä»¶å¤§å° | ä¿®å¤å‰ | ä¿®å¤å | æ”¹è¿› |
|---------|--------|--------|------|
| 10 MB   | 40 MB  | 10 MB  | **4x** |
| 100 MB  | 400 MB | 50 MB  | **8x** |
| 500 MB  | OOM    | 80 MB  | **å¯å¤„ç†** |
| 1 GB    | OOM    | 120 MB | **å¯å¤„ç†** |

### å¤„ç†é€Ÿåº¦æ”¹è¿›

| æ–‡ä»¶å¤§å° | ä¿®å¤å‰ | ä¿®å¤å | æ”¹è¿› |
|---------|--------|--------|------|
| 10 MB   | 5 ç§’   | 2 ç§’   | **2.5x** |
| 100 MB  | 45 ç§’  | 15 ç§’  | **3x** |
| 500 MB  | OOM    | 60 ç§’  | **å¯å¤„ç†** |
| 1 GB    | OOM    | 120 ç§’ | **å¯å¤„ç†** |

### ç”¨æˆ·ä½“éªŒæ”¹è¿›

- âœ… å¯ä»¥å¤„ç† GB çº§å¤§æ–‡ä»¶
- âœ… å¯åŠ¨å»¶è¿Ÿä» 5 ç§’é™ä½åˆ° 0.1 ç§’
- âœ… å†…å­˜å ç”¨ç¨³å®šï¼Œä¸ä¼šçªç„¶é£™å‡
- âœ… è¿›åº¦æŠ¥å‘Šæ›´å‡†ç¡®

---

## ğŸ”— ç›¸å…³èµ„æº

### Scapy å®˜æ–¹æ–‡æ¡£
- [Scapy Performance Tips](https://scapy.readthedocs.io/en/latest/usage.html#performance)
- [PcapReader API](https://scapy.readthedocs.io/en/latest/api/scapy.utils.html#scapy.utils.PcapReader)
- [PcapWriter API](https://scapy.readthedocs.io/en/latest/api/scapy.utils.html#scapy.utils.PcapWriter)

### å‚è€ƒå®ç°
- âœ… `src/pktmask/core/pipeline/stages/masking_stage/masker/payload_masker.py:237-238`
- âœ… `src/pktmask/core/pipeline/stages/masking_stage/marker/http_marker.py:122`

---

**åˆ›å»ºäºº**: AI Assistant  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-09  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**ä¸‹æ¬¡æ›´æ–°**: ä¿®å¤å®Œæˆåæ›´æ–°å®é™…æ•ˆæœ

