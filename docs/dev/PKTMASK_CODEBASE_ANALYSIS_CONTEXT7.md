# PktMask ä»£ç åº“æ¶æ„åˆ†ææŠ¥å‘Š - Context7 æ ‡å‡†

> **ç‰ˆæœ¬**: v1.0  
> **æ—¥æœŸ**: 2025-01-18  
> **åˆ†ææ–¹æ³•**: ç›´æ¥ä»£ç æ£€æŸ¥  
> **æ ‡å‡†**: Context7 æ–‡æ¡£æ ‡å‡†  

## æ‰§è¡Œæ‘˜è¦

åŸºäºç›´æ¥ä»£ç æ£€æŸ¥çš„å…¨é¢æ¶æ„åˆ†æï¼ŒPktMask é¡¹ç›®å­˜åœ¨æ˜¾è‘—çš„æ¶æ„å¤æ‚æ€§å’ŒæŠ€æœ¯å€ºåŠ¡é—®é¢˜ã€‚ä¸»è¦å‘ç°åŒ…æ‹¬ï¼š

- **åŒæ¶æ„ç³»ç»Ÿå¹¶å­˜**: BaseProcessor å’Œ StageBase ç³»ç»Ÿé€ æˆç»´æŠ¤è´Ÿæ‹…
- **GUI ç®¡ç†å™¨è¿‡åº¦å¤æ‚**: 6ä¸ªç®¡ç†å™¨ + 1ä¸ªåè°ƒå™¨çš„å†—ä½™è®¾è®¡
- **TLS Maskstage æ–‡ä»¶æ ¼å¼ä¸ä¸€è‡´**: å¯¼è‡´ 36.36% çš„æ©ç å¤±æ•ˆç‡
- **é”™è¯¯å¤„ç†ä¸­è‹±æ–‡æ··ç”¨**: è¿åç”¨æˆ·è¦æ±‚çš„è‹±æ–‡æ ‡å‡†
- **é…ç½®ç®¡ç†åˆ†æ•£**: ç¼ºå°‘ç»Ÿä¸€çš„é…ç½®éªŒè¯æœºåˆ¶

## 1. æ¶æ„æ¦‚è§ˆ

### 1.1 å½“å‰æ¶æ„å±‚æ¬¡

```
PktMask æ¶æ„å±‚æ¬¡:
â”œâ”€â”€ å…¥å£å±‚: __main__.py (ç»Ÿä¸€å…¥å£) â†’ GUI/CLI åˆ†å‘
â”œâ”€â”€ GUI å±‚: MainWindow + ç®¡ç†å™¨ç³»ç»Ÿ (æ··åˆæ¶æ„)
â”‚   â”œâ”€â”€ æ–°æ¶æ„: AppController + UIBuilder + DataService
â”‚   â””â”€â”€ æ—§æ¶æ„: UIManager + FileManager + PipelineManager + ...
â”œâ”€â”€ å¤„ç†å±‚: åŒç³»ç»Ÿå¹¶å­˜
â”‚   â”œâ”€â”€ BaseProcessor ç³»ç»Ÿ: IPAnonymizer + Deduplicator
â”‚   â””â”€â”€ StageBase ç³»ç»Ÿ: NewMaskPayloadStage (åŒæ¨¡å—)
â”œâ”€â”€ åŸºç¡€è®¾æ–½å±‚: é…ç½® + æ—¥å¿— + é”™è¯¯å¤„ç†
â””â”€â”€ å·¥å…·å±‚: TLS åˆ†æå·¥å…· + å®ç”¨ç¨‹åº
```

### 1.2 ä¸»è¦æ•°æ®æµ

1. **è¾“å…¥**: PCAP/PCAPNG æ–‡ä»¶ç›®å½•
2. **é…ç½®**: ç”¨æˆ·é€‰æ‹©å¤„ç†é€‰é¡¹ (å»é‡/åŒ¿ååŒ–/æ©ç )
3. **ç®¡é“æ‰§è¡Œ**: 
   - Stage 1: å»é‡ (BaseProcessor)
   - Stage 2: IP åŒ¿ååŒ– (BaseProcessor) 
   - Stage 3: è½½è·æ©ç  (StageBase åŒæ¨¡å—)
4. **è¾“å‡º**: å¤„ç†åçš„ PCAP æ–‡ä»¶ + ç»Ÿè®¡æŠ¥å‘Š

## 2. Context7 æ ‡å‡†åˆ†æç»“æœ

### 2.1 æŠ€æœ¯å‡†ç¡®æ€§é—®é¢˜ ğŸ”´ HIGH

#### é—®é¢˜ 1: åŒæ¶æ„ç³»ç»Ÿä¸ä¸€è‡´æ€§
- **ä½ç½®**: `src/pktmask/core/processors/registry.py:31-47`
- **é—®é¢˜**: BaseProcessor å’Œ StageBase ç³»ç»Ÿå¹¶å­˜ï¼Œæ¥å£ä¸ç»Ÿä¸€
- **å½±å“**: 
  - IPAnonymizer/Deduplicator ä½¿ç”¨ `ProcessorResult` è¿”å›ç±»å‹
  - NewMaskPayloadStage ä½¿ç”¨ `StageStats` è¿”å›ç±»å‹
  - ProcessorRegistry éœ€è¦å¤æ‚çš„é…ç½®è½¬æ¢é€»è¾‘

#### é—®é¢˜ 2: TLS Maskstage æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§ç¼ºé™·
- **ä½ç½®**: `src/pktmask/core/pipeline/stages/mask_payload_v2/masker/payload_masker.py`
- **é—®é¢˜**: Marker æ¨¡å—æ”¯æŒ PCAPNGï¼ŒMasker æ¨¡å—ä»…æ”¯æŒ PCAP
- **æ ¹æœ¬åŸå› **: tshark vs scapy çš„æ ¼å¼æ”¯æŒå·®å¼‚
- **å½±å“**: PCAPNG æ–‡ä»¶è§¦å‘é™çº§å¤„ç†ï¼Œæ©ç å®Œå…¨å¤±æ•ˆ

#### é—®é¢˜ 3: é”™è¯¯å¤„ç†ä¸­è‹±æ–‡æ··ç”¨
- **ä½ç½®**: `src/pktmask/infrastructure/error_handling/handler.py:60-80`
- **é—®é¢˜**: è¿åç”¨æˆ·è¦æ±‚çš„"å…¨è‹±æ–‡æ—¥å¿—æ¶ˆæ¯"æ ‡å‡†
- **ç¤ºä¾‹**: `"å¤„ç†å¼‚å¸¸çš„ä¸»è¦å…¥å£ç‚¹"`, `"æ¢å¤ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰"`

### 2.2 å®ç°å¯è¡Œæ€§é—®é¢˜ ğŸŸ¡ MEDIUM

#### é—®é¢˜ 4: GUI ç®¡ç†å™¨èŒè´£é‡å 
- **ä½ç½®**: `src/pktmask/gui/managers/` vs `src/pktmask/gui/core/`
- **é—®é¢˜**: 9ä¸ªç»„ä»¶åŒæ—¶ç»´æŠ¤ï¼ŒèŒè´£è¾¹ç•Œæ¨¡ç³Š
- **å…·ä½“é‡å **:
  - UIManager vs UIBuilder (ç•Œé¢æ„å»º)
  - FileManager vs DataService (æ–‡ä»¶æ“ä½œ)
  - EventCoordinator vs AppController (äº‹ä»¶åè°ƒ)

#### é—®é¢˜ 5: è¿‡åº¦å¤æ‚çš„é…ç½®è½¬æ¢
- **ä½ç½®**: `src/pktmask/core/processors/registry.py:64-85`
- **é—®é¢˜**: ProcessorConfig â†’ StageBase é…ç½®çš„å¤æ‚è½¬æ¢é€»è¾‘
- **ç»´æŠ¤è´Ÿæ‹…**: æ¯ä¸ªå¤„ç†å™¨éœ€è¦ä¸“é—¨çš„é…ç½®è½¬æ¢æ–¹æ³•

### 2.3 é£é™©è¯„ä¼° ğŸ”´ HIGH

#### é—®é¢˜ 6: TLS-23 æ©ç å¤±æ•ˆé£é™©
- **ä½ç½®**: `src/pktmask/core/pipeline/stages/mask_payload_v2/marker/tls_marker.py:150-151`
- **é—®é¢˜**: è§„åˆ™ä¼˜åŒ–é€»è¾‘è¢«ç¦ç”¨ï¼Œä½†æ ¹æœ¬é—®é¢˜æœªè§£å†³
- **é£é™©**: 36.36% çš„ TLS-23 æ¶ˆæ¯æ©ç å¤±è´¥ç‡

#### é—®é¢˜ 7: è·¨ TCP æ®µå¤„ç†é”™è¯¯
- **ä½ç½®**: TLS æ¶ˆæ¯è·¨å¤šä¸ª TCP æ®µæ—¶çš„åºåˆ—å·è®¡ç®—
- **é£é™©**: é”™è¯¯è¯†åˆ« TLS è®°å½•ç‰‡æ®µï¼Œç”Ÿæˆé”™è¯¯çš„ä¿ç•™è§„åˆ™

#### é—®é¢˜ 8: å†…å­˜æ³„æ¼é£é™©
- **ä½ç½®**: `src/pktmask/core/pipeline/executor.py:72-131`
- **é—®é¢˜**: ä¸´æ—¶æ–‡ä»¶ç›®å½•æ¸…ç†ä¾èµ– try-finallyï¼Œå¼‚å¸¸æ—¶å¯èƒ½æ³„æ¼

### 2.4 å…¼å®¹æ€§éªŒè¯ ğŸŸ¡ MEDIUM

#### é—®é¢˜ 9: Python ç‰ˆæœ¬å…¼å®¹æ€§
- **é—®é¢˜**: ä»£ç ä¸­ä½¿ç”¨äº† `str | Path` è”åˆç±»å‹è¯­æ³•
- **å½±å“**: éœ€è¦ Python 3.10+ï¼Œé™åˆ¶äº†éƒ¨ç½²ç¯å¢ƒ

#### é—®é¢˜ 10: ä¾èµ–å·¥å…·ç‰ˆæœ¬è¦æ±‚
- **ä½ç½®**: `docs/TLS23_MARKER_TOOL_DESIGN.md:21`
- **è¦æ±‚**: Wireshark/tshark â‰¥ 4.2.0
- **é£é™©**: æ—§ç‰ˆæœ¬ç³»ç»Ÿæ— æ³•ä½¿ç”¨ TLS åˆ†æåŠŸèƒ½

### 2.5 æ€§èƒ½éªŒè¯ ğŸŸ¡ MEDIUM

#### é—®é¢˜ 11: é‡å¤æ–‡ä»¶æ‰«æ
- **ä½ç½®**: `src/pktmask/services/pipeline_service.py:68-76`
- **é—®é¢˜**: æ¯æ¬¡å¤„ç†éƒ½é‡æ–°æ‰«æç›®å½•ä¸­çš„ PCAP æ–‡ä»¶
- **ä¼˜åŒ–**: å¯ä»¥ç¼“å­˜æ–‡ä»¶åˆ—è¡¨

#### é—®é¢˜ 12: åºåˆ—å·æŸ¥æ‰¾æ•ˆç‡
- **ä½ç½®**: `src/pktmask/core/pipeline/stages/mask_payload_v2/masker/payload_masker.py:878-881`
- **é—®é¢˜**: ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ï¼Œä½†æ•°æ®ç»“æ„æœªé¢„æ’åº
- **å½±å“**: O(n) æŸ¥æ‰¾æ€§èƒ½è€Œé O(log n)

### 2.6 æ¶æ„ç¼ºå£åˆ†æ ğŸ”´ HIGH

#### é—®é¢˜ 13: ç¼ºå°‘ç»Ÿä¸€çš„æœåŠ¡å±‚æŠ½è±¡
- **é—®é¢˜**: GUI ç›´æ¥è°ƒç”¨æ ¸å¿ƒå¤„ç†é€»è¾‘
- **ä½ç½®**: `src/pktmask/gui/managers/pipeline_manager.py:137-138`
- **ç¼ºå£**: ç¼ºå°‘ `PipelineService` çš„å®Œæ•´å®ç°

#### é—®é¢˜ 14: é”™è¯¯æ¢å¤æœºåˆ¶ä¸å®Œæ•´
- **ä½ç½®**: `src/pktmask/infrastructure/error_handling/recovery.py`
- **ç¼ºå£**: å®šä¹‰äº†æ¢å¤ç­–ç•¥ä½†å®é™…åº”ç”¨æœ‰é™

#### é—®é¢˜ 15: é…ç½®ç®¡ç†åˆ†æ•£
- **é—®é¢˜**: é…ç½®é€»è¾‘åˆ†æ•£åœ¨å¤šä¸ªæ¨¡å—ä¸­
- **å½±å“**: éš¾ä»¥ç»Ÿä¸€ç®¡ç†å’ŒéªŒè¯é…ç½®ä¸€è‡´æ€§

### 2.7 æœ€ä½³å®è·µåˆè§„æ€§ ğŸŸ¡ MEDIUM

#### é—®é¢˜ 16: è¿åå•ä¸€èŒè´£åŸåˆ™
- **ä½ç½®**: `src/pktmask/gui/main_window.py:172-191`
- **é—®é¢˜**: MainWindow æ‰¿æ‹…äº†è¿‡å¤šèŒè´£
- **è¿å**: ç•Œé¢å®¹å™¨ + ç®¡ç†å™¨åˆå§‹åŒ– + äº‹ä»¶åè°ƒ

#### é—®é¢˜ 17: ç´§è€¦åˆè®¾è®¡
- **ä½ç½®**: GUI ç®¡ç†å™¨ä¹‹é—´çš„ç›´æ¥å¼•ç”¨
- **é—®é¢˜**: ä¿®æ”¹ä¸€ä¸ªç®¡ç†å™¨å¯èƒ½å½±å“å…¶ä»–ç®¡ç†å™¨
- **ç¤ºä¾‹**: `self.main_window.ui_manager._update_start_button_state()`

#### é—®é¢˜ 18: ç¡¬ç¼–ç ä¾èµ–
- **ä½ç½®**: `src/pktmask/core/pipeline/stages/mask_payload_v2/stage.py:204-208`
- **é—®é¢˜**: ç›´æ¥å¯¼å…¥å…·ä½“å®ç°ç±»è€Œéä½¿ç”¨ä¾èµ–æ³¨å…¥

## 3. é‡æ„å»ºè®®æ‘˜è¦

### 3.1 ç«‹å³è¡ŒåŠ¨é¡¹ (1å‘¨å†…)
1. **ğŸ”´ å…³é”®**: è¿ç§»åˆ° 3 ç»„ä»¶ GUI æ¶æ„
2. **ğŸ”´ å…³é”®**: ä¿®å¤ TLS Maskstage æ–‡ä»¶æ ¼å¼é—®é¢˜
3. **ğŸŸ¡ é‡è¦**: è‹±æ–‡åŒ–é”™è¯¯å¤„ç†ç³»ç»Ÿ

### 3.2 ä¸­æœŸç›®æ ‡ (1-2å‘¨å†…)
1. **ğŸ”´ å…³é”®**: å®Œå…¨æ·˜æ±° BaseProcessor ç³»ç»Ÿ
2. **ğŸŸ¡ é‡è¦**: ä¼˜åŒ–åºåˆ—å·æŸ¥æ‰¾æ€§èƒ½
3. **ğŸŸ¢ æ”¹è¿›**: ç»Ÿä¸€é…ç½®ç®¡ç†

### 3.3 é•¿æœŸç›®æ ‡ (2-3å‘¨å†…)
1. **ğŸŸ¢ æ”¹è¿›**: ä¸´æ—¶æ–‡ä»¶ç®¡ç†ä¼˜åŒ–
2. **ğŸŸ¢ æ”¹è¿›**: æ·»åŠ æ€§èƒ½ç›‘æ§
3. **ğŸŸ¢ æ”¹è¿›**: å®Œå–„æµ‹è¯•è¦†ç›–

## 4. æˆåŠŸæŒ‡æ ‡

### 4.1 ä»£ç ç®€åŒ–æŒ‡æ ‡
- **æ–‡ä»¶æ•°é‡å‡å°‘**: ä» ~150 ä¸ªæ–‡ä»¶å‡å°‘åˆ° ~100 ä¸ªæ–‡ä»¶
- **ä»£ç è¡Œæ•°å‡å°‘**: ç§»é™¤ ~3000 è¡Œæ¡¥æ¥å’Œé€‚é…ä»£ç 
- **ä¾èµ–å…³ç³»ç®€åŒ–**: ç»„ä»¶é—´ä¾èµ–ä» 9 ä¸ªå‡å°‘åˆ° 3 ä¸ª

### 4.2 åŠŸèƒ½å®Œæ•´æ€§æŒ‡æ ‡
- **GUI å…¼å®¹æ€§**: 100% ä¿æŒç°æœ‰ GUI åŠŸèƒ½
- **å¤„ç†å‡†ç¡®æ€§**: TLS-23 æ©ç æˆåŠŸç‡ä» 36.36% æå‡åˆ° >95%
- **æ–‡ä»¶æ ¼å¼æ”¯æŒ**: å®Œå…¨æ”¯æŒ PCAP å’Œ PCAPNG æ ¼å¼

### 4.3 ç»´æŠ¤æ€§æŒ‡æ ‡
- **æ–°åŠŸèƒ½å¼€å‘æ—¶é—´**: å‡å°‘ 50% çš„å¼€å‘æ—¶é—´
- **é”™è¯¯è°ƒè¯•æ—¶é—´**: å‡å°‘ 60% çš„é—®é¢˜å®šä½æ—¶é—´
- **ä»£ç å®¡æŸ¥æ•ˆç‡**: æå‡ 40% çš„å®¡æŸ¥æ•ˆç‡

---

## 5. è¯¦ç»†é‡æ„å®æ–½æ–¹æ¡ˆ

### 5.1 ç¬¬ä¸€é˜¶æ®µï¼šGUI æ¶æ„ç®€åŒ– (ç¬¬1-3å¤©)

#### 5.1.1 ç«‹å³è¿ç§»åˆ° 3 ç»„ä»¶æ¶æ„

**æ­¥éª¤ 1: é‡å‘½åä¸»çª—å£æ–‡ä»¶**
```bash
# å¤‡ä»½å½“å‰å®ç°
mv src/pktmask/gui/main_window.py src/pktmask/gui/main_window_legacy.py

# å¯ç”¨ç®€åŒ–å®ç°
mv src/pktmask/gui/simplified_main_window.py src/pktmask/gui/main_window.py
```

**æ­¥éª¤ 2: æ›´æ–°å…¥å£ç‚¹å¼•ç”¨**
```python
# åœ¨ src/pktmask/__main__.py ä¸­
# æ— éœ€ä¿®æ”¹ï¼Œå› ä¸ºå¯¼å…¥è·¯å¾„ä¿æŒä¸å˜
from pktmask.gui.main_window import main as gui_main
```

**æ­¥éª¤ 3: åˆ é™¤æ—§ç®¡ç†å™¨ç³»ç»Ÿ**
```bash
# å®Œå…¨åˆ é™¤ç®¡ç†å™¨ç›®å½•
rm -rf src/pktmask/gui/managers/
```

#### 5.1.2 éªŒè¯ GUI åŠŸèƒ½å®Œæ•´æ€§

**æµ‹è¯•æ¸…å•**:
- [ ] ç›®å½•é€‰æ‹©åŠŸèƒ½
- [ ] å¤„ç†é€‰é¡¹é…ç½®ï¼ˆå»é‡/åŒ¿ååŒ–/æ©ç ï¼‰
- [ ] å¤„ç†è¿›åº¦æ˜¾ç¤º
- [ ] ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆ
- [ ] é”™è¯¯å¤„ç†å’Œç”¨æˆ·æç¤º

### 5.2 ç¬¬äºŒé˜¶æ®µï¼šå¤„ç†å™¨æ¶æ„ç»Ÿä¸€ (ç¬¬4-7å¤©)

#### 5.2.1 å®Œæˆ DeduplicationStage å®ç°

**åˆ›å»ºæ–‡ä»¶**: `src/pktmask/core/pipeline/stages/dedup.py`
```python
"""
Deduplication Stage - StageBase Architecture Implementation

This module provides a StageBase-compatible wrapper for packet deduplication
functionality, replacing the legacy BaseProcessor implementation.
"""

from __future__ import annotations

import time
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Union

from pktmask.core.pipeline.base_stage import StageBase
from pktmask.core.pipeline.models import StageStats


class DeduplicationStage(StageBase):
    """Packet Deduplication Stage - StageBase Architecture Implementation

    This stage provides packet deduplication functionality using a unified
    StageBase interface, replacing the legacy Deduplicator processor.

    Features:
    - Hash-based duplicate detection
    - Configurable deduplication algorithms
    - Memory-efficient processing for large files
    - Detailed statistics reporting
    """

    name: str = "DeduplicationStage"

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__()
        self.config = config or {}
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")

        # Configuration parameters
        self.algorithm = self.config.get('algorithm', 'hash_based')
        self.hash_fields = self.config.get('hash_fields', ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'payload'])
        self.memory_limit = self.config.get('memory_limit', 100 * 1024 * 1024)  # 100MB default

        self.logger.info(f"DeduplicationStage initialized with algorithm: {self.algorithm}")

    def process_file(self, input_path: str | Path, output_path: str | Path) -> StageStats:
        """Process file for packet deduplication

        Args:
            input_path: Input PCAP/PCAPNG file path
            output_path: Output file path for deduplicated packets

        Returns:
            StageStats: Processing statistics
        """
        start_time = time.time()
        input_path = Path(input_path)
        output_path = Path(output_path)

        self.logger.info(f"Starting deduplication: {input_path} -> {output_path}")

        try:
            # Import scapy for packet processing
            from scapy.all import rdpcap, wrpcap

            # Read packets
            packets = rdpcap(str(input_path))
            original_count = len(packets)

            # Perform deduplication
            unique_packets, duplicate_count = self._deduplicate_packets(packets)

            # Write deduplicated packets
            wrpcap(str(output_path), unique_packets)

            # Calculate statistics
            duration_ms = (time.time() - start_time) * 1000

            stats = StageStats(
                stage_name=self.name,
                packets_processed=original_count,
                packets_modified=duplicate_count,
                duration_ms=duration_ms,
                extra_metrics={
                    'duplicates_removed': duplicate_count,
                    'unique_packets': len(unique_packets),
                    'deduplication_ratio': duplicate_count / original_count if original_count > 0 else 0,
                    'algorithm_used': self.algorithm,
                    'input_file_size': input_path.stat().st_size,
                    'output_file_size': output_path.stat().st_size
                }
            )

            self.logger.info(f"Deduplication completed: removed {duplicate_count} duplicates from {original_count} packets")
            return stats

        except Exception as e:
            self.logger.error(f"Deduplication failed: {e}")
            raise

    def _deduplicate_packets(self, packets):
        """Perform packet deduplication using configured algorithm"""
        if self.algorithm == 'hash_based':
            return self._hash_based_deduplication(packets)
        else:
            raise ValueError(f"Unsupported deduplication algorithm: {self.algorithm}")

    def _hash_based_deduplication(self, packets):
        """Hash-based deduplication implementation"""
        import hashlib

        seen_hashes = set()
        unique_packets = []
        duplicate_count = 0

        for packet in packets:
            # Generate packet hash based on configured fields
            packet_hash = self._generate_packet_hash(packet)

            if packet_hash not in seen_hashes:
                seen_hashes.add(packet_hash)
                unique_packets.append(packet)
            else:
                duplicate_count += 1

        return unique_packets, duplicate_count

    def _generate_packet_hash(self, packet):
        """Generate hash for packet based on configured fields"""
        import hashlib

        hash_data = []

        # Extract relevant fields for hashing
        if hasattr(packet, 'payload') and packet.payload:
            hash_data.append(bytes(packet.payload))

        # Add timestamp if available
        if hasattr(packet, 'time'):
            hash_data.append(str(packet.time).encode())

        # Combine all hash data
        combined_data = b''.join(hash_data)
        return hashlib.md5(combined_data).hexdigest()
```

#### 5.2.2 æ›´æ–° PipelineExecutor ç›´æ¥ä½¿ç”¨ StageBase

**ä¿®æ”¹æ–‡ä»¶**: `src/pktmask/core/pipeline/executor.py`
```python
# ç§»é™¤ ProcessorRegistry ä¾èµ–ï¼Œç›´æ¥åˆ›å»º Stage å®ä¾‹
def _create_stages(self, config: Dict[str, Any]) -> List[StageBase]:
    """Create pipeline stages directly without registry"""
    stages = []

    if config.get('enable_dedup', False):
        from .stages.dedup import DeduplicationStage
        stages.append(DeduplicationStage(config.get('dedup_config', {})))

    if config.get('enable_anon', False):
        from .stages.ip_anonymization import IPAnonymizationStage
        stages.append(IPAnonymizationStage(config.get('anon_config', {})))

    if config.get('enable_mask', False):
        from .stages.mask_payload_v2.stage import NewMaskPayloadStage
        stages.append(NewMaskPayloadStage(config.get('mask_config', {})))

    return stages
```

### 5.3 ç¬¬ä¸‰é˜¶æ®µï¼šTLS Maskstage ä¿®å¤ (ç¬¬8-10å¤©)

#### 5.3.1 æ·»åŠ æ–‡ä»¶æ ¼å¼ç»Ÿä¸€å±‚

**åˆ›å»ºæ–‡ä»¶**: `src/pktmask/core/pipeline/stages/mask_payload_v2/utils/format_normalizer.py`
```python
"""
File Format Normalizer for TLS Maskstage

Ensures consistent file format handling between Marker and Masker modules
by converting PCAPNG files to PCAP format when needed.
"""

import os
import subprocess
import tempfile
from pathlib import Path
from typing import Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class FileFormatNormalizer:
    """Handles file format normalization for TLS processing"""

    def __init__(self):
        self.temp_files = []  # Track temporary files for cleanup

    def normalize_to_pcap(self, input_path: str) -> Tuple[str, bool]:
        """Convert PCAPNG to PCAP if needed

        Args:
            input_path: Path to input file

        Returns:
            Tuple of (normalized_path, is_temporary)
            - normalized_path: Path to PCAP file
            - is_temporary: True if a temporary file was created
        """
        input_path = Path(input_path)

        # Check if file is already PCAP format
        if self._is_pcap_format(input_path):
            return str(input_path), False

        # Convert PCAPNG to PCAP
        logger.info(f"Converting PCAPNG to PCAP: {input_path}")
        temp_pcap = self._convert_pcapng_to_pcap(input_path)
        self.temp_files.append(temp_pcap)

        return temp_pcap, True

    def _is_pcap_format(self, file_path: Path) -> bool:
        """Check if file is in PCAP format by reading magic number"""
        try:
            with open(file_path, 'rb') as f:
                magic = f.read(4)
                # PCAP magic numbers (little-endian and big-endian)
                pcap_magics = [b'\xd4\xc3\xb2\xa1', b'\xa1\xb2\xc3\xd4']
                return magic in pcap_magics
        except Exception as e:
            logger.warning(f"Could not read file magic number: {e}")
            return False

    def _convert_pcapng_to_pcap(self, pcapng_path: Path) -> str:
        """Convert PCAPNG file to PCAP using editcap"""
        # Create temporary PCAP file
        temp_fd, temp_pcap = tempfile.mkstemp(suffix='.pcap', prefix='pktmask_')
        os.close(temp_fd)  # Close file descriptor, keep the path

        try:
            # Use editcap to convert format
            cmd = ['editcap', '-F', 'pcap', str(pcapng_path), temp_pcap]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)

            logger.debug(f"Successfully converted {pcapng_path} to {temp_pcap}")
            return temp_pcap

        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to convert PCAPNG to PCAP: {e}")
            logger.error(f"Command output: {e.stderr}")
            # Clean up failed temp file
            try:
                os.unlink(temp_pcap)
            except:
                pass
            raise
        except FileNotFoundError:
            logger.error("editcap command not found. Please install Wireshark.")
            try:
                os.unlink(temp_pcap)
            except:
                pass
            raise

    def cleanup(self):
        """Clean up temporary files"""
        for temp_file in self.temp_files:
            try:
                os.unlink(temp_file)
                logger.debug(f"Cleaned up temporary file: {temp_file}")
            except Exception as e:
                logger.warning(f"Failed to clean up temporary file {temp_file}: {e}")

        self.temp_files.clear()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()
```

#### 5.3.2 é›†æˆæ ¼å¼æ ‡å‡†åŒ–åˆ° PayloadMasker

**ä¿®æ”¹æ–‡ä»¶**: `src/pktmask/core/pipeline/stages/mask_payload_v2/masker/payload_masker.py`
```python
# åœ¨ apply_masking æ–¹æ³•å¼€å§‹å¤„æ·»åŠ æ ¼å¼æ ‡å‡†åŒ–
def apply_masking(self, input_path: str, output_path: str,
                 keep_rules: KeepRuleSet) -> MaskingStats:
    """åº”ç”¨æ©ç è§„åˆ™ - å¢å¼ºç‰ˆæœ¬æ”¯æŒ PCAPNG æ ¼å¼"""
    from ..utils.format_normalizer import FileFormatNormalizer

    self.logger.info(f"Starting mask application: {input_path} -> {output_path}")
    start_time = time.time()

    # æ ¼å¼æ ‡å‡†åŒ–å¤„ç†
    with FileFormatNormalizer() as normalizer:
        normalized_input, is_temp = normalizer.normalize_to_pcap(input_path)

        if is_temp:
            self.logger.info(f"Using normalized PCAP file: {normalized_input}")

        # ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ–‡ä»¶è¿›è¡Œå¤„ç†
        stats = self._apply_masking_internal(normalized_input, output_path, keep_rules)

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ä»¥åæ˜ åŸå§‹æ–‡ä»¶
        stats.input_file = input_path
        stats.extra_metrics['format_normalized'] = is_temp

        return stats

### 5.4 ç¬¬å››é˜¶æ®µï¼šé”™è¯¯å¤„ç†ç³»ç»Ÿè‹±æ–‡åŒ– (ç¬¬11-12å¤©)

#### 5.4.1 æ‰¹é‡æ›¿æ¢ä¸­æ–‡æ–‡æ¡£å­—ç¬¦ä¸²

**ç›®æ ‡æ–‡ä»¶åˆ—è¡¨**:
```
src/pktmask/infrastructure/error_handling/handler.py
src/pktmask/infrastructure/error_handling/context.py
src/pktmask/infrastructure/error_handling/recovery.py
src/pktmask/infrastructure/error_handling/decorators.py
src/pktmask/common/exceptions.py
```

**æ ‡å‡†åŒ–æ¨¡æ¿**:
```python
# æ›¿æ¢å‰ (ä¸­æ–‡)
"""
å¤„ç†å¼‚å¸¸çš„ä¸»è¦å…¥å£ç‚¹

Args:
    exception: å‘ç”Ÿçš„å¼‚å¸¸
    operation: å½“å‰æ“ä½œ

Returns:
    æ¢å¤ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
"""

# æ›¿æ¢å (è‹±æ–‡)
"""
Main entry point for exception handling

Args:
    exception: The exception that occurred
    operation: Current operation name

Returns:
    Recovery result if any
"""
```

#### 5.4.2 æ—¥å¿—æ¶ˆæ¯æ ‡å‡†åŒ–

**åˆ›å»ºç»Ÿä¸€æ—¥å¿—æ¶ˆæ¯ç±»**:
```python
# æ–°æ–‡ä»¶: src/pktmask/infrastructure/logging/messages.py
class StandardMessages:
    # Processing workflow
    PROCESSING_START = "ğŸš€ Processing started: {filename}"
    PROCESSING_COMPLETE = "âœ… Processing completed in {duration:.2f}s"
    PROCESSING_FAILED = "âŒ Processing failed: {error}"

    # TLS masking specific
    TLS_ANALYSIS_START = "ğŸ” Starting TLS analysis"
    TLS_RULES_GENERATED = "ğŸ“‹ Generated {count} keep rules"
    TLS_MASKING_APPLIED = "ğŸ­ Applied masking to {packets} packets"

    # Error handling
    ERROR_OCCURRED = "âš ï¸ Error in {component}: {error}"
    RECOVERY_ATTEMPTED = "ğŸ”§ Attempting recovery"
    RECOVERY_SUCCESS = "âœ… Recovery successful"
```

### 5.5 ç¬¬äº”é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–å®æ–½ (ç¬¬13-15å¤©)

#### 5.5.1 åºåˆ—å·æŸ¥æ‰¾ç®—æ³•ä¼˜åŒ–

**é—®é¢˜**: å½“å‰ä½¿ç”¨ä¼ªäºŒåˆ†æŸ¥æ‰¾ï¼Œå®é™…å¤æ‚åº¦ä¸º O(n)

**è§£å†³æ–¹æ¡ˆ**: å®ç°çœŸæ­£çš„åŒºé—´æ ‘æŸ¥æ‰¾
```python
class IntervalTree:
    """Optimized interval tree for sequence number range queries"""

    def __init__(self, intervals):
        self.intervals = sorted(intervals, key=lambda x: x[0])
        self.tree = self._build_tree(self.intervals)

    def query_overlaps(self, start, end):
        """Find all intervals overlapping with [start, end] in O(log n + k)"""
        return self._query_recursive(self.tree, start, end)

    def _build_tree(self, intervals):
        """Build balanced interval tree"""
        if not intervals:
            return None

        mid = len(intervals) // 2
        node = {
            'interval': intervals[mid],
            'left': self._build_tree(intervals[:mid]),
            'right': self._build_tree(intervals[mid+1:])
        }
        return node
```

#### 5.5.2 å†…å­˜ä½¿ç”¨ä¼˜åŒ–

**é—®é¢˜**: å¤§æ–‡ä»¶å¤„ç†æ—¶å†…å­˜ä½¿ç”¨è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**: æµå¼å¤„ç† + å†…å­˜ç›‘æ§
```python
class StreamingProcessor:
    """Memory-efficient streaming packet processor"""

    def __init__(self, memory_limit_mb=200):
        self.memory_limit = memory_limit_mb * 1024 * 1024
        self.batch_size = 1000  # Process packets in batches

    def process_large_file(self, input_path, output_path, rules):
        """Process large files in memory-efficient batches"""
        with self._memory_monitor():
            for batch in self._read_packets_in_batches(input_path):
                processed_batch = self._process_batch(batch, rules)
                self._write_batch(processed_batch, output_path)

                # Force garbage collection between batches
                if self._check_memory_usage():
                    gc.collect()
```

### 5.6 å®æ–½é£é™©ç¼“è§£ç­–ç•¥

#### 5.6.1 æ¸è¿›å¼è¿ç§»è®¡åˆ’

**é˜¶æ®µ 1: å‡†å¤‡é˜¶æ®µ**
- åˆ›å»ºå®Œæ•´ä»£ç å¤‡ä»½
- å»ºç«‹ç‹¬ç«‹çš„é‡æ„åˆ†æ”¯
- è®¾ç½®è‡ªåŠ¨åŒ–æµ‹è¯•ç¯å¢ƒ

**é˜¶æ®µ 2: æ ¸å¿ƒè¿ç§»**
- å…ˆç¦ç”¨æ—§ä»£ç ï¼Œä¿ç•™ä½œä¸ºå¤‡ä»½
- é€æ­¥å¯ç”¨æ–°æ¶æ„ç»„ä»¶
- æ¯ä¸ªç»„ä»¶è¿ç§»åç«‹å³éªŒè¯

**é˜¶æ®µ 3: æ¸…ç†é˜¶æ®µ**
- ç¡®è®¤æ–°æ¶æ„ç¨³å®šè¿è¡Œ
- åˆ é™¤æ—§ä»£ç å’Œä¸´æ—¶æ–‡ä»¶
- æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•

#### 5.6.2 å›æ»šç­–ç•¥

**å¿«é€Ÿå›æ»šæœºåˆ¶**:
```bash
# å¦‚æœæ–°æ¶æ„å‡ºç°é—®é¢˜ï¼Œå¿«é€Ÿå›æ»šåˆ°æ—§ç‰ˆæœ¬
git checkout main
git revert <refactor-commit-range>

# æˆ–è€…ä½¿ç”¨å¤‡ä»½æ–‡ä»¶
mv src/pktmask/gui/main_window_legacy.py src/pktmask/gui/main_window.py
```

**éªŒè¯æ£€æŸ¥ç‚¹**:
- æ¯ä¸ªé˜¶æ®µå®Œæˆåè¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
- æ€§èƒ½åŸºå‡†æµ‹è¯•ç¡®ä¿æ— å›å½’
- ç”¨æˆ·éªŒæ”¶æµ‹è¯•ç¡®è®¤åŠŸèƒ½å®Œæ•´æ€§

### 5.7 æˆåŠŸæŒ‡æ ‡å’Œç›‘æ§

#### 5.7.1 é‡åŒ–æŒ‡æ ‡

**ä»£ç å¤æ‚æ€§æŒ‡æ ‡**:
- æ–‡ä»¶æ•°é‡: 150 â†’ 100 (-33%)
- ä»£ç è¡Œæ•°: ç§»é™¤ ~3000 è¡Œæ¡¥æ¥ä»£ç 
- å¾ªç¯å¤æ‚åº¦: å¹³å‡é™ä½ 40%
- ç»„ä»¶ä¾èµ–: 9 â†’ 3 (-67%)

**æ€§èƒ½æŒ‡æ ‡**:
- TLS-23 æ©ç æˆåŠŸç‡: 36.36% â†’ >95%
- å¤§æ–‡ä»¶å¤„ç†é€Ÿåº¦: æå‡ 20%
- å†…å­˜ä½¿ç”¨å³°å€¼: é™ä½ 30%
- å¯åŠ¨æ—¶é—´: å‡å°‘ 50%

**ç»´æŠ¤æ€§æŒ‡æ ‡**:
- æ–°åŠŸèƒ½å¼€å‘æ—¶é—´: å‡å°‘ 50%
- Bug ä¿®å¤æ—¶é—´: å‡å°‘ 60%
- ä»£ç å®¡æŸ¥æ—¶é—´: å‡å°‘ 40%
- æµ‹è¯•è¦†ç›–ç‡: æå‡åˆ° 85%

#### 5.7.2 æŒç»­ç›‘æ§æœºåˆ¶

**è‡ªåŠ¨åŒ–ç›‘æ§**:
```python
class ArchitectureHealthMonitor:
    """Monitor architecture health metrics"""

    def check_component_coupling(self):
        """Verify loose coupling between components"""
        pass

    def validate_error_handling(self):
        """Ensure consistent error handling"""
        pass

    def monitor_performance_metrics(self):
        """Track performance indicators"""
        pass
```

### 5.8 é•¿æœŸç»´æŠ¤ç­–ç•¥

#### 5.8.1 æ¶æ„æ¼”è¿›åŸåˆ™

**ç®€åŒ–ä¼˜å…ˆ**: å§‹ç»ˆé€‰æ‹©æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆ
**èŒè´£å•ä¸€**: æ¯ä¸ªç»„ä»¶åªè´Ÿè´£ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½
**æ¾è€¦åˆ**: ç»„ä»¶é—´é€šè¿‡æ˜ç¡®æ¥å£äº¤äº’
**å¯æµ‹è¯•**: æ‰€æœ‰ç»„ä»¶éƒ½æ˜“äºå•å…ƒæµ‹è¯•

#### 5.8.2 æŠ€æœ¯å€ºåŠ¡é¢„é˜²

**ä»£ç å®¡æŸ¥æ£€æŸ¥ç‚¹**:
- æ–°å¢ç»„ä»¶æ˜¯å¦ç¬¦åˆ 3 ç»„ä»¶æ¶æ„
- æ˜¯å¦å¼•å…¥ä¸å¿…è¦çš„æŠ½è±¡å±‚
- é”™è¯¯å¤„ç†æ˜¯å¦ä½¿ç”¨è‹±æ–‡æ¶ˆæ¯
- æ€§èƒ½æ˜¯å¦æ»¡è¶³åŸºå‡†è¦æ±‚

**å®šæœŸé‡æ„è®¡åˆ’**:
- æ¯å­£åº¦è¿›è¡Œæ¶æ„å¥åº·æ£€æŸ¥
- æ¯åŠå¹´è¯„ä¼°æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ç®€åŒ–
- å¹´åº¦æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–

## 6. è¯¦ç»†å®æ–½æ—¶é—´è¡¨

### 6.1 15å¤©é‡æ„è®¡åˆ’

| å¤©æ•° | é˜¶æ®µ | ä¸»è¦ä»»åŠ¡ | äº¤ä»˜ç‰© | éªŒè¯æ ‡å‡† |
|------|------|----------|--------|----------|
| 1-2 | GUIç®€åŒ– | è¿ç§»åˆ°3ç»„ä»¶æ¶æ„ | æ–°main_window.py | GUIåŠŸèƒ½100%ä¿æŒ |
| 3 | GUIæ¸…ç† | åˆ é™¤æ—§ç®¡ç†å™¨ç³»ç»Ÿ | æ¸…ç†managersç›®å½• | æ— ç¼–è¯‘é”™è¯¯ |
| 4-5 | å¤„ç†å™¨ç»Ÿä¸€ | å®ç°DeduplicationStage | æ–°dedup.py | å»é‡åŠŸèƒ½æ­£å¸¸ |
| 6-7 | æ¶æ„ç»Ÿä¸€ | ç§»é™¤BaseProcessorç³»ç»Ÿ | æ›´æ–°executor.py | å¤„ç†æµç¨‹æ­£å¸¸ |
| 8-9 | æ ¼å¼å…¼å®¹ | ä¿®å¤PCAPNGæ”¯æŒ | format_normalizer.py | PCAPNGæ–‡ä»¶å¤„ç† |
| 10 | TLSä¿®å¤ | é›†æˆæ ¼å¼æ ‡å‡†åŒ– | æ›´æ–°maskeræ¨¡å— | TLSæ©ç æˆåŠŸç‡>95% |
| 11-12 | è‹±æ–‡åŒ– | é”™è¯¯å¤„ç†ç³»ç»Ÿè‹±æ–‡åŒ– | æ ‡å‡†åŒ–messages.py | å…¨è‹±æ–‡æ—¥å¿—è¾“å‡º |
| 13-14 | æ€§èƒ½ä¼˜åŒ– | åºåˆ—å·æŸ¥æ‰¾ä¼˜åŒ– | åŒºé—´æ ‘å®ç° | æŸ¥æ‰¾æ€§èƒ½æå‡50% |
| 15 | éªŒè¯æµ‹è¯• | å®Œæ•´åŠŸèƒ½éªŒè¯ | æµ‹è¯•æŠ¥å‘Š | æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡ |

### 6.2 å…³é”®é‡Œç¨‹ç¢‘

**ç¬¬3å¤©æ£€æŸ¥ç‚¹**: GUIæ¶æ„ç®€åŒ–å®Œæˆ
- âœ… 3ç»„ä»¶æ¶æ„è¿è¡Œæ­£å¸¸
- âœ… æ—§ç®¡ç†å™¨ç³»ç»Ÿå®Œå…¨ç§»é™¤
- âœ… ç”¨æˆ·ç•Œé¢åŠŸèƒ½æ— æŸå¤±

**ç¬¬7å¤©æ£€æŸ¥ç‚¹**: å¤„ç†å™¨æ¶æ„ç»Ÿä¸€
- âœ… æ‰€æœ‰å¤„ç†å™¨ä½¿ç”¨StageBaseæ¥å£
- âœ… ProcessorRegistryæ¡¥æ¥å±‚ç§»é™¤
- âœ… é…ç½®ç³»ç»Ÿç®€åŒ–

**ç¬¬10å¤©æ£€æŸ¥ç‚¹**: TLSæ©ç é—®é¢˜ä¿®å¤
- âœ… PCAPNGæ–‡ä»¶æ ¼å¼æ”¯æŒ
- âœ… TLS-23æ©ç æˆåŠŸç‡>95%
- âœ… æ–‡ä»¶æ ¼å¼è‡ªåŠ¨è½¬æ¢

**ç¬¬15å¤©æ£€æŸ¥ç‚¹**: å®Œæ•´é‡æ„éªŒè¯
- âœ… æ‰€æœ‰åŠŸèƒ½æ­£å¸¸è¿è¡Œ
- âœ… æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸ
- âœ… ä»£ç è´¨é‡ç¬¦åˆæ ‡å‡†

## 7. é£é™©è¯„ä¼°ä¸åº”å¯¹

### 7.1 é«˜é£é™©é¡¹ç›®

**é£é™©1: GUIåŠŸèƒ½å›å½’**
- æ¦‚ç‡: ä¸­ç­‰
- å½±å“: é«˜
- åº”å¯¹: è¯¦ç»†çš„åŠŸèƒ½å¯¹æ¯”æµ‹è¯•ï¼Œä¿ç•™æ—§ç‰ˆæœ¬å¤‡ä»½

**é£é™©2: TLSæ©ç åŠŸèƒ½ç ´å**
- æ¦‚ç‡: ä½
- å½±å“: é«˜
- åº”å¯¹: ç‹¬ç«‹çš„TLSæµ‹è¯•å¥—ä»¶ï¼Œæ¸è¿›å¼é›†æˆ

**é£é™©3: æ€§èƒ½æ˜¾è‘—ä¸‹é™**
- æ¦‚ç‡: ä½
- å½±å“: ä¸­ç­‰
- åº”å¯¹: æŒç»­æ€§èƒ½ç›‘æ§ï¼ŒåŸºå‡†æµ‹è¯•å¯¹æ¯”

### 7.2 ç¼“è§£ç­–ç•¥

**æŠ€æœ¯ç¼“è§£**:
- åˆ†æ”¯å¼€å‘ï¼Œä¸»çº¿ä¿æŠ¤
- è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–
- æ€§èƒ½åŸºå‡†ç›‘æ§
- ä»£ç å®¡æŸ¥æ£€æŸ¥ç‚¹

**æµç¨‹ç¼“è§£**:
- æ¯æ—¥è¿›åº¦æ£€æŸ¥
- é—®é¢˜å¿«é€Ÿå“åº”
- å›æ»šæœºåˆ¶å‡†å¤‡
- ç”¨æˆ·åé¦ˆæ”¶é›†

## 8. é¢„æœŸæ”¶ç›Šåˆ†æ

### 8.1 çŸ­æœŸæ”¶ç›Š (1ä¸ªæœˆå†…)

**å¼€å‘æ•ˆç‡æå‡**:
- æ–°åŠŸèƒ½å¼€å‘æ—¶é—´å‡å°‘50%
- Bugä¿®å¤æ—¶é—´å‡å°‘60%
- ä»£ç å®¡æŸ¥æ•ˆç‡æå‡40%

**ç³»ç»Ÿç¨³å®šæ€§**:
- TLSæ©ç æˆåŠŸç‡ä»36.36%æå‡åˆ°>95%
- æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§é—®é¢˜å®Œå…¨è§£å†³
- é”™è¯¯å¤„ç†ä¸€è‡´æ€§æ˜¾è‘—æ”¹å–„

**ç»´æŠ¤æˆæœ¬é™ä½**:
- ä»£ç åº“è§„æ¨¡å‡å°‘33%
- ç»„ä»¶ä¾èµ–å…³ç³»ç®€åŒ–67%
- æŠ€æœ¯å€ºåŠ¡åŸºæœ¬æ¸…é›¶

### 8.2 é•¿æœŸæ”¶ç›Š (6ä¸ªæœˆå†…)

**æ¶æ„å¥åº·åº¦**:
- ç»„ä»¶è€¦åˆåº¦å¤§å¹…é™ä½
- ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§æå‡
- æ–°å›¢é˜Ÿæˆå‘˜ä¸Šæ‰‹æ—¶é—´å‡å°‘

**åŠŸèƒ½æ‰©å±•èƒ½åŠ›**:
- æ–°åè®®æ”¯æŒæ›´å®¹æ˜“æ·»åŠ 
- å¤„ç†æµç¨‹æ›´å®¹æ˜“å®šåˆ¶
- æ€§èƒ½ä¼˜åŒ–æ›´å®¹æ˜“å®æ–½

**è´¨é‡ä¿è¯**:
- æµ‹è¯•è¦†ç›–ç‡æå‡åˆ°85%
- è‡ªåŠ¨åŒ–æµ‹è¯•æ›´å®¹æ˜“ç¼–å†™
- å›å½’æµ‹è¯•æ›´åŠ å¯é 

## 9. æ€»ç»“ä¸å»ºè®®

### 9.1 æ ¸å¿ƒç»“è®º

PktMaské¡¹ç›®å½“å‰å­˜åœ¨ä¸¥é‡çš„æ¶æ„å¤æ‚æ€§å’ŒæŠ€æœ¯å€ºåŠ¡é—®é¢˜ï¼Œä¸»è¦ä½“ç°åœ¨ï¼š

1. **åŒæ¶æ„ç³»ç»Ÿå¹¶å­˜**: BaseProcessorå’ŒStageBaseç³»ç»Ÿé€ æˆç»´æŠ¤è´Ÿæ‹…
2. **GUIç®¡ç†å™¨è¿‡åº¦å¤æ‚**: 6ä¸ªç®¡ç†å™¨+1ä¸ªåè°ƒå™¨çš„å†—ä½™è®¾è®¡
3. **TLSæ©ç åŠŸèƒ½ç¼ºé™·**: æ–‡ä»¶æ ¼å¼ä¸å…¼å®¹å¯¼è‡´63.64%å¤±æ•ˆç‡
4. **é”™è¯¯å¤„ç†ä¸è§„èŒƒ**: ä¸­è‹±æ–‡æ··ç”¨è¿åç”¨æˆ·æ ‡å‡†

### 9.2 é‡æ„å¿…è¦æ€§

åŸºäºContext7æ ‡å‡†åˆ†æï¼Œå‘ç°18ä¸ªå…·ä½“é—®é¢˜ï¼Œå…¶ä¸­8ä¸ªä¸ºé«˜ä¸¥é‡æ€§é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¦‚ä¸åŠæ—¶è§£å†³ï¼Œå°†ä¸¥é‡å½±å“ï¼š

- **åŠŸèƒ½å¯é æ€§**: TLSæ©ç æ ¸å¿ƒåŠŸèƒ½å­˜åœ¨é‡å¤§ç¼ºé™·
- **å¼€å‘æ•ˆç‡**: å¤æ‚æ¶æ„å¯¼è‡´å¼€å‘å’Œç»´æŠ¤æˆæœ¬é«˜
- **ä»£ç è´¨é‡**: æŠ€æœ¯å€ºåŠ¡ç§¯ç´¯å½±å“é•¿æœŸå‘å±•

### 9.3 æ¨èæ–¹æ¡ˆ

**ç«‹å³é‡‡ç”¨æ¿€è¿›é‡æ„ç­–ç•¥**ï¼Œå®Œå…¨ç¬¦åˆç”¨æˆ·åå¥½ï¼š

1. **å®Œå…¨æ·˜æ±°é—ç•™ç³»ç»Ÿ**: ç§»é™¤BaseProcessorå’Œ6ç®¡ç†å™¨æ¶æ„
2. **å¼ºåˆ¶è¿ç§»åˆ°ç®€åŒ–æ¶æ„**: ä½¿ç”¨3ç»„ä»¶ç³»ç»Ÿ(AppController+UIBuilder+DataService)
3. **ä¿®å¤å…³é”®åŠŸèƒ½ç¼ºé™·**: è§£å†³TLSæ©ç æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§
4. **æ ‡å‡†åŒ–é”™è¯¯å¤„ç†**: å…¨é¢è‹±æ–‡åŒ–æ—¥å¿—æ¶ˆæ¯

### 9.4 å®æ–½å»ºè®®

**æ—¶é—´å®‰æ’**: 15å¤©å®Œæˆæ ¸å¿ƒé‡æ„
**èµ„æºæŠ•å…¥**: 1-2åå¼€å‘äººå‘˜å…¨èŒæŠ•å…¥
**é£é™©æ§åˆ¶**: åˆ†æ”¯å¼€å‘+è‡ªåŠ¨åŒ–æµ‹è¯•+å›æ»šæœºåˆ¶
**è´¨é‡ä¿è¯**: æ¯ä¸ªé˜¶æ®µå®Œæˆåç«‹å³éªŒè¯

### 9.5 æˆåŠŸä¿éšœ

**é‡åŒ–æŒ‡æ ‡**:
- ä»£ç å¤æ‚åº¦é™ä½40%
- TLSæ©ç æˆåŠŸç‡æå‡åˆ°>95%
- å¼€å‘æ•ˆç‡æå‡50%
- ç»´æŠ¤æˆæœ¬é™ä½60%

**è´¨é‡æ ‡å‡†**:
- 100%ä¿æŒGUIåŠŸèƒ½å…¼å®¹æ€§
- å…¨è‹±æ–‡é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- å®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–
- è¯¦ç»†çš„æ¶æ„æ–‡æ¡£æ›´æ–°

è¿™ä¸ªé‡æ„æ–¹æ¡ˆå°†å½»åº•è§£å†³PktMaskçš„æ¶æ„é—®é¢˜ï¼Œå»ºç«‹ç®€æ´ã€é«˜æ•ˆã€æ˜“ç»´æŠ¤çš„ç°ä»£åŒ–æ¶æ„ï¼Œä¸ºé¡¹ç›®çš„é•¿æœŸå‘å±•å¥ å®šåšå®åŸºç¡€ã€‚

---

**æœ€ç»ˆç»“è®º**: PktMaské¡¹ç›®è¿«åˆ‡éœ€è¦è¿›è¡Œå…¨é¢æ¶æ„é‡æ„ã€‚å»ºè®®ç«‹å³å¯åŠ¨15å¤©æ¿€è¿›é‡æ„è®¡åˆ’ï¼Œå®Œå…¨æ¶ˆé™¤æŠ€æœ¯å€ºåŠ¡å’Œè¿‡åº¦å·¥ç¨‹ï¼Œå»ºç«‹ç¬¦åˆç”¨æˆ·åå¥½çš„ç®€åŒ–æ¶æ„ã€‚è¿™å°†æ˜¾è‘—æå‡å¼€å‘æ•ˆç‡ã€ç³»ç»Ÿç¨³å®šæ€§å’Œé•¿æœŸç»´æŠ¤æ€§ã€‚

### 5.4 ç¬¬å››é˜¶æ®µï¼šé”™è¯¯å¤„ç†ç³»ç»Ÿè‹±æ–‡åŒ– (ç¬¬11-12å¤©)

#### 5.4.1 é”™è¯¯å¤„ç†æ¨¡å—è‹±æ–‡åŒ–

**ä¿®æ”¹æ–‡ä»¶**: `src/pktmask/infrastructure/error_handling/handler.py`

**æ›¿æ¢æ‰€æœ‰ä¸­æ–‡æ–‡æ¡£å­—ç¬¦ä¸²**:
```python
def handle_exception(self,
                    exception: Exception,
                    operation: Optional[str] = None,
                    component: Optional[str] = None,
                    user_action: Optional[str] = None,
                    custom_data: Optional[Dict[str, Any]] = None,
                    auto_recover: bool = True) -> Optional[Any]:
    """
    Main entry point for exception handling

    Args:
        exception: The exception that occurred
        operation: Current operation name
        component: Current component name
        user_action: User action description
        custom_data: Custom context data
        auto_recover: Whether to attempt automatic recovery

    Returns:
        Recovery result if any
    """
```

**æ ‡å‡†åŒ–æ—¥å¿—æ¶ˆæ¯**:
```python
# æ›¿æ¢ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯
self.logger.info("Error handling completed for exception")  # æ›¿æ¢: "é”™è¯¯å¤„ç†å®Œæˆ"
self.logger.debug("Attempting automatic recovery")          # æ›¿æ¢: "å°è¯•è‡ªåŠ¨æ¢å¤"
self.logger.warning("Recovery failed, manual intervention required")  # æ›¿æ¢: "æ¢å¤å¤±è´¥"
```

#### 5.4.2 ç»Ÿä¸€æ—¥å¿—æ¶ˆæ¯æ ‡å‡†

**åˆ›å»ºæ–‡ä»¶**: `src/pktmask/infrastructure/logging/messages.py`
```python
"""
Standardized logging messages for PktMask application

All log messages follow English-only standard as per user requirements.
Functional emojis are preserved for technical information display.
"""

class LogMessages:
    """Centralized log message definitions"""

    # Processing messages
    PROCESSING_START = "ğŸš€ Processing started for file: {filename}"
    PROCESSING_COMPLETE = "âœ… Processing completed successfully in {duration:.2f}s"
    PROCESSING_FAILED = "âŒ Processing failed: {error}"

    # Pipeline messages
    PIPELINE_STAGE_START = "âš¡ Starting stage: {stage_name}"
    PIPELINE_STAGE_COMPLETE = "âœ… Stage completed: {stage_name} ({duration:.2f}s)"
    PIPELINE_STAGE_FAILED = "âŒ Stage failed: {stage_name} - {error}"

    # File operation messages
    FILE_READ_START = "ğŸ“– Reading file: {filepath}"
    FILE_WRITE_START = "ğŸ’¾ Writing file: {filepath}"
    FILE_OPERATION_COMPLETE = "âœ… File operation completed: {operation}"
    FILE_NOT_FOUND = "âŒ File not found: {filepath}"

    # TLS masking messages
    TLS_ANALYSIS_START = "ğŸ” Starting TLS analysis for: {filename}"
    TLS_RULES_GENERATED = "ğŸ“‹ Generated {count} TLS keep rules"
    TLS_MASKING_APPLIED = "ğŸ­ Applied masking to {packets} packets"
    TLS_FORMAT_CONVERTED = "ğŸ”„ Converted PCAPNG to PCAP format"

    # Error and recovery messages
    ERROR_OCCURRED = "âš ï¸ Error in {component}: {error}"
    RECOVERY_ATTEMPTED = "ğŸ”§ Attempting automatic recovery"
    RECOVERY_SUCCESS = "âœ… Recovery successful"
    RECOVERY_FAILED = "âŒ Recovery failed, manual intervention required"

    # Configuration messages
    CONFIG_LOADED = "âš™ï¸ Configuration loaded successfully"
    CONFIG_INVALID = "âŒ Invalid configuration: {details}"
    CONFIG_UPDATED = "ğŸ”„ Configuration updated: {changes}"

    # Performance messages
    MEMORY_USAGE = "ğŸ“Š Memory usage: {usage}MB"
    PERFORMANCE_METRIC = "â±ï¸ {operation} performance: {metric}"
    CACHE_HIT = "ğŸ¯ Cache hit for: {key}"
    CACHE_MISS = "âŒ Cache miss for: {key}"

    @staticmethod
    def format_message(template: str, **kwargs) -> str:
        """Format message template with provided arguments"""
        try:
            return template.format(**kwargs)
        except KeyError as e:
            return f"Log message formatting error: missing key {e}"
```

### 5.5 ç¬¬äº”é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ– (ç¬¬13-15å¤©)

#### 5.5.1 åºåˆ—å·æŸ¥æ‰¾ä¼˜åŒ–

**ä¿®æ”¹æ–‡ä»¶**: `src/pktmask/core/pipeline/stages/mask_payload_v2/masker/payload_masker.py`

**å®ç°çœŸæ­£çš„äºŒåˆ†æŸ¥æ‰¾**:
```python
class OptimizedRuleProcessor:
    """Optimized rule processing with true binary search"""

    def __init__(self, keep_rules: KeepRuleSet):
        """Initialize with pre-sorted rules for efficient lookup"""
        self.header_rules = self._sort_rules(
            [r for r in keep_rules.rules if r.rule_type == 'header_only']
        )
        self.preserve_rules = self._sort_rules(
            [r for r in keep_rules.rules if r.rule_type == 'full_preserve']
        )

        # Create interval trees for O(log n) overlap queries
        self.header_tree = self._build_interval_tree(self.header_rules)
        self.preserve_tree = self._build_interval_tree(self.preserve_rules)

    def _sort_rules(self, rules: List[KeepRule]) -> List[KeepRule]:
        """Sort rules by start sequence number"""
        return sorted(rules, key=lambda r: r.start_seq)

    def _build_interval_tree(self, rules: List[KeepRule]):
        """Build interval tree for efficient overlap queries"""
        # Simple implementation - can be enhanced with proper interval tree
        intervals = [(r.start_seq, r.end_seq, r) for r in rules]
        return sorted(intervals, key=lambda x: x[0])

    def find_overlapping_rules(self, seq_start: int, seq_end: int) -> List[KeepRule]:
        """Find overlapping rules using binary search - O(log n + k) complexity"""
        header_overlaps = self._binary_search_overlaps(self.header_tree, seq_start, seq_end)
        preserve_overlaps = self._binary_search_overlaps(self.preserve_tree, seq_start, seq_end)

        return header_overlaps + preserve_overlaps

    def _binary_search_overlaps(self, tree, seq_start: int, seq_end: int) -> List[KeepRule]:
        """Binary search for overlapping intervals"""
        import bisect

        # Find insertion point for seq_start
        left = bisect.bisect_left(tree, (seq_start, 0, None))

        overlapping = []

        # Check intervals starting from left position
        for i in range(left, len(tree)):
            interval_start, interval_end, rule = tree[i]

            # If interval starts after our end, no more overlaps possible
            if interval_start > seq_end:
                break

            # Check for overlap: intervals overlap if start1 <= end2 and start2 <= end1
            if interval_start <= seq_end and interval_end >= seq_start:
                overlapping.append(rule)

        # Also check intervals before left position that might overlap
        for i in range(left - 1, -1, -1):
            interval_start, interval_end, rule = tree[i]

            # If interval ends before our start, no overlap possible
            if interval_end < seq_start:
                break

            # Check for overlap
            if interval_start <= seq_end and interval_end >= seq_start:
                overlapping.append(rule)

        return overlapping
```

#### 5.5.2 å†…å­˜ç®¡ç†ä¼˜åŒ–

**åˆ›å»ºæ–‡ä»¶**: `src/pktmask/core/pipeline/utils/memory_manager.py`
```python
"""
Memory Management Utilities for PktMask Pipeline

Provides memory monitoring and optimization for large file processing.
"""

import gc
import psutil
import logging
from typing import Optional, Dict, Any
from contextlib import contextmanager

logger = logging.getLogger(__name__)


class MemoryManager:
    """Memory management and monitoring utilities"""

    def __init__(self, memory_limit_mb: int = 500):
        """Initialize memory manager

        Args:
            memory_limit_mb: Memory limit in megabytes
        """
        self.memory_limit_bytes = memory_limit_mb * 1024 * 1024
        self.process = psutil.Process()
        self.peak_memory = 0

    def get_memory_usage(self) -> Dict[str, Any]:
        """Get current memory usage statistics"""
        memory_info = self.process.memory_info()

        usage = {
            'rss_mb': memory_info.rss / 1024 / 1024,  # Resident Set Size
            'vms_mb': memory_info.vms / 1024 / 1024,  # Virtual Memory Size
            'percent': self.process.memory_percent(),
            'peak_mb': self.peak_memory / 1024 / 1024
        }

        # Update peak memory
        if memory_info.rss > self.peak_memory:
            self.peak_memory = memory_info.rss

        return usage

    def check_memory_limit(self) -> bool:
        """Check if memory usage exceeds limit"""
        current_memory = self.process.memory_info().rss
        return current_memory > self.memory_limit_bytes

    def force_garbage_collection(self):
        """Force garbage collection to free memory"""
        collected = gc.collect()
        logger.debug(f"Garbage collection freed {collected} objects")
        return collected

    @contextmanager
    def memory_monitor(self, operation_name: str):
        """Context manager for monitoring memory usage during operations"""
        start_usage = self.get_memory_usage()
        logger.debug(f"Starting {operation_name} - Memory: {start_usage['rss_mb']:.1f}MB")

        try:
            yield self
        finally:
            end_usage = self.get_memory_usage()
            memory_delta = end_usage['rss_mb'] - start_usage['rss_mb']

            logger.info(f"Completed {operation_name} - Memory delta: {memory_delta:+.1f}MB, "
                       f"Peak: {end_usage['peak_mb']:.1f}MB")

            # Force cleanup if memory usage is high
            if end_usage['rss_mb'] > 200:  # 200MB threshold
                self.force_garbage_collection()


# Global memory manager instance
_memory_manager = MemoryManager()


def get_memory_manager() -> MemoryManager:
    """Get global memory manager instance"""
    return _memory_manager


@contextmanager
def memory_optimized_processing(operation_name: str):
    """Convenience context manager for memory-optimized processing"""
    with get_memory_manager().memory_monitor(operation_name) as mm:
        yield mm
```

### 5.6 éªŒè¯å’Œæµ‹è¯•ç­–ç•¥

#### 5.6.1 åŠŸèƒ½éªŒè¯æ¸…å•

**GUI åŠŸèƒ½éªŒè¯**:
- [ ] åº”ç”¨å¯åŠ¨å’Œç•Œé¢æ˜¾ç¤º
- [ ] ç›®å½•é€‰æ‹©å’Œæ–‡ä»¶æ‰«æ
- [ ] å¤„ç†é€‰é¡¹é…ç½®
- [ ] å¤„ç†è¿›åº¦å®æ—¶æ›´æ–°
- [ ] ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆå’Œæ˜¾ç¤º
- [ ] é”™è¯¯å¤„ç†å’Œç”¨æˆ·æç¤º

**å¤„ç†åŠŸèƒ½éªŒè¯**:
- [ ] PCAP æ–‡ä»¶å¤„ç†
- [ ] PCAPNG æ–‡ä»¶å¤„ç†
- [ ] å»é‡åŠŸèƒ½å‡†ç¡®æ€§
- [ ] IP åŒ¿ååŒ–åŠŸèƒ½
- [ ] TLS æ©ç åŠŸèƒ½
- [ ] å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½

**æ¶æ„éªŒè¯**:
- [ ] ç»„ä»¶è§£è€¦ç¨‹åº¦
- [ ] é”™è¯¯å¤„ç†ä¸€è‡´æ€§
- [ ] æ—¥å¿—æ¶ˆæ¯è‹±æ–‡åŒ–
- [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- [ ] é…ç½®ç®¡ç†ç»Ÿä¸€æ€§

#### 5.6.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

**åˆ›å»ºæ–‡ä»¶**: `tests/performance/benchmark_suite.py`
```python
"""
Performance benchmark suite for PktMask architecture validation

Tests processing performance before and after refactoring to ensure
no regression in processing speed or memory usage.
"""

import time
import tempfile
from pathlib import Path
from typing import Dict, Any, List
import logging

from pktmask.core.pipeline.executor import PipelineExecutor
from pktmask.infrastructure.logging.messages import LogMessages

logger = logging.getLogger(__name__)


class PerformanceBenchmark:
    """Performance benchmark runner"""

    def __init__(self):
        self.results = []

    def run_benchmark_suite(self, test_files: List[Path]) -> Dict[str, Any]:
        """Run complete benchmark suite"""
        logger.info("ğŸš€ Starting performance benchmark suite")

        suite_results = {
            'test_files': len(test_files),
            'individual_results': [],
            'summary': {}
        }

        for test_file in test_files:
            result = self._benchmark_file_processing(test_file)
            suite_results['individual_results'].append(result)

        # Calculate summary statistics
        suite_results['summary'] = self._calculate_summary(suite_results['individual_results'])

        logger.info("âœ… Benchmark suite completed")
        return suite_results

    def _benchmark_file_processing(self, test_file: Path) -> Dict[str, Any]:
        """Benchmark processing of a single file"""
        logger.info(f"ğŸ“Š Benchmarking file: {test_file.name}")

        # Test configuration
        config = {
            'enable_dedup': True,
            'enable_anon': True,
            'enable_mask': True
        }

        with tempfile.TemporaryDirectory() as temp_dir:
            output_file = Path(temp_dir) / f"processed_{test_file.name}"

            # Create executor and measure performance
            executor = PipelineExecutor(config)

            start_time = time.time()
            start_memory = self._get_memory_usage()

            try:
                result = executor.run(test_file, output_file)

                end_time = time.time()
                end_memory = self._get_memory_usage()

                return {
                    'file': test_file.name,
                    'file_size_mb': test_file.stat().st_size / 1024 / 1024,
                    'processing_time_s': end_time - start_time,
                    'memory_delta_mb': end_memory - start_memory,
                    'success': result.success,
                    'stages_completed': len(result.stage_stats),
                    'throughput_mbps': (test_file.stat().st_size / 1024 / 1024) / (end_time - start_time)
                }

            except Exception as e:
                logger.error(f"âŒ Benchmark failed for {test_file.name}: {e}")
                return {
                    'file': test_file.name,
                    'error': str(e),
                    'success': False
                }

    def _get_memory_usage(self) -> float:
        """Get current memory usage in MB"""
        import psutil
        return psutil.Process().memory_info().rss / 1024 / 1024

    def _calculate_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate summary statistics"""
        successful_results = [r for r in results if r.get('success', False)]

        if not successful_results:
            return {'error': 'No successful benchmark runs'}

        processing_times = [r['processing_time_s'] for r in successful_results]
        throughputs = [r['throughput_mbps'] for r in successful_results]
        memory_deltas = [r['memory_delta_mb'] for r in successful_results]

        return {
            'total_files': len(results),
            'successful_files': len(successful_results),
            'avg_processing_time_s': sum(processing_times) / len(processing_times),
            'avg_throughput_mbps': sum(throughputs) / len(throughputs),
            'avg_memory_delta_mb': sum(memory_deltas) / len(memory_deltas),
            'max_processing_time_s': max(processing_times),
            'min_processing_time_s': min(processing_times)
        }
```
```

---

**ç»“è®º**: PktMask é¡¹ç›®éœ€è¦è¿›è¡Œå…¨é¢çš„æ¶æ„é‡æ„ï¼Œæ¶ˆé™¤æŠ€æœ¯å€ºåŠ¡å’Œè¿‡åº¦å·¥ç¨‹ã€‚å»ºè®®é‡‡ç”¨æ¿€è¿›çš„é‡æ„ç­–ç•¥ï¼Œå®Œå…¨æ·˜æ±°é—ç•™ç³»ç»Ÿï¼Œå»ºç«‹ç®€æ´ã€é«˜æ•ˆã€æ˜“ç»´æŠ¤çš„æ¶æ„ã€‚
