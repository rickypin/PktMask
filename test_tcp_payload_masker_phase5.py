#!/usr/bin/env python3
"""
TCP Payload Masker é˜¶æ®µ5éªŒè¯æµ‹è¯•

éªŒè¯æ€§èƒ½ä¼˜åŒ–å’Œæ‰¹é‡å¤„ç†åŠŸèƒ½ï¼Œä¸ä¾èµ–å¤–éƒ¨åº“ã€‚
"""

import sys
import os
import time
import logging
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/workspace/src')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_batch_processing_logic():
    """æµ‹è¯•æ‰¹é‡å¤„ç†é€»è¾‘"""
    logger.info("ğŸ§ª æµ‹è¯•æ‰¹é‡å¤„ç†é€»è¾‘...")
    
    try:
        # ç›´æ¥å¯¼å…¥æ ¸å¿ƒæ¨¡å—é¿å…Scapyä¾èµ–
        sys.path.insert(0, '/workspace/src/pktmask/core/tcp_payload_masker/core')
        
        from keep_range_models import TcpKeepRangeTable, TcpKeepRangeEntry, TcpMaskingResult
        
        # æ¨¡æ‹Ÿæ‰¹é‡ä»»åŠ¡ç»“æ„
        def create_mock_batch_jobs():
            """åˆ›å»ºæ¨¡æ‹Ÿæ‰¹é‡ä»»åŠ¡"""
            jobs = []
            for i in range(3):
                table = TcpKeepRangeTable()
                entry = TcpKeepRangeEntry(
                    stream_id=f"TCP_1.2.3.{i}:443_5.6.7.8:1234_forward",
                    sequence_start=1000,
                    sequence_end=2000,
                    keep_ranges=[(0, 5)],
                    protocol_hint="TLS"
                )
                table.add_keep_range_entry(entry)
                
                jobs.append({
                    'input_pcap': f'input_{i}.pcap',
                    'keep_range_table': table,
                    'output_pcap': f'output_{i}.pcap'
                })
            return jobs
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        batch_jobs = create_mock_batch_jobs()
        assert len(batch_jobs) == 3, "æ‰¹é‡ä»»åŠ¡åˆ›å»ºå¤±è´¥"
        
        # éªŒè¯ä»»åŠ¡ç»“æ„
        for i, job in enumerate(batch_jobs):
            assert 'input_pcap' in job, f"ä»»åŠ¡ {i} ç¼ºå°‘input_pcap"
            assert 'keep_range_table' in job, f"ä»»åŠ¡ {i} ç¼ºå°‘keep_range_table"
            assert 'output_pcap' in job, f"ä»»åŠ¡ {i} ç¼ºå°‘output_pcap"
            assert isinstance(job['keep_range_table'], TcpKeepRangeTable), f"ä»»åŠ¡ {i} ä¿ç•™èŒƒå›´è¡¨ç±»å‹é”™è¯¯"
        
        # æµ‹è¯•è¿›åº¦å›è°ƒ
        progress_updates = []
        def progress_callback(current, total, status):
            progress_updates.append((current, total, status))
        
        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
        for i in range(1, 4):
            progress_callback(i, 3, f"å¤„ç†ä»»åŠ¡ {i}/3")
        
        assert len(progress_updates) == 3, "è¿›åº¦å›è°ƒæµ‹è¯•å¤±è´¥"
        assert progress_updates[0] == (1, 3, "å¤„ç†ä»»åŠ¡ 1/3"), "è¿›åº¦å›è°ƒå†…å®¹é”™è¯¯"
        
        logger.info("âœ… æ‰¹é‡å¤„ç†é€»è¾‘æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¤„ç†é€»è¾‘æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_keep_range_table_optimization():
    """æµ‹è¯•ä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–"""
    logger.info("ğŸ§ª æµ‹è¯•ä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–...")
    
    try:
        from keep_range_models import TcpKeepRangeTable, TcpKeepRangeEntry
        
        # åˆ›å»ºåŒ…å«é‡å æ¡ç›®çš„è¡¨
        table = TcpKeepRangeTable()
        
        # æ·»åŠ é‡å çš„æ¡ç›®ï¼ˆåº”è¯¥å¯ä»¥åˆå¹¶ï¼‰
        entry1 = TcpKeepRangeEntry(
            stream_id="TCP_1.2.3.4:443_5.6.7.8:1234_forward",
            sequence_start=1000,
            sequence_end=1500,
            keep_ranges=[(0, 5)],
            protocol_hint="TLS"
        )
        
        entry2 = TcpKeepRangeEntry(
            stream_id="TCP_1.2.3.4:443_5.6.7.8:1234_forward",
            sequence_start=1400,  # ä¸entry1é‡å 
            sequence_end=2000,
            keep_ranges=[(0, 5)],
            protocol_hint="TLS"
        )
        
        entry3 = TcpKeepRangeEntry(
            stream_id="TCP_1.2.3.4:80_5.6.7.8:5678_forward",  # ä¸åŒæµ
            sequence_start=3000,
            sequence_end=4000,
            keep_ranges=[(0, 10)],
            protocol_hint="HTTP"
        )
        
        table.add_keep_range_entry(entry1)
        table.add_keep_range_entry(entry2)
        table.add_keep_range_entry(entry3)
        
        original_count = table.get_total_entries()
        assert original_count == 3, "åŸå§‹æ¡ç›®æ•°é‡é”™è¯¯"
        
        # æµ‹è¯•èŒƒå›´åˆå¹¶é€»è¾‘
        def merge_overlapping_ranges(ranges):
            """ç®€åŒ–çš„èŒƒå›´åˆå¹¶å®ç°"""
            if not ranges:
                return []
            
            sorted_ranges = sorted(ranges)
            merged = [sorted_ranges[0]]
            
            for current in sorted_ranges[1:]:
                last = merged[-1]
                
                if current[0] <= last[1]:
                    merged[-1] = (last[0], max(last[1], current[1]))
                else:
                    merged.append(current)
            
            return merged
        
        # æµ‹è¯•èŒƒå›´åˆå¹¶
        test_ranges = [(0, 5), (3, 8), (10, 15)]
        merged_ranges = merge_overlapping_ranges(test_ranges)
        expected = [(0, 8), (10, 15)]
        assert merged_ranges == expected, f"èŒƒå›´åˆå¹¶é”™è¯¯: {merged_ranges} != {expected}"
        
        # æµ‹è¯•å•ç‹¬èŒƒå›´
        single_range = [(5, 10)]
        merged_single = merge_overlapping_ranges(single_range)
        assert merged_single == [(5, 10)], "å•ç‹¬èŒƒå›´åˆå¹¶é”™è¯¯"
        
        # æµ‹è¯•ç©ºèŒƒå›´
        empty_merged = merge_overlapping_ranges([])
        assert empty_merged == [], "ç©ºèŒƒå›´åˆå¹¶é”™è¯¯"
        
        logger.info("âœ… ä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_processing_time_estimation():
    """æµ‹è¯•å¤„ç†æ—¶é—´ä¼°ç®—"""
    logger.info("ğŸ§ª æµ‹è¯•å¤„ç†æ—¶é—´ä¼°ç®—...")
    
    try:
        from keep_range_models import TcpKeepRangeTable, TcpKeepRangeEntry
        
        # åˆ›å»ºä¸åŒå¤æ‚åº¦çš„ä¿ç•™èŒƒå›´è¡¨
        simple_table = TcpKeepRangeTable()
        entry = TcpKeepRangeEntry(
            stream_id="TCP_1.2.3.4:443_5.6.7.8:1234_forward",
            sequence_start=1000,
            sequence_end=2000,
            keep_ranges=[(0, 5)],
            protocol_hint="TLS"
        )
        simple_table.add_keep_range_entry(entry)
        
        complex_table = TcpKeepRangeTable()
        for i in range(10):
            entry = TcpKeepRangeEntry(
                stream_id=f"TCP_1.2.3.{i}:443_5.6.7.8:1234_forward",
                sequence_start=i * 1000,
                sequence_end=(i + 1) * 1000,
                keep_ranges=[(0, 5), (10, 15)],
                protocol_hint="TLS"
            )
            complex_table.add_keep_range_entry(entry)
        
        # æ¨¡æ‹Ÿæ—¶é—´ä¼°ç®—é€»è¾‘
        def estimate_processing_time(file_size_mb: float, table: TcpKeepRangeTable):
            """æ¨¡æ‹Ÿå¤„ç†æ—¶é—´ä¼°ç®—"""
            complexity_score = (
                table.get_total_entries() * 0.1 +
                table.get_streams_count() * 0.5 +
                len(table.get_all_stream_ids()) * 0.3
            )
            
            base_time = file_size_mb * 0.1
            complexity_time = complexity_score * 0.05
            estimated_time = base_time + complexity_time
            
            return {
                'estimated_time': estimated_time,
                'confidence': 0.8,
                'file_size_mb': file_size_mb,
                'complexity_score': complexity_score
            }
        
        # æµ‹è¯•ç®€å•è¡¨
        simple_estimation = estimate_processing_time(1.0, simple_table)
        assert simple_estimation['file_size_mb'] == 1.0, "æ–‡ä»¶å¤§å°è®°å½•é”™è¯¯"
        assert simple_estimation['estimated_time'] > 0, "ä¼°ç®—æ—¶é—´åº”å¤§äº0"
        assert simple_estimation['complexity_score'] > 0, "å¤æ‚åº¦è¯„åˆ†åº”å¤§äº0"
        
        # æµ‹è¯•å¤æ‚è¡¨
        complex_estimation = estimate_processing_time(1.0, complex_table)
        assert complex_estimation['complexity_score'] > simple_estimation['complexity_score'], "å¤æ‚è¡¨å¤æ‚åº¦åº”æ›´é«˜"
        assert complex_estimation['estimated_time'] > simple_estimation['estimated_time'], "å¤æ‚è¡¨ä¼°ç®—æ—¶é—´åº”æ›´é•¿"
        
        # æµ‹è¯•ä¸åŒæ–‡ä»¶å¤§å°
        large_file_estimation = estimate_processing_time(10.0, simple_table)
        assert large_file_estimation['estimated_time'] > simple_estimation['estimated_time'], "å¤§æ–‡ä»¶ä¼°ç®—æ—¶é—´åº”æ›´é•¿"
        
        logger.info("âœ… å¤„ç†æ—¶é—´ä¼°ç®—æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†æ—¶é—´ä¼°ç®—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡è®¡ç®—"""
    logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½æŒ‡æ ‡è®¡ç®—...")
    
    try:
        # æ¨¡æ‹Ÿæ€§èƒ½ç»Ÿè®¡æ•°æ®
        mock_stats = {
            'total_processing_time': 10.0,
            'total_packets_processed': 1000,
            'total_packets_modified': 750,
            'total_files_processed': 5,
            'total_tcp_streams_processed': 25,
            'total_bytes_masked': 50000,
            'total_bytes_kept': 10000,
            'avg_processing_time_per_file': 2.0
        }
        
        # æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡è®¡ç®—
        def calculate_performance_metrics(stats):
            """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
            total_time = stats.get('total_processing_time', 0.001)
            total_packets = stats.get('total_packets_processed', 0)
            processing_speed = total_packets / total_time if total_time > 0 else 0
            
            estimated_data_mb = total_packets * 1024 / (1024 * 1024)
            throughput_mbps = estimated_data_mb / total_time if total_time > 0 else 0
            
            modification_efficiency = (
                stats.get('total_packets_modified', 0) / total_packets * 100
                if total_packets > 0 else 0
            )
            
            stream_efficiency = (
                stats.get('total_tcp_streams_processed', 0) / 
                stats.get('total_files_processed', 1)
            )
            
            return {
                'processing_speed': {
                    'packets_per_second': processing_speed,
                    'files_per_hour': stats.get('total_files_processed', 0) / (total_time / 3600) if total_time > 0 else 0
                },
                'throughput': {
                    'mbps': throughput_mbps,
                    'estimated_data_processed_mb': estimated_data_mb
                },
                'efficiency_metrics': {
                    'modification_rate_percent': modification_efficiency,
                    'avg_streams_per_file': stream_efficiency,
                    'avg_processing_time_per_file': stats.get('avg_processing_time_per_file', 0)
                }
            }
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        metrics = calculate_performance_metrics(mock_stats)
        
        # éªŒè¯è®¡ç®—ç»“æœ
        assert metrics['processing_speed']['packets_per_second'] == 100.0, "å¤„ç†é€Ÿåº¦è®¡ç®—é”™è¯¯"
        assert metrics['efficiency_metrics']['modification_rate_percent'] == 75.0, "ä¿®æ”¹ç‡è®¡ç®—é”™è¯¯"
        assert metrics['efficiency_metrics']['avg_streams_per_file'] == 5.0, "å¹³å‡æµæ•°è®¡ç®—é”™è¯¯"
        
        # éªŒè¯ååé‡è®¡ç®—
        assert metrics['throughput']['mbps'] > 0, "ååé‡åº”å¤§äº0"
        assert metrics['throughput']['estimated_data_processed_mb'] > 0, "ä¼°ç®—æ•°æ®é‡åº”å¤§äº0"
        
        # éªŒè¯æ–‡ä»¶å¤„ç†é€Ÿåº¦
        assert metrics['processing_speed']['files_per_hour'] > 0, "æ–‡ä»¶å¤„ç†é€Ÿåº¦åº”å¤§äº0"
        
        logger.info("âœ… æ€§èƒ½æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æŒ‡æ ‡è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_resource_management():
    """æµ‹è¯•èµ„æºç®¡ç†"""
    logger.info("ğŸ§ª æµ‹è¯•èµ„æºç®¡ç†...")
    
    try:
        # æ¨¡æ‹Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        resource_stats = {
            'memory_usage_mb': 150.5,
            'temp_files_count': 5,
            'cache_entries': 100,
            'active_connections': 3
        }
        
        # æ¨¡æ‹Ÿèµ„æºæ¸…ç†é€»è¾‘
        def cleanup_resources(stats):
            """æ¨¡æ‹Ÿèµ„æºæ¸…ç†"""
            cleaned_stats = stats.copy()
            
            # æ¨¡æ‹Ÿæ¸…ç†æ“ä½œ
            cleaned_stats['temp_files_count'] = 0
            cleaned_stats['cache_entries'] = 0
            cleaned_stats['active_connections'] = 0
            # å†…å­˜ä½¿ç”¨å‡å°‘50%
            cleaned_stats['memory_usage_mb'] = stats['memory_usage_mb'] * 0.5
            
            return cleaned_stats
        
        # æ‰§è¡Œæ¸…ç†
        original_memory = resource_stats['memory_usage_mb']
        cleaned_stats = cleanup_resources(resource_stats)
        
        # éªŒè¯æ¸…ç†æ•ˆæœ
        assert cleaned_stats['temp_files_count'] == 0, "ä¸´æ—¶æ–‡ä»¶æœªæ¸…ç†"
        assert cleaned_stats['cache_entries'] == 0, "ç¼“å­˜æœªæ¸…ç†"
        assert cleaned_stats['active_connections'] == 0, "è¿æ¥æœªå…³é—­"
        assert cleaned_stats['memory_usage_mb'] < original_memory, "å†…å­˜ä½¿ç”¨æœªå‡å°‘"
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†ä¸­çš„èµ„æºç®¡ç†
        def simulate_batch_processing_with_cleanup():
            """æ¨¡æ‹Ÿå¸¦èµ„æºæ¸…ç†çš„æ‰¹é‡å¤„ç†"""
            resources = {'memory': 100}
            
            # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ä¸­èµ„æºå¢é•¿
            for i in range(5):
                resources['memory'] += 20  # æ¯ä¸ªä»»åŠ¡å¢åŠ 20MB
                
                # æ¯å¤„ç†2ä¸ªä»»åŠ¡æ¸…ç†ä¸€æ¬¡èµ„æº
                if (i + 1) % 2 == 0:
                    resources['memory'] *= 0.7  # æ¸…ç†30%å†…å­˜
            
            return resources
        
        final_resources = simulate_batch_processing_with_cleanup()
        assert final_resources['memory'] < 200, "æ‰¹é‡å¤„ç†èµ„æºç®¡ç†å¤±æ•ˆ"
        
        logger.info("âœ… èµ„æºç®¡ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ èµ„æºç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_optimization_modes():
    """æµ‹è¯•ä¼˜åŒ–æ¨¡å¼é…ç½®"""
    logger.info("ğŸ§ª æµ‹è¯•ä¼˜åŒ–æ¨¡å¼é…ç½®...")
    
    try:
        # æ¨¡æ‹Ÿé…ç½®ç®¡ç†
        class MockConfigManager:
            def __init__(self):
                self.config = {}
            
            def update(self, updates):
                self.config.update(updates)
            
            def get(self, key, default=None):
                return self.config.get(key, default)
        
        config_manager = MockConfigManager()
        
        # æµ‹è¯•å¯ç”¨æ€§èƒ½ä¼˜åŒ–
        def enable_performance_optimization(enable=True):
            """æ¨¡æ‹Ÿå¯ç”¨æ€§èƒ½ä¼˜åŒ–"""
            config_manager.update({'performance_optimization_enabled': enable})
            
            if enable:
                optimizations = {
                    'auto_optimize_keep_range_table': True,
                    'enable_batch_processing': True,
                    'cache_query_results': True,
                    'optimize_memory_usage': True
                }
            else:
                optimizations = {
                    'auto_optimize_keep_range_table': False,
                    'enable_batch_processing': False,
                    'cache_query_results': False,
                    'optimize_memory_usage': False
                }
            
            config_manager.update(optimizations)
        
        # æµ‹è¯•å¯ç”¨ä¼˜åŒ–
        enable_performance_optimization(True)
        assert config_manager.get('performance_optimization_enabled') == True, "æ€§èƒ½ä¼˜åŒ–æœªå¯ç”¨"
        assert config_manager.get('auto_optimize_keep_range_table') == True, "è‡ªåŠ¨ä¼˜åŒ–æœªå¯ç”¨"
        assert config_manager.get('enable_batch_processing') == True, "æ‰¹é‡å¤„ç†æœªå¯ç”¨"
        assert config_manager.get('cache_query_results') == True, "æŸ¥è¯¢ç¼“å­˜æœªå¯ç”¨"
        assert config_manager.get('optimize_memory_usage') == True, "å†…å­˜ä¼˜åŒ–æœªå¯ç”¨"
        
        # æµ‹è¯•ç¦ç”¨ä¼˜åŒ–
        enable_performance_optimization(False)
        assert config_manager.get('performance_optimization_enabled') == False, "æ€§èƒ½ä¼˜åŒ–æœªç¦ç”¨"
        assert config_manager.get('auto_optimize_keep_range_table') == False, "è‡ªåŠ¨ä¼˜åŒ–æœªç¦ç”¨"
        assert config_manager.get('enable_batch_processing') == False, "æ‰¹é‡å¤„ç†æœªç¦ç”¨"
        assert config_manager.get('cache_query_results') == False, "æŸ¥è¯¢ç¼“å­˜æœªç¦ç”¨"
        assert config_manager.get('optimize_memory_usage') == False, "å†…å­˜ä¼˜åŒ–æœªç¦ç”¨"
        
        logger.info("âœ… ä¼˜åŒ–æ¨¡å¼é…ç½®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¼˜åŒ–æ¨¡å¼é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def test_performance_characteristics():
    """æµ‹è¯•æ€§èƒ½ç‰¹å¾"""
    logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½ç‰¹å¾...")
    
    try:
        from keep_range_models import TcpKeepRangeTable, TcpKeepRangeEntry
        
        # æµ‹è¯•å¤§è§„æ¨¡æ•°æ®å¤„ç†æ€§èƒ½
        table = TcpKeepRangeTable()
        
        # æ·»åŠ å¤§é‡æ¡ç›®æµ‹è¯•æ€§èƒ½
        start_time = time.time()
        for i in range(1000):
            entry = TcpKeepRangeEntry(
                stream_id=f"TCP_1.2.3.{i%256}:443_5.6.7.8:{1234+i}_forward",
                sequence_start=i * 1000,
                sequence_end=(i + 1) * 1000,
                keep_ranges=[(0, 5)],
                protocol_hint="TLS"
            )
            table.add_keep_range_entry(entry)
        
        add_time = time.time() - start_time
        logger.info(f"æ·»åŠ 1000ä¸ªæ¡ç›®è€—æ—¶: {add_time:.4f}ç§’")
        
        # æµ‹è¯•æŸ¥æ‰¾æ€§èƒ½
        start_time = time.time()
        for i in range(1000):
            stream_id = f"TCP_1.2.3.{i%256}:443_5.6.7.8:{1234+i}_forward"
            ranges = table.find_keep_ranges_for_sequence(stream_id, i * 1000 + 500)
        lookup_time = time.time() - start_time
        logger.info(f"1000æ¬¡æŸ¥æ‰¾è€—æ—¶: {lookup_time:.4f}ç§’")
        
        # æ€§èƒ½è¦æ±‚éªŒè¯
        assert add_time < 5.0, f"æ·»åŠ æ¡ç›®æ€§èƒ½ä¸è¾¾æ ‡: {add_time}ç§’"
        assert lookup_time < 1.0, f"æŸ¥æ‰¾æ€§èƒ½ä¸è¾¾æ ‡: {lookup_time}ç§’"
        
        # éªŒè¯æ•°æ®æ­£ç¡®æ€§
        assert table.get_total_entries() == 1000, "æ¡ç›®æ•°é‡ä¸æ­£ç¡®"
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        add_rate = 1000 / add_time  # æ¡ç›®/ç§’
        lookup_rate = 1000 / lookup_time  # æŸ¥è¯¢/ç§’
        
        logger.info(f"æ·»åŠ æ€§èƒ½: {add_rate:.0f} æ¡ç›®/ç§’")
        logger.info(f"æŸ¥è¯¢æ€§èƒ½: {lookup_rate:.0f} æŸ¥è¯¢/ç§’")
        
        assert add_rate > 200, "æ·»åŠ æ€§èƒ½è¿‡ä½"
        assert lookup_rate > 1000, "æŸ¥è¯¢æ€§èƒ½è¿‡ä½"
        
        logger.info("âœ… æ€§èƒ½ç‰¹å¾æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½ç‰¹å¾æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def run_phase5_validation():
    """è¿è¡Œé˜¶æ®µ5éªŒè¯æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹TCP Payload Maskeré˜¶æ®µ5éªŒè¯æµ‹è¯•")
    
    tests = [
        ("æ‰¹é‡å¤„ç†é€»è¾‘", test_batch_processing_logic),
        ("ä¿ç•™èŒƒå›´è¡¨ä¼˜åŒ–", test_keep_range_table_optimization),
        ("å¤„ç†æ—¶é—´ä¼°ç®—", test_processing_time_estimation),
        ("æ€§èƒ½æŒ‡æ ‡è®¡ç®—", test_performance_metrics),
        ("èµ„æºç®¡ç†", test_resource_management),
        ("ä¼˜åŒ–æ¨¡å¼é…ç½®", test_optimization_modes),
        ("æ€§èƒ½ç‰¹å¾", test_performance_characteristics),
    ]
    
    passed = 0
    total = len(tests)
    
    start_time = time.time()
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"æ‰§è¡Œæµ‹è¯•: {test_name}")
        logger.info(f"{'='*50}")
        
        if test_func():
            passed += 1
            logger.info(f"âœ… {test_name} - é€šè¿‡")
        else:
            logger.error(f"âŒ {test_name} - å¤±è´¥")
    
    end_time = time.time()
    test_duration = end_time - start_time
    
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ¯ TCP Payload Maskeré˜¶æ®µ5éªŒè¯æµ‹è¯•ç»“æœ")
    logger.info(f"{'='*60}")
    logger.info(f"é€šè¿‡æµ‹è¯•: {passed}/{total} ({passed/total*100:.1f}%)")
    logger.info(f"æµ‹è¯•è€—æ—¶: {test_duration:.2f} ç§’")
    
    if passed == total:
        logger.info("ğŸ‰ é˜¶æ®µ5éªŒè¯æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
    else:
        logger.error(f"ğŸ’¥ {total-passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    success = run_phase5_validation()
    sys.exit(0 if success else 1)