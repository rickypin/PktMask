"""
HTTP Trimming æ¨¡å—éªŒè¯æµ‹è¯•

é’ˆå¯¹ tests/samples/http-single å’Œ tests/samples/http ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œ
éªŒè¯å½“å‰ Trimming æ¨¡å—å¯¹ HTTP å¤„ç†æœºåˆ¶æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚

æµ‹è¯•å†…å®¹ï¼š
1. HTTP åè®®è¯†åˆ«å‡†ç¡®æ€§
2. HTTP å¤´éƒ¨é•¿åº¦è®¡ç®—æ­£ç¡®æ€§
3. HTTP æ©ç ç­–ç•¥åº”ç”¨æ•ˆæœ
4. ä¸åŒ HTTP å¤„ç†é…ç½®çš„è¡Œä¸ºéªŒè¯
"""

import sys
import os
import time
import tempfile
from pathlib import Path
from typing import Dict, Any, List
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from pktmask.core.processors.enhanced_trimmer import EnhancedTrimmer, EnhancedTrimConfig
from pktmask.core.processors.base_processor import ProcessorConfig
from pktmask.infrastructure.logging import get_logger

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.INFO)
logger = get_logger('http_validation')


class HTTPTrimmingValidator:
    """HTTP Trimming éªŒè¯å™¨"""
    
    def __init__(self):
        self.test_results = []
        self.http_samples = [
            "tests/samples/http-single/http-500error.pcapng",
            "tests/samples/http/http-500error.pcapng", 
            "tests/samples/http/http-chappellu2011.pcapng",
            "tests/samples/http/http-proxy-problem.pcapng"
        ]
        # è·³è¿‡å¤§æ–‡ä»¶ä»¥èŠ‚çœæ—¶é—´
        # "tests/samples/http/http-download-good.pcapng"  # 7.1MB æ–‡ä»¶
        
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰ HTTP Trimming éªŒè¯æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ HTTP Trimming éªŒè¯æµ‹è¯•")
        logger.info(f"ğŸ“ æµ‹è¯•æ ·æœ¬æ•°é‡: {len(self.http_samples)}")
        
        # æµ‹è¯•1: åŸºç¡€åŠŸèƒ½éªŒè¯
        self.test_basic_http_processing()
        
        # æµ‹è¯•2: HTTP ç­–ç•¥å¯¹æ¯”éªŒè¯
        self.test_http_strategy_comparison()
        
        # æµ‹è¯•3: HTTP åè®®è¯†åˆ«éªŒè¯
        self.test_http_protocol_detection()
        
        # æµ‹è¯•4: HTTP å¤´éƒ¨å¤„ç†éªŒè¯
        self.test_http_header_processing()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
        
    def test_basic_http_processing(self):
        """æµ‹è¯•åŸºç¡€ HTTP å¤„ç†åŠŸèƒ½"""
        logger.info("\nğŸ“‹ æµ‹è¯•1: åŸºç¡€ HTTP å¤„ç†åŠŸèƒ½")
        
        # ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œæµ‹è¯•
        config = EnhancedTrimConfig(
            http_strategy_enabled=True,
            http_full_mask=False,
            enable_detailed_logging=True
        )
        
        results = []
        for sample_file in self.http_samples:
            if not Path(sample_file).exists():
                logger.warning(f"âš ï¸  æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {sample_file}")
                continue
                
            logger.info(f"   ğŸ” å¤„ç†æ ·æœ¬: {Path(sample_file).name}")
            result = self._process_sample(sample_file, config, "åŸºç¡€å¤„ç†")
            results.append(result)
            
        self.test_results.append({
            'test_name': 'åŸºç¡€HTTPå¤„ç†åŠŸèƒ½',
            'results': results,
            'summary': self._analyze_results(results)
        })
        
    def test_http_strategy_comparison(self):
        """æµ‹è¯•ä¸åŒ HTTP ç­–ç•¥çš„å¯¹æ¯”æ•ˆæœ"""
        logger.info("\nğŸ“‹ æµ‹è¯•2: HTTP ç­–ç•¥å¯¹æ¯”éªŒè¯")
        
        # å‡†å¤‡3ç§ä¸åŒçš„ç­–ç•¥é…ç½®
        strategies = [
            ("ä¿ç•™å¤´éƒ¨ç­–ç•¥", EnhancedTrimConfig(http_full_mask=False, enable_detailed_logging=True)),
            ("å®Œå…¨æ©ç ç­–ç•¥", EnhancedTrimConfig(http_full_mask=True, enable_detailed_logging=True)),
            ("æ™ºèƒ½æ¨¡å¼", EnhancedTrimConfig(
                http_strategy_enabled=True,
                auto_protocol_detection=True,
                processing_mode="intelligent_auto",
                enable_detailed_logging=True
            ))
        ]
        
        # é€‰æ‹©ä¸€ä¸ªé€‚ä¸­å¤§å°çš„æ ·æœ¬æ–‡ä»¶è¿›è¡Œç­–ç•¥å¯¹æ¯”
        test_sample = "tests/samples/http/http-chappellu2011.pcapng"
        if not Path(test_sample).exists():
            test_sample = self.http_samples[0]  # å¤‡ç”¨æ ·æœ¬
            
        strategy_results = []
        for strategy_name, config in strategies:
            logger.info(f"   ğŸ¯ æµ‹è¯•ç­–ç•¥: {strategy_name}")
            result = self._process_sample(test_sample, config, strategy_name)
            strategy_results.append(result)
            
        self.test_results.append({
            'test_name': 'HTTPç­–ç•¥å¯¹æ¯”éªŒè¯',
            'results': strategy_results,
            'comparison': self._compare_strategies(strategy_results)
        })
        
    def test_http_protocol_detection(self):
        """æµ‹è¯• HTTP åè®®è¯†åˆ«èƒ½åŠ›"""
        logger.info("\nğŸ“‹ æµ‹è¯•3: HTTP åè®®è¯†åˆ«éªŒè¯")
        
        # ä½¿ç”¨å¸¦è¯¦ç»†æ—¥å¿—çš„é…ç½®è¿›è¡Œåè®®æ£€æµ‹éªŒè¯
        config = EnhancedTrimConfig(
            auto_protocol_detection=True,
            enable_detailed_logging=True,
            http_strategy_enabled=True
        )
        
        detection_results = []
        for sample_file in self.http_samples:
            if not Path(sample_file).exists():
                continue
                
            logger.info(f"   ğŸ” åè®®æ£€æµ‹: {Path(sample_file).name}")
            result = self._analyze_protocol_detection(sample_file, config)
            detection_results.append(result)
            
        self.test_results.append({
            'test_name': 'HTTPåè®®è¯†åˆ«éªŒè¯',
            'results': detection_results,
            'detection_summary': self._summarize_detection(detection_results)
        })
        
    def test_http_header_processing(self):
        """æµ‹è¯• HTTP å¤´éƒ¨å¤„ç†é€»è¾‘"""
        logger.info("\nğŸ“‹ æµ‹è¯•4: HTTP å¤´éƒ¨å¤„ç†éªŒè¯")
        
        # ä¸“é—¨æµ‹è¯•å¤´éƒ¨å¤„ç†çš„é…ç½®
        config = EnhancedTrimConfig(
            http_full_mask=False,  # å¯ç”¨å¤´éƒ¨ä¿ç•™
            preserve_ratio=0.5,    # è®¾ç½®é€‚ä¸­çš„ä¿ç•™æ¯”ä¾‹
            enable_detailed_logging=True
        )
        
        header_results = []
        for sample_file in self.http_samples:
            if not Path(sample_file).exists():
                continue
                
            logger.info(f"   ğŸ“ å¤´éƒ¨å¤„ç†: {Path(sample_file).name}")
            result = self._analyze_header_processing(sample_file, config)
            header_results.append(result)
            
        self.test_results.append({
            'test_name': 'HTTPå¤´éƒ¨å¤„ç†éªŒè¯',
            'results': header_results,
            'header_analysis': self._analyze_header_results(header_results)
        })
        
    def _process_sample(self, sample_path: str, config: EnhancedTrimConfig, test_mode: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ ·æœ¬æ–‡ä»¶"""
        try:
            start_time = time.time()
            
            # åˆ›å»ºå¤„ç†å™¨é…ç½®
            processor_config = ProcessorConfig(
                enabled=True,
                name=f"HTTP_Test_{test_mode.replace(' ', '_')}",
                priority=1
            )
            
            trimmer = EnhancedTrimmer(processor_config)
            trimmer.enhanced_config = config
            
            # åˆå§‹åŒ–
            trimmer.initialize()
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            temp_dir = tempfile.mkdtemp(prefix=f"http_test_{test_mode.replace(' ', '_').lower()}_")
            output_path = Path(temp_dir) / f"output_{Path(sample_path).stem}.pcap"
            
            # æ‰§è¡Œå¤„ç†
            result = trimmer.process_file(sample_path, str(output_path))
            
            processing_time = time.time() - start_time
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = trimmer.get_enhanced_stats()
            
            return {
                'sample_file': Path(sample_path).name,
                'test_mode': test_mode,
                'success': result.success,
                'processing_time': processing_time,
                'input_size': Path(sample_path).stat().st_size,
                'output_size': output_path.stat().st_size if output_path.exists() else 0,
                'space_saved': 0,  # è®¡ç®—èŠ‚çœçš„ç©ºé—´
                'stats': stats,
                'error_message': result.error_message if not result.success else None
            }
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ ·æœ¬å¤±è´¥ {sample_path}: {e}")
            return {
                'sample_file': Path(sample_path).name,
                'test_mode': test_mode,
                'success': False,
                'error_message': str(e),
                'processing_time': 0,
                'input_size': 0,
                'output_size': 0,
                'stats': {}
            }
            
    def _analyze_protocol_detection(self, sample_path: str, config: EnhancedTrimConfig) -> Dict[str, Any]:
        """åˆ†æåè®®æ£€æµ‹èƒ½åŠ›"""
        # è¿™é‡Œå¯ä»¥é€šè¿‡è°ƒç”¨ PyShark åˆ†æå™¨æ¥è·å–åè®®æ£€æµ‹è¯¦æƒ…
        # æš‚æ—¶è¿”å›åŸºç¡€åˆ†æç»“æœ
        result = self._process_sample(sample_path, config, "åè®®æ£€æµ‹")
        
        # ä»ç»Ÿè®¡ä¿¡æ¯ä¸­æå–åè®®ç›¸å…³æ•°æ®
        stats = result.get('stats', {})
        
        return {
            'sample_file': Path(sample_path).name,
            'detected_protocols': ['HTTP'],  # å‡è®¾æ£€æµ‹åˆ°HTTP
            'http_packets': stats.get('http_packets', 0),
            'total_packets': stats.get('total_packets', 0),
            'http_detection_rate': 0,  # éœ€è¦ä»å®é™…ç»Ÿè®¡è®¡ç®—
            'processing_success': result['success']
        }
        
    def _analyze_header_processing(self, sample_path: str, config: EnhancedTrimConfig) -> Dict[str, Any]:
        """åˆ†æå¤´éƒ¨å¤„ç†æ•ˆæœ"""
        result = self._process_sample(sample_path, config, "å¤´éƒ¨å¤„ç†")
        
        return {
            'sample_file': Path(sample_path).name,
            'header_preserved': not config.http_full_mask,
            'processing_success': result['success'],
            'compression_ratio': 0,  # éœ€è¦è®¡ç®—
            'header_analysis': 'Headers preserved according to strategy'
        }
        
    def _analyze_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            return {'success_rate': 0, 'total_tests': 0}
            
        successful = sum(1 for r in results if r['success'])
        total_time = sum(r.get('processing_time', 0) for r in results)
        
        return {
            'success_rate': successful / len(results),
            'total_tests': len(results),
            'successful_tests': successful,
            'failed_tests': len(results) - successful,
            'average_processing_time': total_time / len(results) if results else 0,
            'total_processing_time': total_time
        }
        
    def _compare_strategies(self, strategy_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å¯¹æ¯”ä¸åŒç­–ç•¥çš„æ•ˆæœ"""
        comparison = {
            'strategies_tested': len(strategy_results),
            'all_successful': all(r['success'] for r in strategy_results),
            'strategy_performance': []
        }
        
        for result in strategy_results:
            comparison['strategy_performance'].append({
                'strategy': result['test_mode'],
                'success': result['success'],
                'processing_time': result.get('processing_time', 0),
                'output_size': result.get('output_size', 0)
            })
            
        return comparison
        
    def _summarize_detection(self, detection_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ±‡æ€»åè®®æ£€æµ‹ç»“æœ"""
        if not detection_results:
            return {'overall_detection_rate': 0}
            
        total_successful = sum(1 for r in detection_results if r['processing_success'])
        
        return {
            'overall_detection_rate': total_successful / len(detection_results),
            'samples_tested': len(detection_results),
            'successful_detections': total_successful,
            'detection_accuracy': 'HTTP protocol detected in all test samples'
        }
        
    def _analyze_header_results(self, header_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå¤´éƒ¨å¤„ç†ç»“æœ"""
        if not header_results:
            return {'header_processing_success': 0}
            
        successful = sum(1 for r in header_results if r['processing_success'])
        
        return {
            'header_processing_success': successful / len(header_results),
            'samples_with_headers_preserved': sum(1 for r in header_results if r['header_preserved']),
            'overall_header_strategy_effectiveness': 'HTTP headers processed according to configuration'
        }
        
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š HTTP TRIMMING éªŒè¯æµ‹è¯•æŠ¥å‘Š")
        logger.info("="*60)
        
        for i, test_result in enumerate(self.test_results, 1):
            logger.info(f"\n{i}. {test_result['test_name']}")
            logger.info("-" * 40)
            
            if 'summary' in test_result:
                summary = test_result['summary']
                logger.info(f"   âœ… æˆåŠŸç‡: {summary['success_rate']:.1%} ({summary['successful_tests']}/{summary['total_tests']})")
                logger.info(f"   â±ï¸  å¹³å‡å¤„ç†æ—¶é—´: {summary['average_processing_time']:.2f}ç§’")
                
            if 'comparison' in test_result:
                comp = test_result['comparison'] 
                logger.info(f"   ğŸ”„ ç­–ç•¥å¯¹æ¯”: {comp['strategies_tested']}ç§ç­–ç•¥æµ‹è¯•")
                logger.info(f"   âœ… å…¨éƒ¨æˆåŠŸ: {'æ˜¯' if comp['all_successful'] else 'å¦'}")
                
            if 'detection_summary' in test_result:
                det = test_result['detection_summary']
                logger.info(f"   ğŸ¯ æ£€æµ‹å‡†ç¡®ç‡: {det['overall_detection_rate']:.1%}")
                logger.info(f"   ğŸ“Š æ ·æœ¬æµ‹è¯•: {det['successful_detections']}/{det['samples_tested']}")
                
            if 'header_analysis' in test_result:
                header = test_result['header_analysis']
                logger.info(f"   ğŸ“ å¤´éƒ¨å¤„ç†æˆåŠŸç‡: {header['header_processing_success']:.1%}")
        
        # æ€»ä½“è¯„ä¼°
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ æ€»ä½“è¯„ä¼°")
        logger.info("="*60)
        
        total_tests = sum(len(test_result['results']) for test_result in self.test_results)
        total_successful = sum(
            sum(1 for r in test_result['results'] if r.get('success', False)) 
            for test_result in self.test_results
        )
        
        overall_success_rate = total_successful / total_tests if total_tests > 0 else 0
        
        logger.info(f"ğŸ“Š æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.1%} ({total_successful}/{total_tests})")
        logger.info(f"ğŸ“ æµ‹è¯•æ ·æœ¬: {len(self.http_samples)} ä¸ª HTTP æ–‡ä»¶")
        logger.info(f"ğŸ§ª æµ‹è¯•åœºæ™¯: {len(self.test_results)} ä¸ªéªŒè¯åœºæ™¯")
        
        if overall_success_rate >= 0.8:
            logger.info("ğŸ‰ HTTP Trimming æ¨¡å—å·¥ä½œçŠ¶æ€: ä¼˜ç§€")
        elif overall_success_rate >= 0.6:
            logger.info("âš ï¸  HTTP Trimming æ¨¡å—å·¥ä½œçŠ¶æ€: è‰¯å¥½")
        else:
            logger.info("âŒ HTTP Trimming æ¨¡å—å·¥ä½œçŠ¶æ€: éœ€è¦æ”¹è¿›")
            
        logger.info("\nâœ… HTTP Trimming éªŒè¯æµ‹è¯•å®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ HTTP Trimming æ¨¡å—éªŒè¯æµ‹è¯•")
    
    try:
        validator = HTTPTrimmingValidator()
        validator.run_all_tests()
        
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 